Script started on 2017ÎÖÑ 05Ïõî 23Ïùº (Ìôî) Ïò§Ï†Ñ 01Ïãú 12Î∂Ñ 23Ï¥à
]0;gt@gt: ~/PycharmProjects/show-and-tell[01;32mgt@gt[00m:[01;34m~/PycharmProjects/show-and-tell[00m$ python Main.py[Ky

run arguments: {
    "batch_size": 128, 
    "crop_size": 224, 
    "data_json": "data/data.json", 
    "embed_size": 512, 
    "exp_id": "withGAN", 
    "expr_dir": "experiment", 
    "grad_clip": 0.5, 
    "hidden_size": 512, 
    "language_eval": 1, 
    "learning_rate": 0.0005, 
    "learning_rate_decay_every": 3, 
    "learning_rate_decay_rate": 0.8, 
    "learning_rate_decay_start": 1, 
    "load_best_score": true, 
    "load_model_path": false, 
    "load_optim_path": false, 
    "load_pretrained": false, 
    "log_step": 10, 
    "max_epochs": 100, 
    "max_length": 20, 
    "num_gpu": 1, 
    "num_layers": 1, 
    "random_seed": 1234, 
    "root_dir": "/home/gt/PycharmProjects/show-and-tell", 
    "save_checkpoint_every": 3236, 
    "scheduled_sampling_increase_every": 5, 
    "scheduled_sampling_increase_prob": 0.05, 
    "scheduled_sampling_max_prob": 0.25, 
    "scheduled_sampling_start": -1, 
    "start_from": null, 
    "user_id": "gt", 
    "vocab_path": "data/vocab.pkl"
}
load the dataset into memory...
total iterations in training phase : 3236 
total iterations in validation phase : 196
loading annotations into memory...
Done (t=0.51s)
creating index...
index created!
training the ShowAttendTellModel_GAN model from scratch
done
Epoch [1/100], Step [10/3236], Loss: 7.9862, Perplexity: 2939.9767
Epoch [1/100], Step [20/3236], Loss: 5.5321, Perplexity: 252.6809
Exception in user code:
------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gt/PycharmProjects/show-and-tell/visualizer/__init__.py", line 239, in _send
    data=json.dumps(msg),
  File "/usr/local/lib/python2.7/dist-packages/requests/api.py", line 110, in post
    return request('post', url, data=data, json=json, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/sessions.py", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/sessions.py", line 609, in send
    r = adapter.send(request, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fe5391509d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Epoch [1/100], Step [30/3236], Loss: 5.3079, Perplexity: 201.9353
Exception in user code:
------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gt/PycharmProjects/show-and-tell/visualizer/__init__.py", line 239, in _send
    data=json.dumps(msg),
  File "/usr/local/lib/python2.7/dist-packages/requests/api.py", line 110, in post
    return request('post', url, data=data, json=json, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/sessions.py", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/sessions.py", line 609, in send
    r = adapter.send(request, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/requests/adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fe5389b4e90>: Failed to establish a new connection: [Errno 111] Connection refused',))
^Z
[1]+  Ï†ïÏßÄÎê®               python Main.py
]0;gt@gt: ~/PycharmProjects/show-and-tell[01;32mgt@gt[00m:[01;34m~/PycharmProjects/show-and-tell[00m$ python Main.py

run arguments: {
    "batch_size": 128, 
    "crop_size": 224, 
    "data_json": "data/data.json", 
    "embed_size": 512, 
    "exp_id": "withGAN", 
    "expr_dir": "experiment", 
    "grad_clip": 0.5, 
    "hidden_size": 512, 
    "language_eval": 1, 
    "learning_rate": 0.0005, 
    "learning_rate_decay_every": 3, 
    "learning_rate_decay_rate": 0.8, 
    "learning_rate_decay_start": 1, 
    "load_best_score": true, 
    "load_model_path": false, 
    "load_optim_path": false, 
    "load_pretrained": false, 
    "log_step": 10, 
    "max_epochs": 100, 
    "max_length": 20, 
    "num_gpu": 1, 
    "num_layers": 1, 
    "random_seed": 1234, 
    "root_dir": "/home/gt/PycharmProjects/show-and-tell", 
    "save_checkpoint_every": 3236, 
    "scheduled_sampling_increase_every": 5, 
    "scheduled_sampling_increase_prob": 0.05, 
    "scheduled_sampling_max_prob": 0.25, 
    "scheduled_sampling_start": -1, 
    "start_from": null, 
    "user_id": "gt", 
    "vocab_path": "data/vocab.pkl"
}
load the dataset into memory...
total iterations in training phase : 3236 
total iterations in validation phase : 196
loading annotations into memory...
Done (t=0.50s)
creating index...
index created!
training the ShowAttendTellModel_GAN model from scratch
done
Epoch [1/100], Step [10/3236], Loss: 7.9865, Perplexity: 2940.8783
Epoch [1/100], Step [20/3236], Loss: 5.5332, Perplexity: 252.9498
Epoch [1/100], Step [30/3236], Loss: 5.3083, Perplexity: 201.9986
Epoch [1/100], Step [40/3236], Loss: 4.9889, Perplexity: 146.7813
Epoch [1/100], Step [50/3236], Loss: 4.9195, Perplexity: 136.9332
Epoch [1/100], Step [60/3236], Loss: 4.7775, Perplexity: 118.8034
Epoch [1/100], Step [70/3236], Loss: 4.6576, Perplexity: 105.3790
Epoch [1/100], Step [80/3236], Loss: 4.8141, Perplexity: 123.2395
Epoch [1/100], Step [90/3236], Loss: 4.4950, Perplexity: 89.5703
Epoch [1/100], Step [100/3236], Loss: 4.4829, Perplexity: 88.4921
Epoch [1/100], Step [110/3236], Loss: 4.4766, Perplexity: 87.9313
Epoch [1/100], Step [120/3236], Loss: 4.3733, Perplexity: 79.3047
Epoch [1/100], Step [130/3236], Loss: 4.3130, Perplexity: 74.6671
Epoch [1/100], Step [140/3236], Loss: 4.1710, Perplexity: 64.7789
Epoch [1/100], Step [150/3236], Loss: 4.3045, Perplexity: 74.0354
Epoch [1/100], Step [160/3236], Loss: 4.1573, Perplexity: 63.9009
Epoch [1/100], Step [170/3236], Loss: 4.2351, Perplexity: 69.0683
Epoch [1/100], Step [180/3236], Loss: 4.2590, Perplexity: 70.7367
Epoch [1/100], Step [190/3236], Loss: 4.1825, Perplexity: 65.5316
Epoch [1/100], Step [200/3236], Loss: 3.9669, Perplexity: 52.8184
Epoch [1/100], Step [210/3236], Loss: 4.0569, Perplexity: 57.7939
Epoch [1/100], Step [220/3236], Loss: 4.2009, Perplexity: 66.7486
Epoch [1/100], Step [230/3236], Loss: 4.0415, Perplexity: 56.9106
Epoch [1/100], Step [240/3236], Loss: 3.9496, Perplexity: 51.9148
Epoch [1/100], Step [250/3236], Loss: 3.8234, Perplexity: 45.7605
Epoch [1/100], Step [260/3236], Loss: 3.8994, Perplexity: 49.3748
Epoch [1/100], Step [270/3236], Loss: 3.9069, Perplexity: 49.7448
Epoch [1/100], Step [280/3236], Loss: 3.6704, Perplexity: 39.2694
Epoch [1/100], Step [290/3236], Loss: 3.8186, Perplexity: 45.5391
Epoch [1/100], Step [300/3236], Loss: 3.7820, Perplexity: 43.9038
Epoch [1/100], Step [310/3236], Loss: 3.6295, Perplexity: 37.6949
Epoch [1/100], Step [320/3236], Loss: 3.5882, Perplexity: 36.1707
Epoch [1/100], Step [330/3236], Loss: 3.6482, Perplexity: 38.4040
Epoch [1/100], Step [340/3236], Loss: 3.8666, Perplexity: 47.7778
Epoch [1/100], Step [350/3236], Loss: 3.7863, Perplexity: 44.0930
Epoch [1/100], Step [360/3236], Loss: 3.6506, Perplexity: 38.4974
Epoch [1/100], Step [370/3236], Loss: 3.7050, Perplexity: 40.6507
Epoch [1/100], Step [380/3236], Loss: 3.7839, Perplexity: 43.9887
Epoch [1/100], Step [390/3236], Loss: 3.6104, Perplexity: 36.9796
Epoch [1/100], Step [400/3236], Loss: 3.4884, Perplexity: 32.7336
Epoch [1/100], Step [410/3236], Loss: 3.4926, Perplexity: 32.8727
Epoch [1/100], Step [420/3236], Loss: 3.4574, Perplexity: 31.7348
Epoch [1/100], Step [430/3236], Loss: 3.6254, Perplexity: 37.5407
Epoch [1/100], Step [440/3236], Loss: 3.3993, Perplexity: 29.9437
Epoch [1/100], Step [450/3236], Loss: 3.5135, Perplexity: 33.5651
Epoch [1/100], Step [460/3236], Loss: 3.5110, Perplexity: 33.4831
Epoch [1/100], Step [470/3236], Loss: 3.3988, Perplexity: 29.9284
Epoch [1/100], Step [480/3236], Loss: 3.4415, Perplexity: 31.2329
Epoch [1/100], Step [490/3236], Loss: 3.3434, Perplexity: 28.3157
Epoch [1/100], Step [500/3236], Loss: 3.5281, Perplexity: 34.0588
Epoch [1/100], Step [510/3236], Loss: 3.4754, Perplexity: 32.3108
Epoch [1/100], Step [520/3236], Loss: 3.3388, Perplexity: 28.1842
Epoch [1/100], Step [530/3236], Loss: 3.4930, Perplexity: 32.8836
Epoch [1/100], Step [540/3236], Loss: 3.4979, Perplexity: 33.0464
Epoch [1/100], Step [550/3236], Loss: 3.3401, Perplexity: 28.2222
Epoch [1/100], Step [560/3236], Loss: 3.3786, Perplexity: 29.3302
Epoch [1/100], Step [570/3236], Loss: 3.4795, Perplexity: 32.4434
Epoch [1/100], Step [580/3236], Loss: 3.3291, Perplexity: 27.9139
Epoch [1/100], Step [590/3236], Loss: 3.3802, Perplexity: 29.3781
Epoch [1/100], Step [600/3236], Loss: 3.3741, Perplexity: 29.1975
Epoch [1/100], Step [610/3236], Loss: 3.3636, Perplexity: 28.8918
Epoch [1/100], Step [620/3236], Loss: 3.3077, Perplexity: 27.3215
Epoch [1/100], Step [630/3236], Loss: 3.4246, Perplexity: 30.7106
Epoch [1/100], Step [640/3236], Loss: 3.2163, Perplexity: 24.9358
Epoch [1/100], Step [650/3236], Loss: 3.0955, Perplexity: 22.0986
Epoch [1/100], Step [660/3236], Loss: 3.1617, Perplexity: 23.6114
Epoch [1/100], Step [670/3236], Loss: 3.2564, Perplexity: 25.9564
Epoch [1/100], Step [680/3236], Loss: 3.4014, Perplexity: 30.0056
Epoch [1/100], Step [690/3236], Loss: 3.5702, Perplexity: 35.5253
Epoch [1/100], Step [700/3236], Loss: 3.1463, Perplexity: 23.2505
Epoch [1/100], Step [710/3236], Loss: 3.3070, Perplexity: 27.3032
Epoch [1/100], Step [720/3236], Loss: 3.1230, Perplexity: 22.7146
Epoch [1/100], Step [730/3236], Loss: 3.1862, Perplexity: 24.1968
Epoch [1/100], Step [740/3236], Loss: 3.0828, Perplexity: 21.8188
Epoch [1/100], Step [750/3236], Loss: 3.1103, Perplexity: 22.4283
Epoch [1/100], Step [760/3236], Loss: 3.1026, Perplexity: 22.2564
Epoch [1/100], Step [770/3236], Loss: 3.1893, Perplexity: 24.2723
Epoch [1/100], Step [780/3236], Loss: 3.1485, Perplexity: 23.3018
Epoch [1/100], Step [790/3236], Loss: 3.0092, Perplexity: 20.2717
Epoch [1/100], Step [800/3236], Loss: 2.9901, Perplexity: 19.8883
Epoch [1/100], Step [810/3236], Loss: 3.0413, Perplexity: 20.9324
Epoch [1/100], Step [820/3236], Loss: 3.1033, Perplexity: 22.2720
Epoch [1/100], Step [830/3236], Loss: 3.2224, Perplexity: 25.0893
Epoch [1/100], Step [840/3236], Loss: 3.2312, Perplexity: 25.3097
Epoch [1/100], Step [850/3236], Loss: 3.2070, Perplexity: 24.7054
Epoch [1/100], Step [860/3236], Loss: 2.9997, Perplexity: 20.0788
Epoch [1/100], Step [870/3236], Loss: 3.1890, Perplexity: 24.2635
Epoch [1/100], Step [880/3236], Loss: 3.0918, Perplexity: 22.0168
Epoch [1/100], Step [890/3236], Loss: 3.1027, Perplexity: 22.2587
Epoch [1/100], Step [900/3236], Loss: 3.3560, Perplexity: 28.6746
Epoch [1/100], Step [910/3236], Loss: 2.9857, Perplexity: 19.8008
Epoch [1/100], Step [920/3236], Loss: 3.0017, Perplexity: 20.1195
Epoch [1/100], Step [930/3236], Loss: 3.0892, Perplexity: 21.9603
Epoch [1/100], Step [940/3236], Loss: 3.1313, Perplexity: 22.9026
Epoch [1/100], Step [950/3236], Loss: 3.1444, Perplexity: 23.2059
Epoch [1/100], Step [960/3236], Loss: 3.0283, Perplexity: 20.6622
Epoch [1/100], Step [970/3236], Loss: 3.0172, Perplexity: 20.4340
Epoch [1/100], Step [980/3236], Loss: 3.0369, Perplexity: 20.8411
Epoch [1/100], Step [990/3236], Loss: 2.9423, Perplexity: 18.9593
Epoch [1/100], Step [1000/3236], Loss: 2.9625, Perplexity: 19.3460
Epoch [1/100], Step [1010/3236], Loss: 2.9055, Perplexity: 18.2737
Epoch [1/100], Step [1020/3236], Loss: 2.9968, Perplexity: 20.0216
Epoch [1/100], Step [1030/3236], Loss: 3.0178, Perplexity: 20.4453
Epoch [1/100], Step [1040/3236], Loss: 2.9481, Perplexity: 19.0706
Epoch [1/100], Step [1050/3236], Loss: 2.8935, Perplexity: 18.0568
Epoch [1/100], Step [1060/3236], Loss: 3.1209, Perplexity: 22.6662
Epoch [1/100], Step [1070/3236], Loss: 2.9906, Perplexity: 19.8969
Epoch [1/100], Step [1080/3236], Loss: 3.0787, Perplexity: 21.7299
Epoch [1/100], Step [1090/3236], Loss: 3.0749, Perplexity: 21.6480
Epoch [1/100], Step [1100/3236], Loss: 2.9197, Perplexity: 18.5349
Epoch [1/100], Step [1110/3236], Loss: 3.0005, Perplexity: 20.0954
Epoch [1/100], Step [1120/3236], Loss: 3.1188, Perplexity: 22.6187
Epoch [1/100], Step [1130/3236], Loss: 2.9011, Perplexity: 18.1943
Epoch [1/100], Step [1140/3236], Loss: 3.1998, Perplexity: 24.5279
Epoch [1/100], Step [1150/3236], Loss: 2.9458, Perplexity: 19.0262
Epoch [1/100], Step [1160/3236], Loss: 2.8446, Perplexity: 17.1951
Epoch [1/100], Step [1170/3236], Loss: 2.9540, Perplexity: 19.1824
Epoch [1/100], Step [1180/3236], Loss: 3.0591, Perplexity: 21.3081
Epoch [1/100], Step [1190/3236], Loss: 2.9295, Perplexity: 18.7176
Epoch [1/100], Step [1200/3236], Loss: 3.1264, Perplexity: 22.7909
Epoch [1/100], Step [1210/3236], Loss: 2.8858, Perplexity: 17.9182
Epoch [1/100], Step [1220/3236], Loss: 2.8412, Perplexity: 17.1358
Epoch [1/100], Step [1230/3236], Loss: 2.9102, Perplexity: 18.3612
Epoch [1/100], Step [1240/3236], Loss: 2.9951, Perplexity: 19.9878
Epoch [1/100], Step [1250/3236], Loss: 2.8637, Perplexity: 17.5256
Epoch [1/100], Step [1260/3236], Loss: 3.0107, Perplexity: 20.3025
Epoch [1/100], Step [1270/3236], Loss: 3.0999, Perplexity: 22.1948
Epoch [1/100], Step [1280/3236], Loss: 2.8340, Perplexity: 17.0128
Epoch [1/100], Step [1290/3236], Loss: 2.8566, Perplexity: 17.4029
Epoch [1/100], Step [1300/3236], Loss: 2.7623, Perplexity: 15.8358
Epoch [1/100], Step [1310/3236], Loss: 2.8314, Perplexity: 16.9696
Epoch [1/100], Step [1320/3236], Loss: 3.0281, Perplexity: 20.6581
Epoch [1/100], Step [1330/3236], Loss: 2.9232, Perplexity: 18.6012
Epoch [1/100], Step [1340/3236], Loss: 3.0275, Perplexity: 20.6462
Epoch [1/100], Step [1350/3236], Loss: 2.8413, Perplexity: 17.1380
Epoch [1/100], Step [1360/3236], Loss: 2.8721, Perplexity: 17.6733
Epoch [1/100], Step [1370/3236], Loss: 2.8160, Perplexity: 16.7099
Epoch [1/100], Step [1380/3236], Loss: 2.8957, Perplexity: 18.0962
Epoch [1/100], Step [1390/3236], Loss: 2.7549, Perplexity: 15.7192
Epoch [1/100], Step [1400/3236], Loss: 2.9561, Perplexity: 19.2223
Epoch [1/100], Step [1410/3236], Loss: 3.1234, Perplexity: 22.7225
Epoch [1/100], Step [1420/3236], Loss: 2.8239, Perplexity: 16.8432
Epoch [1/100], Step [1430/3236], Loss: 2.7652, Perplexity: 15.8816
Epoch [1/100], Step [1440/3236], Loss: 2.7828, Perplexity: 16.1637
Epoch [1/100], Step [1450/3236], Loss: 2.9507, Perplexity: 19.1189
Epoch [1/100], Step [1460/3236], Loss: 2.6635, Perplexity: 14.3464
Epoch [1/100], Step [1470/3236], Loss: 3.1208, Perplexity: 22.6645
Epoch [1/100], Step [1480/3236], Loss: 2.9228, Perplexity: 18.5938
Epoch [1/100], Step [1490/3236], Loss: 2.7883, Perplexity: 16.2529
Epoch [1/100], Step [1500/3236], Loss: 2.8436, Perplexity: 17.1766
Epoch [1/100], Step [1510/3236], Loss: 2.7079, Perplexity: 14.9981
Epoch [1/100], Step [1520/3236], Loss: 2.9501, Perplexity: 19.1082
Epoch [1/100], Step [1530/3236], Loss: 2.8275, Perplexity: 16.9036
Epoch [1/100], Step [1540/3236], Loss: 2.9053, Perplexity: 18.2699
Epoch [1/100], Step [1550/3236], Loss: 2.8498, Perplexity: 17.2839
Epoch [1/100], Step [1560/3236], Loss: 2.9197, Perplexity: 18.5354
Epoch [1/100], Step [1570/3236], Loss: 2.8352, Perplexity: 17.0332
Epoch [1/100], Step [1580/3236], Loss: 2.6989, Perplexity: 14.8634
Epoch [1/100], Step [1590/3236], Loss: 2.8609, Perplexity: 17.4776
Epoch [1/100], Step [1600/3236], Loss: 3.0217, Perplexity: 20.5264
Epoch [1/100], Step [1610/3236], Loss: 2.8533, Perplexity: 17.3452
Epoch [1/100], Step [1620/3236], Loss: 2.9031, Perplexity: 18.2298
Epoch [1/100], Step [1630/3236], Loss: 2.8517, Perplexity: 17.3170
Epoch [1/100], Step [1640/3236], Loss: 2.9230, Perplexity: 18.5969
Epoch [1/100], Step [1650/3236], Loss: 2.7405, Perplexity: 15.4948
Epoch [1/100], Step [1660/3236], Loss: 2.7318, Perplexity: 15.3599
Epoch [1/100], Step [1670/3236], Loss: 2.7655, Perplexity: 15.8876
Epoch [1/100], Step [1680/3236], Loss: 2.8397, Perplexity: 17.1108
Epoch [1/100], Step [1690/3236], Loss: 2.6517, Perplexity: 14.1781
Epoch [1/100], Step [1700/3236], Loss: 2.7707, Perplexity: 15.9705
Epoch [1/100], Step [1710/3236], Loss: 2.6989, Perplexity: 14.8639
Epoch [1/100], Step [1720/3236], Loss: 2.8086, Perplexity: 16.5863
Epoch [1/100], Step [1730/3236], Loss: 2.8158, Perplexity: 16.7066
Epoch [1/100], Step [1740/3236], Loss: 2.9190, Perplexity: 18.5219
Epoch [1/100], Step [1750/3236], Loss: 2.8256, Perplexity: 16.8707
Epoch [1/100], Step [1760/3236], Loss: 2.7076, Perplexity: 14.9933
Epoch [1/100], Step [1770/3236], Loss: 2.7863, Perplexity: 16.2202
Epoch [1/100], Step [1780/3236], Loss: 2.7460, Perplexity: 15.5806
Epoch [1/100], Step [1790/3236], Loss: 2.6668, Perplexity: 14.3936
Epoch [1/100], Step [1800/3236], Loss: 2.9022, Perplexity: 18.2148
Epoch [1/100], Step [1810/3236], Loss: 2.9513, Perplexity: 19.1311
Epoch [1/100], Step [1820/3236], Loss: 2.6550, Perplexity: 14.2246
Epoch [1/100], Step [1830/3236], Loss: 2.9175, Perplexity: 18.4948
Epoch [1/100], Step [1840/3236], Loss: 2.6591, Perplexity: 14.2837
Epoch [1/100], Step [1850/3236], Loss: 2.5983, Perplexity: 13.4412
Epoch [1/100], Step [1860/3236], Loss: 2.6999, Perplexity: 14.8782
Epoch [1/100], Step [1870/3236], Loss: 2.8408, Perplexity: 17.1287
Epoch [1/100], Step [1880/3236], Loss: 2.7800, Perplexity: 16.1187
Epoch [1/100], Step [1890/3236], Loss: 2.7982, Perplexity: 16.4145
Epoch [1/100], Step [1900/3236], Loss: 2.5844, Perplexity: 13.2560
Epoch [1/100], Step [1910/3236], Loss: 2.7505, Perplexity: 15.6500
Epoch [1/100], Step [1920/3236], Loss: 2.7709, Perplexity: 15.9738
Epoch [1/100], Step [1930/3236], Loss: 2.5853, Perplexity: 13.2669
Epoch [1/100], Step [1940/3236], Loss: 2.6607, Perplexity: 14.3062
Epoch [1/100], Step [1950/3236], Loss: 2.7824, Perplexity: 16.1570
Epoch [1/100], Step [1960/3236], Loss: 2.6518, Perplexity: 14.1796
Epoch [1/100], Step [1970/3236], Loss: 2.7569, Perplexity: 15.7510
Epoch [1/100], Step [1980/3236], Loss: 2.8922, Perplexity: 18.0336
Epoch [1/100], Step [1990/3236], Loss: 2.7228, Perplexity: 15.2227
Epoch [1/100], Step [2000/3236], Loss: 2.7857, Perplexity: 16.2106
Epoch [1/100], Step [2010/3236], Loss: 2.8696, Perplexity: 17.6308
Epoch [1/100], Step [2020/3236], Loss: 2.5505, Perplexity: 12.8134
Epoch [1/100], Step [2030/3236], Loss: 2.6159, Perplexity: 13.6799
Epoch [1/100], Step [2040/3236], Loss: 2.7744, Perplexity: 16.0284
Epoch [1/100], Step [2050/3236], Loss: 2.7811, Perplexity: 16.1364
Epoch [1/100], Step [2060/3236], Loss: 2.7007, Perplexity: 14.8899
Epoch [1/100], Step [2070/3236], Loss: 2.7682, Perplexity: 15.9307
Epoch [1/100], Step [2080/3236], Loss: 2.6391, Perplexity: 14.0000
Epoch [1/100], Step [2090/3236], Loss: 2.7331, Perplexity: 15.3807
Epoch [1/100], Step [2100/3236], Loss: 2.7423, Perplexity: 15.5221
Epoch [1/100], Step [2110/3236], Loss: 2.7627, Perplexity: 15.8428
Epoch [1/100], Step [2120/3236], Loss: 2.8468, Perplexity: 17.2326
Epoch [1/100], Step [2130/3236], Loss: 2.7165, Perplexity: 15.1271
Epoch [1/100], Step [2140/3236], Loss: 2.7935, Perplexity: 16.3380
Epoch [1/100], Step [2150/3236], Loss: 2.7742, Perplexity: 16.0261
Epoch [1/100], Step [2160/3236], Loss: 2.6724, Perplexity: 14.4749
Epoch [1/100], Step [2170/3236], Loss: 2.7885, Perplexity: 16.2562
Epoch [1/100], Step [2180/3236], Loss: 2.8667, Perplexity: 17.5793
Epoch [1/100], Step [2190/3236], Loss: 2.5484, Perplexity: 12.7861
Epoch [1/100], Step [2200/3236], Loss: 2.6838, Perplexity: 14.6411
Epoch [1/100], Step [2210/3236], Loss: 2.7233, Perplexity: 15.2299
Epoch [1/100], Step [2220/3236], Loss: 2.8545, Perplexity: 17.3657
Epoch [1/100], Step [2230/3236], Loss: 2.8273, Perplexity: 16.8999
Epoch [1/100], Step [2240/3236], Loss: 2.7012, Perplexity: 14.8972
Epoch [1/100], Step [2250/3236], Loss: 2.6334, Perplexity: 13.9210
Epoch [1/100], Step [2260/3236], Loss: 2.8030, Perplexity: 16.4936
Epoch [1/100], Step [2270/3236], Loss: 2.7250, Perplexity: 15.2561
Epoch [1/100], Step [2280/3236], Loss: 2.6251, Perplexity: 13.8061
Epoch [1/100], Step [2290/3236], Loss: 2.7777, Perplexity: 16.0827
Epoch [1/100], Step [2300/3236], Loss: 2.7189, Perplexity: 15.1632
Epoch [1/100], Step [2310/3236], Loss: 2.8415, Perplexity: 17.1416
Epoch [1/100], Step [2320/3236], Loss: 2.7855, Perplexity: 16.2075
Epoch [1/100], Step [2330/3236], Loss: 2.6107, Perplexity: 13.6090
Epoch [1/100], Step [2340/3236], Loss: 2.7750, Perplexity: 16.0385
Epoch [1/100], Step [2350/3236], Loss: 2.5196, Perplexity: 12.4234
Epoch [1/100], Step [2360/3236], Loss: 2.7206, Perplexity: 15.1900
Epoch [1/100], Step [2370/3236], Loss: 2.6172, Perplexity: 13.6977
Epoch [1/100], Step [2380/3236], Loss: 2.9006, Perplexity: 18.1859
Epoch [1/100], Step [2390/3236], Loss: 2.7579, Perplexity: 15.7675
Epoch [1/100], Step [2400/3236], Loss: 2.5831, Perplexity: 13.2383
Epoch [1/100], Step [2410/3236], Loss: 2.8714, Perplexity: 17.6617
Epoch [1/100], Step [2420/3236], Loss: 2.5840, Perplexity: 13.2506
Epoch [1/100], Step [2430/3236], Loss: 2.9814, Perplexity: 19.7146
Epoch [1/100], Step [2440/3236], Loss: 2.6264, Perplexity: 13.8235
Epoch [1/100], Step [2450/3236], Loss: 2.6201, Perplexity: 13.7370
Epoch [1/100], Step [2460/3236], Loss: 2.6933, Perplexity: 14.7806
Epoch [1/100], Step [2470/3236], Loss: 2.5243, Perplexity: 12.4821
Epoch [1/100], Step [2480/3236], Loss: 2.8603, Perplexity: 17.4675
Epoch [1/100], Step [2490/3236], Loss: 2.6176, Perplexity: 13.7030
Epoch [1/100], Step [2500/3236], Loss: 2.6293, Perplexity: 13.8639
Epoch [1/100], Step [2510/3236], Loss: 2.5723, Perplexity: 13.0958
Epoch [1/100], Step [2520/3236], Loss: 2.6189, Perplexity: 13.7204
Epoch [1/100], Step [2530/3236], Loss: 2.6143, Perplexity: 13.6581
Epoch [1/100], Step [2540/3236], Loss: 2.8732, Perplexity: 17.6932
Epoch [1/100], Step [2550/3236], Loss: 2.8304, Perplexity: 16.9523
Epoch [1/100], Step [2560/3236], Loss: 2.5577, Perplexity: 12.9058
Epoch [1/100], Step [2570/3236], Loss: 2.5281, Perplexity: 12.5298
Epoch [1/100], Step [2580/3236], Loss: 2.5638, Perplexity: 12.9855
Epoch [1/100], Step [2590/3236], Loss: 2.4137, Perplexity: 11.1752
Epoch [1/100], Step [2600/3236], Loss: 2.5418, Perplexity: 12.7021
Epoch [1/100], Step [2610/3236], Loss: 2.6653, Perplexity: 14.3728
Epoch [1/100], Step [2620/3236], Loss: 2.7305, Perplexity: 15.3411
Epoch [1/100], Step [2630/3236], Loss: 2.7349, Perplexity: 15.4083
Epoch [1/100], Step [2640/3236], Loss: 2.8093, Perplexity: 16.5984
Epoch [1/100], Step [2650/3236], Loss: 2.7054, Perplexity: 14.9596
Epoch [1/100], Step [2660/3236], Loss: 2.6594, Perplexity: 14.2883
Epoch [1/100], Step [2670/3236], Loss: 2.5584, Perplexity: 12.9152
Epoch [1/100], Step [2680/3236], Loss: 2.3393, Perplexity: 10.3745
Epoch [1/100], Step [2690/3236], Loss: 2.7934, Perplexity: 16.3358
Epoch [1/100], Step [2700/3236], Loss: 2.7142, Perplexity: 15.0919
Epoch [1/100], Step [2710/3236], Loss: 2.7028, Perplexity: 14.9222
Epoch [1/100], Step [2720/3236], Loss: 2.5893, Perplexity: 13.3210
Epoch [1/100], Step [2730/3236], Loss: 2.6586, Perplexity: 14.2758
Epoch [1/100], Step [2740/3236], Loss: 2.6053, Perplexity: 13.5348
Epoch [1/100], Step [2750/3236], Loss: 2.8229, Perplexity: 16.8264
Epoch [1/100], Step [2760/3236], Loss: 2.5737, Perplexity: 13.1146
Epoch [1/100], Step [2770/3236], Loss: 2.6650, Perplexity: 14.3684
Epoch [1/100], Step [2780/3236], Loss: 2.7043, Perplexity: 14.9432
Epoch [1/100], Step [2790/3236], Loss: 2.7738, Perplexity: 16.0193
Epoch [1/100], Step [2800/3236], Loss: 2.8860, Perplexity: 17.9223
Epoch [1/100], Step [2810/3236], Loss: 2.6497, Perplexity: 14.1504
Epoch [1/100], Step [2820/3236], Loss: 2.5837, Perplexity: 13.2467
Epoch [1/100], Step [2830/3236], Loss: 2.8816, Perplexity: 17.8425
Epoch [1/100], Step [2840/3236], Loss: 2.6131, Perplexity: 13.6412
Epoch [1/100], Step [2850/3236], Loss: 2.7658, Perplexity: 15.8913
Epoch [1/100], Step [2860/3236], Loss: 2.5506, Perplexity: 12.8146
Epoch [1/100], Step [2870/3236], Loss: 2.6729, Perplexity: 14.4826
Epoch [1/100], Step [2880/3236], Loss: 2.7272, Perplexity: 15.2894
Epoch [1/100], Step [2890/3236], Loss: 2.7023, Perplexity: 14.9147
Epoch [1/100], Step [2900/3236], Loss: 2.5759, Perplexity: 13.1427
Epoch [1/100], Step [2910/3236], Loss: 2.8509, Perplexity: 17.3026
Epoch [1/100], Step [2920/3236], Loss: 2.5933, Perplexity: 13.3743
Epoch [1/100], Step [2930/3236], Loss: 2.6325, Perplexity: 13.9085
Epoch [1/100], Step [2940/3236], Loss: 2.6387, Perplexity: 13.9948
Epoch [1/100], Step [2950/3236], Loss: 2.6004, Perplexity: 13.4695
Epoch [1/100], Step [2960/3236], Loss: 2.8789, Perplexity: 17.7939
Epoch [1/100], Step [2970/3236], Loss: 2.7418, Perplexity: 15.5154
Epoch [1/100], Step [2980/3236], Loss: 2.5152, Perplexity: 12.3685
Epoch [1/100], Step [2990/3236], Loss: 2.8182, Perplexity: 16.7474
Epoch [1/100], Step [3000/3236], Loss: 2.6464, Perplexity: 14.1035
Epoch [1/100], Step [3010/3236], Loss: 2.5578, Perplexity: 12.9072
Epoch [1/100], Step [3020/3236], Loss: 2.5988, Perplexity: 13.4480
Epoch [1/100], Step [3030/3236], Loss: 2.6156, Perplexity: 13.6755
Epoch [1/100], Step [3040/3236], Loss: 2.6853, Perplexity: 14.6632
Epoch [1/100], Step [3050/3236], Loss: 2.5686, Perplexity: 13.0482
Epoch [1/100], Step [3060/3236], Loss: 2.7182, Perplexity: 15.1523
Epoch [1/100], Step [3070/3236], Loss: 2.6173, Perplexity: 13.6991
Epoch [1/100], Step [3080/3236], Loss: 2.7435, Perplexity: 15.5405
Epoch [1/100], Step [3090/3236], Loss: 2.4530, Perplexity: 11.6228
Epoch [1/100], Step [3100/3236], Loss: 2.4387, Perplexity: 11.4582
Epoch [1/100], Step [3110/3236], Loss: 2.6627, Perplexity: 14.3345
Epoch [1/100], Step [3120/3236], Loss: 2.5763, Perplexity: 13.1481
Epoch [1/100], Step [3130/3236], Loss: 2.7783, Perplexity: 16.0915
Epoch [1/100], Step [3140/3236], Loss: 2.6060, Perplexity: 13.5452
Epoch [1/100], Step [3150/3236], Loss: 2.6508, Perplexity: 14.1654
Epoch [1/100], Step [3160/3236], Loss: 2.5638, Perplexity: 12.9857
Epoch [1/100], Step [3170/3236], Loss: 2.7608, Perplexity: 15.8124
Epoch [1/100], Step [3180/3236], Loss: 2.6433, Perplexity: 14.0597
Epoch [1/100], Step [3190/3236], Loss: 2.6951, Perplexity: 14.8067
Epoch [1/100], Step [3200/3236], Loss: 2.6041, Perplexity: 13.5194
Epoch [1/100], Step [3210/3236], Loss: 2.6409, Perplexity: 14.0264
Epoch [1/100], Step [3220/3236], Loss: 2.7022, Perplexity: 14.9126
Epoch [1/100], Step [3230/3236], Loss: 2.5226, Perplexity: 12.4610
start evaluate ...
433998 : a baseball player is swinging at a ball
293505 : a man riding a bike down a street with a woman on a bike
437554 : a man in a suit and tie standing in a room
163970 : a truck with a large white truck on the back of it
404780 : a man is flying a kite on a beach
434078 : a group of people sitting on a boat in the water
485532 : a truck is parked in a parking lot
189364 : a zebra standing in a field next to a tree
276192 : a plate of food with a salad and a salad
78176 : a clock is shown in a room with a clock
loading annotations into memory...
Done (t=0.86s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 631312.86 tokens per second.
PTBTokenizer tokenized 53342 tokens at 615832.66 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 47922, 'guess': [48343, 43343, 38343, 33343], 'testlen': 48343, 'correct': [32036, 15060, 6173, 2473]}
('ratio:', 1.0087851091356579)
Bleu_1: 0.663
Bleu_2: 0.480
Bleu_3: 0.333
Bleu_4: 0.229
computing METEOR score...
METEOR: 0.215
computing Rouge score...
ROUGE_L: 0.483
computing CIDEr score...
CIDEr: 0.704
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.7 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.9 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].
Threads( StanfordCoreNLP ) [45.917 seconds]
SPICE evaluation took: 1.206 min
SPICE: 0.141
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [2/100], Step [10/3236], Loss: 2.5414, Perplexity: 12.6978
Epoch [2/100], Step [20/3236], Loss: 2.5107, Perplexity: 12.3130
Epoch [2/100], Step [30/3236], Loss: 2.6014, Perplexity: 13.4820
Epoch [2/100], Step [40/3236], Loss: 2.5332, Perplexity: 12.5932
Epoch [2/100], Step [50/3236], Loss: 2.5163, Perplexity: 12.3823
Epoch [2/100], Step [60/3236], Loss: 2.4645, Perplexity: 11.7572
Epoch [2/100], Step [70/3236], Loss: 2.6232, Perplexity: 13.7793
Epoch [2/100], Step [80/3236], Loss: 2.3762, Perplexity: 10.7641
Epoch [2/100], Step [90/3236], Loss: 2.4821, Perplexity: 11.9664
Epoch [2/100], Step [100/3236], Loss: 2.4776, Perplexity: 11.9126
Epoch [2/100], Step [110/3236], Loss: 2.6202, Perplexity: 13.7382
Epoch [2/100], Step [120/3236], Loss: 2.6403, Perplexity: 14.0173
Epoch [2/100], Step [130/3236], Loss: 2.5797, Perplexity: 13.1931
Epoch [2/100], Step [140/3236], Loss: 2.5931, Perplexity: 13.3708
Epoch [2/100], Step [150/3236], Loss: 2.3945, Perplexity: 10.9624
Epoch [2/100], Step [160/3236], Loss: 2.5421, Perplexity: 12.7068
Epoch [2/100], Step [170/3236], Loss: 2.5261, Perplexity: 12.5053
Epoch [2/100], Step [180/3236], Loss: 2.5904, Perplexity: 13.3346
Epoch [2/100], Step [190/3236], Loss: 2.6111, Perplexity: 13.6142
Epoch [2/100], Step [200/3236], Loss: 2.5568, Perplexity: 12.8942
Epoch [2/100], Step [210/3236], Loss: 2.3811, Perplexity: 10.8165
Epoch [2/100], Step [220/3236], Loss: 2.5447, Perplexity: 12.7398
Epoch [2/100], Step [230/3236], Loss: 2.4399, Perplexity: 11.4716
Epoch [2/100], Step [240/3236], Loss: 2.7697, Perplexity: 15.9541
Epoch [2/100], Step [250/3236], Loss: 2.4865, Perplexity: 12.0193
Epoch [2/100], Step [260/3236], Loss: 2.5014, Perplexity: 12.1996
Epoch [2/100], Step [270/3236], Loss: 2.6224, Perplexity: 13.7687
Epoch [2/100], Step [280/3236], Loss: 2.4451, Perplexity: 11.5313
Epoch [2/100], Step [290/3236], Loss: 2.6061, Perplexity: 13.5456
Epoch [2/100], Step [300/3236], Loss: 2.3911, Perplexity: 10.9250
Epoch [2/100], Step [310/3236], Loss: 2.5132, Perplexity: 12.3439
Epoch [2/100], Step [320/3236], Loss: 2.3995, Perplexity: 11.0178
Epoch [2/100], Step [330/3236], Loss: 2.6310, Perplexity: 13.8870
Epoch [2/100], Step [340/3236], Loss: 2.6033, Perplexity: 13.5077
Epoch [2/100], Step [350/3236], Loss: 2.5961, Perplexity: 13.4115
Epoch [2/100], Step [360/3236], Loss: 2.5799, Perplexity: 13.1954
Epoch [2/100], Step [370/3236], Loss: 2.4680, Perplexity: 11.7993
Epoch [2/100], Step [380/3236], Loss: 2.4889, Perplexity: 12.0483
Epoch [2/100], Step [390/3236], Loss: 2.4034, Perplexity: 11.0606
Epoch [2/100], Step [400/3236], Loss: 2.5817, Perplexity: 13.2190
Epoch [2/100], Step [410/3236], Loss: 2.5341, Perplexity: 12.6052
Epoch [2/100], Step [420/3236], Loss: 2.5379, Perplexity: 12.6527
Epoch [2/100], Step [430/3236], Loss: 2.4270, Perplexity: 11.3247
Epoch [2/100], Step [440/3236], Loss: 2.3826, Perplexity: 10.8328
Epoch [2/100], Step [450/3236], Loss: 2.5427, Perplexity: 12.7140
Epoch [2/100], Step [460/3236], Loss: 2.5386, Perplexity: 12.6618
Epoch [2/100], Step [470/3236], Loss: 2.3485, Perplexity: 10.4698
Epoch [2/100], Step [480/3236], Loss: 2.3944, Perplexity: 10.9620
Epoch [2/100], Step [490/3236], Loss: 2.5502, Perplexity: 12.8099
Epoch [2/100], Step [500/3236], Loss: 2.5506, Perplexity: 12.8154
Epoch [2/100], Step [510/3236], Loss: 2.5031, Perplexity: 12.2206
Epoch [2/100], Step [520/3236], Loss: 2.5728, Perplexity: 13.1027
Epoch [2/100], Step [530/3236], Loss: 2.4913, Perplexity: 12.0775
Epoch [2/100], Step [540/3236], Loss: 2.5388, Perplexity: 12.6642
Epoch [2/100], Step [550/3236], Loss: 2.6049, Perplexity: 13.5298
Epoch [2/100], Step [560/3236], Loss: 2.6148, Perplexity: 13.6642
Epoch [2/100], Step [570/3236], Loss: 2.4920, Perplexity: 12.0856
Epoch [2/100], Step [580/3236], Loss: 2.4313, Perplexity: 11.3733
Epoch [2/100], Step [590/3236], Loss: 2.5275, Perplexity: 12.5222
Epoch [2/100], Step [600/3236], Loss: 2.4416, Perplexity: 11.4915
Epoch [2/100], Step [610/3236], Loss: 2.3694, Perplexity: 10.6906
Epoch [2/100], Step [620/3236], Loss: 2.5072, Perplexity: 12.2711
Epoch [2/100], Step [630/3236], Loss: 2.5787, Perplexity: 13.1799
Epoch [2/100], Step [640/3236], Loss: 2.4483, Perplexity: 11.5692
Epoch [2/100], Step [650/3236], Loss: 2.3957, Perplexity: 10.9763
Epoch [2/100], Step [660/3236], Loss: 2.4576, Perplexity: 11.6772
Epoch [2/100], Step [670/3236], Loss: 2.6970, Perplexity: 14.8353
Epoch [2/100], Step [680/3236], Loss: 2.5114, Perplexity: 12.3219
Epoch [2/100], Step [690/3236], Loss: 2.3421, Perplexity: 10.4034
Epoch [2/100], Step [700/3236], Loss: 2.4799, Perplexity: 11.9405
Epoch [2/100], Step [710/3236], Loss: 2.4473, Perplexity: 11.5568
Epoch [2/100], Step [720/3236], Loss: 2.5315, Perplexity: 12.5721
Epoch [2/100], Step [730/3236], Loss: 2.4928, Perplexity: 12.0952
Epoch [2/100], Step [740/3236], Loss: 2.4877, Perplexity: 12.0338
Epoch [2/100], Step [750/3236], Loss: 2.5488, Perplexity: 12.7916
Epoch [2/100], Step [760/3236], Loss: 2.6022, Perplexity: 13.4939
Epoch [2/100], Step [770/3236], Loss: 2.5250, Perplexity: 12.4904
Epoch [2/100], Step [780/3236], Loss: 2.3541, Perplexity: 10.5282
Epoch [2/100], Step [790/3236], Loss: 2.4961, Perplexity: 12.1345
Epoch [2/100], Step [800/3236], Loss: 2.5607, Perplexity: 12.9452
Epoch [2/100], Step [810/3236], Loss: 2.4107, Perplexity: 11.1422
Epoch [2/100], Step [820/3236], Loss: 2.5105, Perplexity: 12.3113
Epoch [2/100], Step [830/3236], Loss: 2.5450, Perplexity: 12.7429
Epoch [2/100], Step [840/3236], Loss: 2.4299, Perplexity: 11.3576
Epoch [2/100], Step [850/3236], Loss: 2.4337, Perplexity: 11.4008
Epoch [2/100], Step [860/3236], Loss: 2.5534, Perplexity: 12.8506
Epoch [2/100], Step [870/3236], Loss: 2.5766, Perplexity: 13.1528
Epoch [2/100], Step [880/3236], Loss: 2.4549, Perplexity: 11.6453
Epoch [2/100], Step [890/3236], Loss: 2.4775, Perplexity: 11.9109
Epoch [2/100], Step [900/3236], Loss: 2.3720, Perplexity: 10.7185
Epoch [2/100], Step [910/3236], Loss: 2.3851, Perplexity: 10.8599
Epoch [2/100], Step [920/3236], Loss: 2.3305, Perplexity: 10.2827
Epoch [2/100], Step [930/3236], Loss: 2.5939, Perplexity: 13.3816
Epoch [2/100], Step [940/3236], Loss: 2.3649, Perplexity: 10.6431
Epoch [2/100], Step [950/3236], Loss: 2.4724, Perplexity: 11.8512
Epoch [2/100], Step [960/3236], Loss: 2.5203, Perplexity: 12.4320
Epoch [2/100], Step [970/3236], Loss: 2.5239, Perplexity: 12.4767
Epoch [2/100], Step [980/3236], Loss: 2.5725, Perplexity: 13.0987
Epoch [2/100], Step [990/3236], Loss: 2.3844, Perplexity: 10.8524
Epoch [2/100], Step [1000/3236], Loss: 2.4005, Perplexity: 11.0285
Epoch [2/100], Step [1010/3236], Loss: 2.3992, Perplexity: 11.0141
Epoch [2/100], Step [1020/3236], Loss: 2.3182, Perplexity: 10.1576
Epoch [2/100], Step [1030/3236], Loss: 2.4597, Perplexity: 11.7011
Epoch [2/100], Step [1040/3236], Loss: 2.5015, Perplexity: 12.2007
Epoch [2/100], Step [1050/3236], Loss: 2.5447, Perplexity: 12.7398
Epoch [2/100], Step [1060/3236], Loss: 2.5159, Perplexity: 12.3783
Epoch [2/100], Step [1070/3236], Loss: 2.3685, Perplexity: 10.6813
Epoch [2/100], Step [1080/3236], Loss: 2.3411, Perplexity: 10.3926
Epoch [2/100], Step [1090/3236], Loss: 2.4359, Perplexity: 11.4265
Epoch [2/100], Step [1100/3236], Loss: 2.5189, Perplexity: 12.4151
Epoch [2/100], Step [1110/3236], Loss: 2.5897, Perplexity: 13.3251
Epoch [2/100], Step [1120/3236], Loss: 2.5948, Perplexity: 13.3942
Epoch [2/100], Step [1130/3236], Loss: 2.5174, Perplexity: 12.3959
Epoch [2/100], Step [1140/3236], Loss: 2.4424, Perplexity: 11.5004
Epoch [2/100], Step [1150/3236], Loss: 2.6076, Perplexity: 13.5668
Epoch [2/100], Step [1160/3236], Loss: 2.4186, Perplexity: 11.2297
Epoch [2/100], Step [1170/3236], Loss: 2.4768, Perplexity: 11.9034
Epoch [2/100], Step [1180/3236], Loss: 2.3135, Perplexity: 10.1096
Epoch [2/100], Step [1190/3236], Loss: 2.5673, Perplexity: 13.0303
Epoch [2/100], Step [1200/3236], Loss: 2.5831, Perplexity: 13.2376
Epoch [2/100], Step [1210/3236], Loss: 2.5154, Perplexity: 12.3716
Epoch [2/100], Step [1220/3236], Loss: 2.4568, Perplexity: 11.6680
Epoch [2/100], Step [1230/3236], Loss: 2.3340, Perplexity: 10.3195
Epoch [2/100], Step [1240/3236], Loss: 2.3631, Perplexity: 10.6241
Epoch [2/100], Step [1250/3236], Loss: 2.3787, Perplexity: 10.7913
Epoch [2/100], Step [1260/3236], Loss: 2.3850, Perplexity: 10.8593
Epoch [2/100], Step [1270/3236], Loss: 2.7206, Perplexity: 15.1897
Epoch [2/100], Step [1280/3236], Loss: 2.5783, Perplexity: 13.1744
Epoch [2/100], Step [1290/3236], Loss: 2.5182, Perplexity: 12.4059
Epoch [2/100], Step [1300/3236], Loss: 2.5690, Perplexity: 13.0528
Epoch [2/100], Step [1310/3236], Loss: 2.6124, Perplexity: 13.6313
Epoch [2/100], Step [1320/3236], Loss: 2.3658, Perplexity: 10.6524
Epoch [2/100], Step [1330/3236], Loss: 2.5545, Perplexity: 12.8648
Epoch [2/100], Step [1340/3236], Loss: 2.3870, Perplexity: 10.8803
Epoch [2/100], Step [1350/3236], Loss: 2.4196, Perplexity: 11.2413
Epoch [2/100], Step [1360/3236], Loss: 2.5868, Perplexity: 13.2868
Epoch [2/100], Step [1370/3236], Loss: 2.5620, Perplexity: 12.9613
Epoch [2/100], Step [1380/3236], Loss: 2.3327, Perplexity: 10.3057
Epoch [2/100], Step [1390/3236], Loss: 2.5308, Perplexity: 12.5638
Epoch [2/100], Step [1400/3236], Loss: 2.4789, Perplexity: 11.9277
Epoch [2/100], Step [1410/3236], Loss: 2.5454, Perplexity: 12.7485
Epoch [2/100], Step [1420/3236], Loss: 2.4792, Perplexity: 11.9317
Epoch [2/100], Step [1430/3236], Loss: 2.3473, Perplexity: 10.4574
Epoch [2/100], Step [1440/3236], Loss: 2.4802, Perplexity: 11.9438
Epoch [2/100], Step [1450/3236], Loss: 2.4971, Perplexity: 12.1478
Epoch [2/100], Step [1460/3236], Loss: 2.7328, Perplexity: 15.3763
Epoch [2/100], Step [1470/3236], Loss: 2.4154, Perplexity: 11.1945
Epoch [2/100], Step [1480/3236], Loss: 2.5586, Perplexity: 12.9180
Epoch [2/100], Step [1490/3236], Loss: 2.6679, Perplexity: 14.4104
Epoch [2/100], Step [1500/3236], Loss: 2.3571, Perplexity: 10.5605
Epoch [2/100], Step [1510/3236], Loss: 2.5300, Perplexity: 12.5540
Epoch [2/100], Step [1520/3236], Loss: 2.3052, Perplexity: 10.0259
Epoch [2/100], Step [1530/3236], Loss: 2.4554, Perplexity: 11.6511
Epoch [2/100], Step [1540/3236], Loss: 2.2334, Perplexity: 9.3314
Epoch [2/100], Step [1550/3236], Loss: 2.4761, Perplexity: 11.8943
Epoch [2/100], Step [1560/3236], Loss: 2.5628, Perplexity: 12.9724
Epoch [2/100], Step [1570/3236], Loss: 2.3663, Perplexity: 10.6581
Epoch [2/100], Step [1580/3236], Loss: 2.4470, Perplexity: 11.5532
Epoch [2/100], Step [1590/3236], Loss: 2.4578, Perplexity: 11.6792
Epoch [2/100], Step [1600/3236], Loss: 2.6337, Perplexity: 13.9250
Epoch [2/100], Step [1610/3236], Loss: 2.4796, Perplexity: 11.9363
Epoch [2/100], Step [1620/3236], Loss: 2.3958, Perplexity: 10.9767
Epoch [2/100], Step [1630/3236], Loss: 2.5393, Perplexity: 12.6707
Epoch [2/100], Step [1640/3236], Loss: 2.2732, Perplexity: 9.7104
Epoch [2/100], Step [1650/3236], Loss: 2.4607, Perplexity: 11.7131
Epoch [2/100], Step [1660/3236], Loss: 2.4190, Perplexity: 11.2352
Epoch [2/100], Step [1670/3236], Loss: 2.3659, Perplexity: 10.6537
Epoch [2/100], Step [1680/3236], Loss: 2.5319, Perplexity: 12.5774
Epoch [2/100], Step [1690/3236], Loss: 2.4215, Perplexity: 11.2633
Epoch [2/100], Step [1700/3236], Loss: 2.5419, Perplexity: 12.7044
Epoch [2/100], Step [1710/3236], Loss: 2.3673, Perplexity: 10.6689
Epoch [2/100], Step [1720/3236], Loss: 2.5824, Perplexity: 13.2289
Epoch [2/100], Step [1730/3236], Loss: 2.5080, Perplexity: 12.2807
Epoch [2/100], Step [1740/3236], Loss: 2.5576, Perplexity: 12.9042
Epoch [2/100], Step [1750/3236], Loss: 2.5751, Perplexity: 13.1328
Epoch [2/100], Step [1760/3236], Loss: 2.5169, Perplexity: 12.3905
Epoch [2/100], Step [1770/3236], Loss: 2.5177, Perplexity: 12.4006
Epoch [2/100], Step [1780/3236], Loss: 2.7236, Perplexity: 15.2347
Epoch [2/100], Step [1790/3236], Loss: 2.3935, Perplexity: 10.9515
Epoch [2/100], Step [1800/3236], Loss: 2.3874, Perplexity: 10.8849
Epoch [2/100], Step [1810/3236], Loss: 2.3633, Perplexity: 10.6260
Epoch [2/100], Step [1820/3236], Loss: 2.5354, Perplexity: 12.6218
Epoch [2/100], Step [1830/3236], Loss: 2.4660, Perplexity: 11.7753
Epoch [2/100], Step [1840/3236], Loss: 2.4072, Perplexity: 11.1033
Epoch [2/100], Step [1850/3236], Loss: 2.5513, Perplexity: 12.8233
Epoch [2/100], Step [1860/3236], Loss: 2.4586, Perplexity: 11.6888
Epoch [2/100], Step [1870/3236], Loss: 2.4824, Perplexity: 11.9701
Epoch [2/100], Step [1880/3236], Loss: 2.3992, Perplexity: 11.0140
Epoch [2/100], Step [1890/3236], Loss: 2.5492, Perplexity: 12.7964
Epoch [2/100], Step [1900/3236], Loss: 2.3997, Perplexity: 11.0200
Epoch [2/100], Step [1910/3236], Loss: 2.4872, Perplexity: 12.0281
Epoch [2/100], Step [1920/3236], Loss: 2.4358, Perplexity: 11.4249
Epoch [2/100], Step [1930/3236], Loss: 2.6117, Perplexity: 13.6222
Epoch [2/100], Step [1940/3236], Loss: 2.3467, Perplexity: 10.4512
Epoch [2/100], Step [1950/3236], Loss: 2.4587, Perplexity: 11.6893
Epoch [2/100], Step [1960/3236], Loss: 2.4553, Perplexity: 11.6497
Epoch [2/100], Step [1970/3236], Loss: 2.3750, Perplexity: 10.7505
Epoch [2/100], Step [1980/3236], Loss: 2.3658, Perplexity: 10.6521
Epoch [2/100], Step [1990/3236], Loss: 2.4903, Perplexity: 12.0646
Epoch [2/100], Step [2000/3236], Loss: 2.2798, Perplexity: 9.7751
Epoch [2/100], Step [2010/3236], Loss: 2.4770, Perplexity: 11.9059
Epoch [2/100], Step [2020/3236], Loss: 2.4156, Perplexity: 11.1970
Epoch [2/100], Step [2030/3236], Loss: 2.3673, Perplexity: 10.6681
Epoch [2/100], Step [2040/3236], Loss: 2.3433, Perplexity: 10.4153
Epoch [2/100], Step [2050/3236], Loss: 2.5715, Perplexity: 13.0856
Epoch [2/100], Step [2060/3236], Loss: 2.4277, Perplexity: 11.3333
Epoch [2/100], Step [2070/3236], Loss: 2.4848, Perplexity: 11.9989
Epoch [2/100], Step [2080/3236], Loss: 2.4740, Perplexity: 11.8695
Epoch [2/100], Step [2090/3236], Loss: 2.6146, Perplexity: 13.6620
Epoch [2/100], Step [2100/3236], Loss: 2.3456, Perplexity: 10.4394
Epoch [2/100], Step [2110/3236], Loss: 2.5994, Perplexity: 13.4560
Epoch [2/100], Step [2120/3236], Loss: 2.2687, Perplexity: 9.6672
Epoch [2/100], Step [2130/3236], Loss: 2.3857, Perplexity: 10.8662
Epoch [2/100], Step [2140/3236], Loss: 2.3795, Perplexity: 10.7998
Epoch [2/100], Step [2150/3236], Loss: 2.4441, Perplexity: 11.5207
Epoch [2/100], Step [2160/3236], Loss: 2.4236, Perplexity: 11.2864
Epoch [2/100], Step [2170/3236], Loss: 2.4348, Perplexity: 11.4130
Epoch [2/100], Step [2180/3236], Loss: 2.4380, Perplexity: 11.4496
Epoch [2/100], Step [2190/3236], Loss: 2.4175, Perplexity: 11.2177
Epoch [2/100], Step [2200/3236], Loss: 2.3149, Perplexity: 10.1238
Epoch [2/100], Step [2210/3236], Loss: 2.4802, Perplexity: 11.9433
Epoch [2/100], Step [2220/3236], Loss: 2.4892, Perplexity: 12.0517
Epoch [2/100], Step [2230/3236], Loss: 2.4200, Perplexity: 11.2460
Epoch [2/100], Step [2240/3236], Loss: 2.3511, Perplexity: 10.4971
Epoch [2/100], Step [2250/3236], Loss: 2.4085, Perplexity: 11.1167
Epoch [2/100], Step [2260/3236], Loss: 2.4699, Perplexity: 11.8218
Epoch [2/100], Step [2270/3236], Loss: 2.5120, Perplexity: 12.3299
Epoch [2/100], Step [2280/3236], Loss: 2.5144, Perplexity: 12.3591
Epoch [2/100], Step [2290/3236], Loss: 2.4276, Perplexity: 11.3317
Epoch [2/100], Step [2300/3236], Loss: 2.5315, Perplexity: 12.5721
Epoch [2/100], Step [2310/3236], Loss: 2.4401, Perplexity: 11.4736
Epoch [2/100], Step [2320/3236], Loss: 2.4605, Perplexity: 11.7105
Epoch [2/100], Step [2330/3236], Loss: 2.5141, Perplexity: 12.3556
Epoch [2/100], Step [2340/3236], Loss: 2.3118, Perplexity: 10.0928
Epoch [2/100], Step [2350/3236], Loss: 2.4672, Perplexity: 11.7891
Epoch [2/100], Step [2360/3236], Loss: 2.4712, Perplexity: 11.8361
Epoch [2/100], Step [2370/3236], Loss: 2.4335, Perplexity: 11.3987
Epoch [2/100], Step [2380/3236], Loss: 2.5179, Perplexity: 12.4026
Epoch [2/100], Step [2390/3236], Loss: 2.4732, Perplexity: 11.8600
Epoch [2/100], Step [2400/3236], Loss: 2.3600, Perplexity: 10.5906
Epoch [2/100], Step [2410/3236], Loss: 2.4670, Perplexity: 11.7872
Epoch [2/100], Step [2420/3236], Loss: 2.3940, Perplexity: 10.9571
Epoch [2/100], Step [2430/3236], Loss: 2.3606, Perplexity: 10.5971
Epoch [2/100], Step [2440/3236], Loss: 2.5639, Perplexity: 12.9867
Epoch [2/100], Step [2450/3236], Loss: 2.5114, Perplexity: 12.3224
Epoch [2/100], Step [2460/3236], Loss: 2.3836, Perplexity: 10.8439
Epoch [2/100], Step [2470/3236], Loss: 2.5499, Perplexity: 12.8055
Epoch [2/100], Step [2480/3236], Loss: 2.3414, Perplexity: 10.3956
Epoch [2/100], Step [2490/3236], Loss: 2.3627, Perplexity: 10.6197
Epoch [2/100], Step [2500/3236], Loss: 2.4960, Perplexity: 12.1333
Epoch [2/100], Step [2510/3236], Loss: 2.3480, Perplexity: 10.4646
Epoch [2/100], Step [2520/3236], Loss: 2.4422, Perplexity: 11.4985
Epoch [2/100], Step [2530/3236], Loss: 2.4015, Perplexity: 11.0402
Epoch [2/100], Step [2540/3236], Loss: 2.3906, Perplexity: 10.9200
Epoch [2/100], Step [2550/3236], Loss: 2.4073, Perplexity: 11.1037
Epoch [2/100], Step [2560/3236], Loss: 2.4391, Perplexity: 11.4627
Epoch [2/100], Step [2570/3236], Loss: 2.3201, Perplexity: 10.1764
Epoch [2/100], Step [2580/3236], Loss: 2.2840, Perplexity: 9.8163
Epoch [2/100], Step [2590/3236], Loss: 2.4650, Perplexity: 11.7631
Epoch [2/100], Step [2600/3236], Loss: 2.3835, Perplexity: 10.8426
Epoch [2/100], Step [2610/3236], Loss: 2.4106, Perplexity: 11.1407
Epoch [2/100], Step [2620/3236], Loss: 2.4616, Perplexity: 11.7241
Epoch [2/100], Step [2630/3236], Loss: 2.3417, Perplexity: 10.3988
Epoch [2/100], Step [2640/3236], Loss: 2.4356, Perplexity: 11.4223
Epoch [2/100], Step [2650/3236], Loss: 2.6062, Perplexity: 13.5477
Epoch [2/100], Step [2660/3236], Loss: 2.5184, Perplexity: 12.4093
Epoch [2/100], Step [2670/3236], Loss: 2.4372, Perplexity: 11.4412
Epoch [2/100], Step [2680/3236], Loss: 2.2527, Perplexity: 9.5135
Epoch [2/100], Step [2690/3236], Loss: 2.3011, Perplexity: 9.9855
Epoch [2/100], Step [2700/3236], Loss: 2.2639, Perplexity: 9.6203
Epoch [2/100], Step [2710/3236], Loss: 2.4674, Perplexity: 11.7917
Epoch [2/100], Step [2720/3236], Loss: 2.2556, Perplexity: 9.5410
Epoch [2/100], Step [2730/3236], Loss: 2.4546, Perplexity: 11.6412
Epoch [2/100], Step [2740/3236], Loss: 2.4048, Perplexity: 11.0765
Epoch [2/100], Step [2750/3236], Loss: 2.3763, Perplexity: 10.7647
Epoch [2/100], Step [2760/3236], Loss: 2.4832, Perplexity: 11.9801
Epoch [2/100], Step [2770/3236], Loss: 2.3913, Perplexity: 10.9276
Epoch [2/100], Step [2780/3236], Loss: 2.3673, Perplexity: 10.6689
Epoch [2/100], Step [2790/3236], Loss: 2.4658, Perplexity: 11.7729
Epoch [2/100], Step [2800/3236], Loss: 2.4467, Perplexity: 11.5505
Epoch [2/100], Step [2810/3236], Loss: 2.3496, Perplexity: 10.4814
Epoch [2/100], Step [2820/3236], Loss: 2.4587, Perplexity: 11.6893
Epoch [2/100], Step [2830/3236], Loss: 2.3790, Perplexity: 10.7944
Epoch [2/100], Step [2840/3236], Loss: 2.3656, Perplexity: 10.6500
Epoch [2/100], Step [2850/3236], Loss: 2.5565, Perplexity: 12.8904
Epoch [2/100], Step [2860/3236], Loss: 2.2497, Perplexity: 9.4846
Epoch [2/100], Step [2870/3236], Loss: 2.5065, Perplexity: 12.2622
Epoch [2/100], Step [2880/3236], Loss: 2.4371, Perplexity: 11.4402
Epoch [2/100], Step [2890/3236], Loss: 2.3611, Perplexity: 10.6023
Epoch [2/100], Step [2900/3236], Loss: 2.2604, Perplexity: 9.5866
Epoch [2/100], Step [2910/3236], Loss: 2.3671, Perplexity: 10.6669
Epoch [2/100], Step [2920/3236], Loss: 2.4810, Perplexity: 11.9531
Epoch [2/100], Step [2930/3236], Loss: 2.3820, Perplexity: 10.8267
Epoch [2/100], Step [2940/3236], Loss: 2.2938, Perplexity: 9.9125
Epoch [2/100], Step [2950/3236], Loss: 2.4324, Perplexity: 11.3867
Epoch [2/100], Step [2960/3236], Loss: 2.5599, Perplexity: 12.9350
Epoch [2/100], Step [2970/3236], Loss: 2.5312, Perplexity: 12.5687
Epoch [2/100], Step [2980/3236], Loss: 2.4914, Perplexity: 12.0780
Epoch [2/100], Step [2990/3236], Loss: 2.3195, Perplexity: 10.1707
Epoch [2/100], Step [3000/3236], Loss: 2.6115, Perplexity: 13.6191
Epoch [2/100], Step [3010/3236], Loss: 2.3567, Perplexity: 10.5558
Epoch [2/100], Step [3020/3236], Loss: 2.4518, Perplexity: 11.6096
Epoch [2/100], Step [3030/3236], Loss: 2.3991, Perplexity: 11.0132
Epoch [2/100], Step [3040/3236], Loss: 2.4716, Perplexity: 11.8409
Epoch [2/100], Step [3050/3236], Loss: 2.2735, Perplexity: 9.7134
Epoch [2/100], Step [3060/3236], Loss: 2.5018, Perplexity: 12.2048
Epoch [2/100], Step [3070/3236], Loss: 2.5007, Perplexity: 12.1906
Epoch [2/100], Step [3080/3236], Loss: 2.4493, Perplexity: 11.5798
Epoch [2/100], Step [3090/3236], Loss: 2.3485, Perplexity: 10.4703
Epoch [2/100], Step [3100/3236], Loss: 2.3293, Perplexity: 10.2703
Epoch [2/100], Step [3110/3236], Loss: 2.4166, Perplexity: 11.2076
Epoch [2/100], Step [3120/3236], Loss: 2.4018, Perplexity: 11.0436
Epoch [2/100], Step [3130/3236], Loss: 2.3752, Perplexity: 10.7529
Epoch [2/100], Step [3140/3236], Loss: 2.4030, Perplexity: 11.0565
Epoch [2/100], Step [3150/3236], Loss: 2.5135, Perplexity: 12.3479
Epoch [2/100], Step [3160/3236], Loss: 2.3884, Perplexity: 10.8960
Epoch [2/100], Step [3170/3236], Loss: 2.4749, Perplexity: 11.8808
Epoch [2/100], Step [3180/3236], Loss: 2.4906, Perplexity: 12.0683
Epoch [2/100], Step [3190/3236], Loss: 2.4046, Perplexity: 11.0741
Epoch [2/100], Step [3200/3236], Loss: 2.4880, Perplexity: 12.0369
Epoch [2/100], Step [3210/3236], Loss: 2.3387, Perplexity: 10.3678
Epoch [2/100], Step [3220/3236], Loss: 2.3948, Perplexity: 10.9662
Epoch [2/100], Step [3230/3236], Loss: 2.3582, Perplexity: 10.5723
start evaluate ...
163601 : a small yellow and black bird sitting on a tree
465489 : a person on a snowboard in the air
87144 : a woman sitting on a bench with a cell phone
399879 : a woman and a child are playing a video game
11320 : a city street with a large building and a clock
458510 : a plate of food with a fork and a fork
189364 : a zebra standing in a field with a tree
75456 : a pizza with a pan on it and a fork
343708 : a train is parked at a station with people walking around
196660 : a man is standing on a beach with a surfboard
loading annotations into memory...
Done (t=0.91s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1053489.08 tokens per second.
PTBTokenizer tokenized 53701 tokens at 565727.90 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48225, 'guess': [48702, 43702, 38702, 33702], 'testlen': 48702, 'correct': [32599, 15593, 6538, 2751]}
('ratio:', 1.0098911353032451)
Bleu_1: 0.669
Bleu_2: 0.489
Bleu_3: 0.343
Bleu_4: 0.240
computing METEOR score...
METEOR: 0.221
computing Rouge score...
ROUGE_L: 0.490
computing CIDEr score...
CIDEr: 0.757
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.4 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [49.792 seconds]
SPICE evaluation took: 1.063 min
SPICE: 0.152
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [3/100], Step [10/3236], Loss: 2.2611, Perplexity: 9.5937
Epoch [3/100], Step [20/3236], Loss: 2.2351, Perplexity: 9.3476
Epoch [3/100], Step [30/3236], Loss: 2.3190, Perplexity: 10.1656
Epoch [3/100], Step [40/3236], Loss: 2.2875, Perplexity: 9.8502
Epoch [3/100], Step [50/3236], Loss: 2.3022, Perplexity: 9.9958
Epoch [3/100], Step [60/3236], Loss: 2.4539, Perplexity: 11.6331
Epoch [3/100], Step [70/3236], Loss: 2.2581, Perplexity: 9.5649
Epoch [3/100], Step [80/3236], Loss: 2.3615, Perplexity: 10.6073
Epoch [3/100], Step [90/3236], Loss: 2.4276, Perplexity: 11.3312
Epoch [3/100], Step [100/3236], Loss: 2.4001, Perplexity: 11.0242
Epoch [3/100], Step [110/3236], Loss: 2.3349, Perplexity: 10.3281
Epoch [3/100], Step [120/3236], Loss: 2.1888, Perplexity: 8.9247
Epoch [3/100], Step [130/3236], Loss: 2.2936, Perplexity: 9.9104
Epoch [3/100], Step [140/3236], Loss: 2.4217, Perplexity: 11.2650
Epoch [3/100], Step [150/3236], Loss: 2.2931, Perplexity: 9.9058
Epoch [3/100], Step [160/3236], Loss: 2.2864, Perplexity: 9.8398
Epoch [3/100], Step [170/3236], Loss: 2.6272, Perplexity: 13.8354
Epoch [3/100], Step [180/3236], Loss: 2.3074, Perplexity: 10.0479
Epoch [3/100], Step [190/3236], Loss: 2.2972, Perplexity: 9.9459
Epoch [3/100], Step [200/3236], Loss: 2.2653, Perplexity: 9.6341
Epoch [3/100], Step [210/3236], Loss: 2.3737, Perplexity: 10.7371
Epoch [3/100], Step [220/3236], Loss: 2.3260, Perplexity: 10.2374
Epoch [3/100], Step [230/3236], Loss: 2.2529, Perplexity: 9.5157
Epoch [3/100], Step [240/3236], Loss: 2.1726, Perplexity: 8.7809
Epoch [3/100], Step [250/3236], Loss: 2.3257, Perplexity: 10.2343
Epoch [3/100], Step [260/3236], Loss: 2.3435, Perplexity: 10.4177
Epoch [3/100], Step [270/3236], Loss: 2.4231, Perplexity: 11.2810
Epoch [3/100], Step [280/3236], Loss: 2.4058, Perplexity: 11.0872
Epoch [3/100], Step [290/3236], Loss: 2.2663, Perplexity: 9.6432
Epoch [3/100], Step [300/3236], Loss: 2.2558, Perplexity: 9.5430
Epoch [3/100], Step [310/3236], Loss: 2.3712, Perplexity: 10.7102
Epoch [3/100], Step [320/3236], Loss: 2.3666, Perplexity: 10.6609
Epoch [3/100], Step [330/3236], Loss: 2.2521, Perplexity: 9.5078
Epoch [3/100], Step [340/3236], Loss: 2.3434, Perplexity: 10.4161
Epoch [3/100], Step [350/3236], Loss: 2.4830, Perplexity: 11.9777
Epoch [3/100], Step [360/3236], Loss: 2.4141, Perplexity: 11.1793
Epoch [3/100], Step [370/3236], Loss: 2.2039, Perplexity: 9.0604
Epoch [3/100], Step [380/3236], Loss: 2.3642, Perplexity: 10.6357
Epoch [3/100], Step [390/3236], Loss: 2.2721, Perplexity: 9.6994
Epoch [3/100], Step [400/3236], Loss: 2.3429, Perplexity: 10.4114
Epoch [3/100], Step [410/3236], Loss: 2.3725, Perplexity: 10.7244
Epoch [3/100], Step [420/3236], Loss: 2.2417, Perplexity: 9.4094
Epoch [3/100], Step [430/3236], Loss: 2.2707, Perplexity: 9.6859
Epoch [3/100], Step [440/3236], Loss: 2.2302, Perplexity: 9.3014
Epoch [3/100], Step [450/3236], Loss: 2.3497, Perplexity: 10.4826
Epoch [3/100], Step [460/3236], Loss: 2.3468, Perplexity: 10.4518
Epoch [3/100], Step [470/3236], Loss: 2.4095, Perplexity: 11.1288
Epoch [3/100], Step [480/3236], Loss: 2.3314, Perplexity: 10.2928
Epoch [3/100], Step [490/3236], Loss: 2.4644, Perplexity: 11.7569
Epoch [3/100], Step [500/3236], Loss: 2.1299, Perplexity: 8.4140
Epoch [3/100], Step [510/3236], Loss: 2.4284, Perplexity: 11.3403
Epoch [3/100], Step [520/3236], Loss: 2.3525, Perplexity: 10.5119
Epoch [3/100], Step [530/3236], Loss: 2.5068, Perplexity: 12.2659
Epoch [3/100], Step [540/3236], Loss: 2.4769, Perplexity: 11.9045
Epoch [3/100], Step [550/3236], Loss: 2.3331, Perplexity: 10.3093
Epoch [3/100], Step [560/3236], Loss: 2.4520, Perplexity: 11.6111
Epoch [3/100], Step [570/3236], Loss: 2.2426, Perplexity: 9.4174
Epoch [3/100], Step [580/3236], Loss: 2.4465, Perplexity: 11.5482
Epoch [3/100], Step [590/3236], Loss: 2.1398, Perplexity: 8.4976
Epoch [3/100], Step [600/3236], Loss: 2.3088, Perplexity: 10.0624
Epoch [3/100], Step [610/3236], Loss: 2.2723, Perplexity: 9.7014
Epoch [3/100], Step [620/3236], Loss: 2.4165, Perplexity: 11.2067
Epoch [3/100], Step [630/3236], Loss: 2.3207, Perplexity: 10.1830
Epoch [3/100], Step [640/3236], Loss: 2.3117, Perplexity: 10.0918
Epoch [3/100], Step [650/3236], Loss: 2.3381, Perplexity: 10.3614
Epoch [3/100], Step [660/3236], Loss: 2.3819, Perplexity: 10.8260
Epoch [3/100], Step [670/3236], Loss: 2.2632, Perplexity: 9.6142
Epoch [3/100], Step [680/3236], Loss: 2.3155, Perplexity: 10.1298
Epoch [3/100], Step [690/3236], Loss: 2.4330, Perplexity: 11.3931
Epoch [3/100], Step [700/3236], Loss: 2.3447, Perplexity: 10.4302
Epoch [3/100], Step [710/3236], Loss: 2.2760, Perplexity: 9.7381
Epoch [3/100], Step [720/3236], Loss: 2.3053, Perplexity: 10.0274
Epoch [3/100], Step [730/3236], Loss: 2.3161, Perplexity: 10.1358
Epoch [3/100], Step [740/3236], Loss: 2.3142, Perplexity: 10.1173
Epoch [3/100], Step [750/3236], Loss: 2.2062, Perplexity: 9.0812
Epoch [3/100], Step [760/3236], Loss: 2.3772, Perplexity: 10.7745
Epoch [3/100], Step [770/3236], Loss: 2.3473, Perplexity: 10.4577
Epoch [3/100], Step [780/3236], Loss: 2.2240, Perplexity: 9.2443
Epoch [3/100], Step [790/3236], Loss: 2.3432, Perplexity: 10.4141
Epoch [3/100], Step [800/3236], Loss: 2.3750, Perplexity: 10.7515
Epoch [3/100], Step [810/3236], Loss: 2.3185, Perplexity: 10.1609
Epoch [3/100], Step [820/3236], Loss: 2.3040, Perplexity: 10.0144
Epoch [3/100], Step [830/3236], Loss: 2.3621, Perplexity: 10.6131
Epoch [3/100], Step [840/3236], Loss: 2.3519, Perplexity: 10.5060
Epoch [3/100], Step [850/3236], Loss: 2.2761, Perplexity: 9.7383
Epoch [3/100], Step [860/3236], Loss: 2.3466, Perplexity: 10.4496
Epoch [3/100], Step [870/3236], Loss: 2.2456, Perplexity: 9.4460
Epoch [3/100], Step [880/3236], Loss: 2.2378, Perplexity: 9.3731
Epoch [3/100], Step [890/3236], Loss: 2.4970, Perplexity: 12.1459
Epoch [3/100], Step [900/3236], Loss: 2.4675, Perplexity: 11.7930
Epoch [3/100], Step [910/3236], Loss: 2.2790, Perplexity: 9.7672
Epoch [3/100], Step [920/3236], Loss: 2.3643, Perplexity: 10.6369
Epoch [3/100], Step [930/3236], Loss: 2.3735, Perplexity: 10.7348
Epoch [3/100], Step [940/3236], Loss: 2.3947, Perplexity: 10.9648
Epoch [3/100], Step [950/3236], Loss: 2.2625, Perplexity: 9.6072
Epoch [3/100], Step [960/3236], Loss: 2.3379, Perplexity: 10.3599
Epoch [3/100], Step [970/3236], Loss: 2.3421, Perplexity: 10.4031
Epoch [3/100], Step [980/3236], Loss: 2.2069, Perplexity: 9.0874
Epoch [3/100], Step [990/3236], Loss: 2.3214, Perplexity: 10.1898
Epoch [3/100], Step [1000/3236], Loss: 2.3390, Perplexity: 10.3707
Epoch [3/100], Step [1010/3236], Loss: 2.3761, Perplexity: 10.7632
Epoch [3/100], Step [1020/3236], Loss: 2.2911, Perplexity: 9.8859
Epoch [3/100], Step [1030/3236], Loss: 2.4270, Perplexity: 11.3243
Epoch [3/100], Step [1040/3236], Loss: 2.3462, Perplexity: 10.4457
Epoch [3/100], Step [1050/3236], Loss: 2.2524, Perplexity: 9.5107
Epoch [3/100], Step [1060/3236], Loss: 2.2316, Perplexity: 9.3150
Epoch [3/100], Step [1070/3236], Loss: 2.3179, Perplexity: 10.1544
Epoch [3/100], Step [1080/3236], Loss: 2.1703, Perplexity: 8.7611
Epoch [3/100], Step [1090/3236], Loss: 2.3927, Perplexity: 10.9431
Epoch [3/100], Step [1100/3236], Loss: 2.2381, Perplexity: 9.3759
Epoch [3/100], Step [1110/3236], Loss: 2.3068, Perplexity: 10.0423
Epoch [3/100], Step [1120/3236], Loss: 2.1676, Perplexity: 8.7376
Epoch [3/100], Step [1130/3236], Loss: 2.2667, Perplexity: 9.6476
Epoch [3/100], Step [1140/3236], Loss: 2.1855, Perplexity: 8.8954
Epoch [3/100], Step [1150/3236], Loss: 2.3945, Perplexity: 10.9630
Epoch [3/100], Step [1160/3236], Loss: 2.3867, Perplexity: 10.8775
Epoch [3/100], Step [1170/3236], Loss: 2.4035, Perplexity: 11.0619
Epoch [3/100], Step [1180/3236], Loss: 2.4022, Perplexity: 11.0472
Epoch [3/100], Step [1190/3236], Loss: 2.4773, Perplexity: 11.9094
Epoch [3/100], Step [1200/3236], Loss: 2.2665, Perplexity: 9.6453
Epoch [3/100], Step [1210/3236], Loss: 2.2372, Perplexity: 9.3672
Epoch [3/100], Step [1220/3236], Loss: 2.2749, Perplexity: 9.7268
Epoch [3/100], Step [1230/3236], Loss: 2.3631, Perplexity: 10.6240
Epoch [3/100], Step [1240/3236], Loss: 2.2645, Perplexity: 9.6264
Epoch [3/100], Step [1250/3236], Loss: 2.3296, Perplexity: 10.2741
Epoch [3/100], Step [1260/3236], Loss: 2.3602, Perplexity: 10.5926
Epoch [3/100], Step [1270/3236], Loss: 2.4151, Perplexity: 11.1905
Epoch [3/100], Step [1280/3236], Loss: 2.2779, Perplexity: 9.7560
Epoch [3/100], Step [1290/3236], Loss: 2.3400, Perplexity: 10.3817
Epoch [3/100], Step [1300/3236], Loss: 2.3293, Perplexity: 10.2706
Epoch [3/100], Step [1310/3236], Loss: 2.3334, Perplexity: 10.3125
Epoch [3/100], Step [1320/3236], Loss: 2.2096, Perplexity: 9.1120
Epoch [3/100], Step [1330/3236], Loss: 2.3369, Perplexity: 10.3488
Epoch [3/100], Step [1340/3236], Loss: 2.3582, Perplexity: 10.5718
Epoch [3/100], Step [1350/3236], Loss: 2.3735, Perplexity: 10.7346
Epoch [3/100], Step [1360/3236], Loss: 2.2886, Perplexity: 9.8612
Epoch [3/100], Step [1370/3236], Loss: 2.2255, Perplexity: 9.2578
Epoch [3/100], Step [1380/3236], Loss: 2.3263, Perplexity: 10.2404
Epoch [3/100], Step [1390/3236], Loss: 2.1692, Perplexity: 8.7512
Epoch [3/100], Step [1400/3236], Loss: 2.2086, Perplexity: 9.1031
Epoch [3/100], Step [1410/3236], Loss: 2.3260, Perplexity: 10.2366
Epoch [3/100], Step [1420/3236], Loss: 2.3574, Perplexity: 10.5630
Epoch [3/100], Step [1430/3236], Loss: 2.0674, Perplexity: 7.9045
Epoch [3/100], Step [1440/3236], Loss: 2.4535, Perplexity: 11.6294
Epoch [3/100], Step [1450/3236], Loss: 2.3222, Perplexity: 10.1986
Epoch [3/100], Step [1460/3236], Loss: 2.3775, Perplexity: 10.7777
Epoch [3/100], Step [1470/3236], Loss: 2.2855, Perplexity: 9.8311
Epoch [3/100], Step [1480/3236], Loss: 2.2680, Perplexity: 9.6597
Epoch [3/100], Step [1490/3236], Loss: 2.3440, Perplexity: 10.4232
Epoch [3/100], Step [1500/3236], Loss: 2.3174, Perplexity: 10.1496
Epoch [3/100], Step [1510/3236], Loss: 2.2895, Perplexity: 9.8703
Epoch [3/100], Step [1520/3236], Loss: 2.2328, Perplexity: 9.3262
Epoch [3/100], Step [1530/3236], Loss: 2.4033, Perplexity: 11.0601
Epoch [3/100], Step [1540/3236], Loss: 2.2294, Perplexity: 9.2942
Epoch [3/100], Step [1550/3236], Loss: 2.2091, Perplexity: 9.1077
Epoch [3/100], Step [1560/3236], Loss: 2.3987, Perplexity: 11.0085
Epoch [3/100], Step [1570/3236], Loss: 2.3647, Perplexity: 10.6411
Epoch [3/100], Step [1580/3236], Loss: 2.2540, Perplexity: 9.5255
Epoch [3/100], Step [1590/3236], Loss: 2.3311, Perplexity: 10.2893
Epoch [3/100], Step [1600/3236], Loss: 2.2717, Perplexity: 9.6954
Epoch [3/100], Step [1610/3236], Loss: 2.1821, Perplexity: 8.8648
Epoch [3/100], Step [1620/3236], Loss: 2.3251, Perplexity: 10.2281
Epoch [3/100], Step [1630/3236], Loss: 2.2162, Perplexity: 9.1723
Epoch [3/100], Step [1640/3236], Loss: 2.3336, Perplexity: 10.3150
Epoch [3/100], Step [1650/3236], Loss: 2.2544, Perplexity: 9.5294
Epoch [3/100], Step [1660/3236], Loss: 2.4616, Perplexity: 11.7232
Epoch [3/100], Step [1670/3236], Loss: 2.2435, Perplexity: 9.4261
Epoch [3/100], Step [1680/3236], Loss: 2.4049, Perplexity: 11.0778
Epoch [3/100], Step [1690/3236], Loss: 2.2607, Perplexity: 9.5897
Epoch [3/100], Step [1700/3236], Loss: 2.3689, Perplexity: 10.6852
Epoch [3/100], Step [1710/3236], Loss: 2.2998, Perplexity: 9.9726
Epoch [3/100], Step [1720/3236], Loss: 2.4239, Perplexity: 11.2903
Epoch [3/100], Step [1730/3236], Loss: 2.5108, Perplexity: 12.3146
Epoch [3/100], Step [1740/3236], Loss: 2.4309, Perplexity: 11.3691
Epoch [3/100], Step [1750/3236], Loss: 2.3228, Perplexity: 10.2043
Epoch [3/100], Step [1760/3236], Loss: 2.2515, Perplexity: 9.5019
Epoch [3/100], Step [1770/3236], Loss: 2.2536, Perplexity: 9.5224
Epoch [3/100], Step [1780/3236], Loss: 2.1969, Perplexity: 8.9972
Epoch [3/100], Step [1790/3236], Loss: 2.4037, Perplexity: 11.0641
Epoch [3/100], Step [1800/3236], Loss: 2.3121, Perplexity: 10.0958
Epoch [3/100], Step [1810/3236], Loss: 2.2434, Perplexity: 9.4249
Epoch [3/100], Step [1820/3236], Loss: 2.4367, Perplexity: 11.4356
Epoch [3/100], Step [1830/3236], Loss: 2.3654, Perplexity: 10.6484
Epoch [3/100], Step [1840/3236], Loss: 2.2067, Perplexity: 9.0857
Epoch [3/100], Step [1850/3236], Loss: 2.3683, Perplexity: 10.6792
Epoch [3/100], Step [1860/3236], Loss: 2.4183, Perplexity: 11.2268
Epoch [3/100], Step [1870/3236], Loss: 2.3731, Perplexity: 10.7303
Epoch [3/100], Step [1880/3236], Loss: 2.2619, Perplexity: 9.6014
Epoch [3/100], Step [1890/3236], Loss: 2.3535, Perplexity: 10.5222
Epoch [3/100], Step [1900/3236], Loss: 2.2822, Perplexity: 9.7981
Epoch [3/100], Step [1910/3236], Loss: 2.4626, Perplexity: 11.7353
Epoch [3/100], Step [1920/3236], Loss: 2.3756, Perplexity: 10.7571
Epoch [3/100], Step [1930/3236], Loss: 2.2996, Perplexity: 9.9698
Epoch [3/100], Step [1940/3236], Loss: 2.3024, Perplexity: 9.9978
Epoch [3/100], Step [1950/3236], Loss: 2.1326, Perplexity: 8.4367
Epoch [3/100], Step [1960/3236], Loss: 2.3725, Perplexity: 10.7244
Epoch [3/100], Step [1970/3236], Loss: 2.2366, Perplexity: 9.3611
Epoch [3/100], Step [1980/3236], Loss: 2.2817, Perplexity: 9.7930
Epoch [3/100], Step [1990/3236], Loss: 2.1840, Perplexity: 8.8820
Epoch [3/100], Step [2000/3236], Loss: 2.2626, Perplexity: 9.6077
Epoch [3/100], Step [2010/3236], Loss: 2.3907, Perplexity: 10.9207
Epoch [3/100], Step [2020/3236], Loss: 2.2639, Perplexity: 9.6206
Epoch [3/100], Step [2030/3236], Loss: 2.1864, Perplexity: 8.9032
Epoch [3/100], Step [2040/3236], Loss: 2.3313, Perplexity: 10.2914
Epoch [3/100], Step [2050/3236], Loss: 2.0466, Perplexity: 7.7414
Epoch [3/100], Step [2060/3236], Loss: 2.2833, Perplexity: 9.8089
Epoch [3/100], Step [2070/3236], Loss: 2.4061, Perplexity: 11.0903
Epoch [3/100], Step [2080/3236], Loss: 2.3900, Perplexity: 10.9136
Epoch [3/100], Step [2090/3236], Loss: 2.2739, Perplexity: 9.7174
Epoch [3/100], Step [2100/3236], Loss: 2.2028, Perplexity: 9.0504
Epoch [3/100], Step [2110/3236], Loss: 2.4054, Perplexity: 11.0829
Epoch [3/100], Step [2120/3236], Loss: 2.3078, Perplexity: 10.0521
Epoch [3/100], Step [2130/3236], Loss: 2.2808, Perplexity: 9.7842
Epoch [3/100], Step [2140/3236], Loss: 2.2200, Perplexity: 9.2070
Epoch [3/100], Step [2150/3236], Loss: 2.2275, Perplexity: 9.2768
Epoch [3/100], Step [2160/3236], Loss: 2.1885, Perplexity: 8.9221
Epoch [3/100], Step [2170/3236], Loss: 2.2562, Perplexity: 9.5470
Epoch [3/100], Step [2180/3236], Loss: 2.3524, Perplexity: 10.5105
Epoch [3/100], Step [2190/3236], Loss: 2.2464, Perplexity: 9.4533
Epoch [3/100], Step [2200/3236], Loss: 2.3697, Perplexity: 10.6942
Epoch [3/100], Step [2210/3236], Loss: 2.4123, Perplexity: 11.1592
Epoch [3/100], Step [2220/3236], Loss: 2.2259, Perplexity: 9.2614
Epoch [3/100], Step [2230/3236], Loss: 2.3013, Perplexity: 9.9871
Epoch [3/100], Step [2240/3236], Loss: 2.2902, Perplexity: 9.8773
Epoch [3/100], Step [2250/3236], Loss: 2.4507, Perplexity: 11.5968
Epoch [3/100], Step [2260/3236], Loss: 2.1490, Perplexity: 8.5762
Epoch [3/100], Step [2270/3236], Loss: 2.2628, Perplexity: 9.6096
Epoch [3/100], Step [2280/3236], Loss: 2.2647, Perplexity: 9.6286
Epoch [3/100], Step [2290/3236], Loss: 2.3590, Perplexity: 10.5808
Epoch [3/100], Step [2300/3236], Loss: 2.2431, Perplexity: 9.4221
Epoch [3/100], Step [2310/3236], Loss: 2.2612, Perplexity: 9.5949
Epoch [3/100], Step [2320/3236], Loss: 2.3267, Perplexity: 10.2443
Epoch [3/100], Step [2330/3236], Loss: 2.2912, Perplexity: 9.8871
Epoch [3/100], Step [2340/3236], Loss: 2.3725, Perplexity: 10.7239
Epoch [3/100], Step [2350/3236], Loss: 2.3400, Perplexity: 10.3814
Epoch [3/100], Step [2360/3236], Loss: 2.3433, Perplexity: 10.4160
Epoch [3/100], Step [2370/3236], Loss: 2.1629, Perplexity: 8.6964
Epoch [3/100], Step [2380/3236], Loss: 2.4074, Perplexity: 11.1047
Epoch [3/100], Step [2390/3236], Loss: 2.4147, Perplexity: 11.1861
Epoch [3/100], Step [2400/3236], Loss: 2.3374, Perplexity: 10.3538
Epoch [3/100], Step [2410/3236], Loss: 2.3078, Perplexity: 10.0527
Epoch [3/100], Step [2420/3236], Loss: 2.4273, Perplexity: 11.3288
Epoch [3/100], Step [2430/3236], Loss: 2.3537, Perplexity: 10.5249
Epoch [3/100], Step [2440/3236], Loss: 2.3082, Perplexity: 10.0563
Epoch [3/100], Step [2450/3236], Loss: 2.2745, Perplexity: 9.7226
Epoch [3/100], Step [2460/3236], Loss: 2.2345, Perplexity: 9.3415
Epoch [3/100], Step [2470/3236], Loss: 2.3219, Perplexity: 10.1955
Epoch [3/100], Step [2480/3236], Loss: 2.2477, Perplexity: 9.4657
Epoch [3/100], Step [2490/3236], Loss: 2.2975, Perplexity: 9.9497
Epoch [3/100], Step [2500/3236], Loss: 2.2501, Perplexity: 9.4885
Epoch [3/100], Step [2510/3236], Loss: 2.4141, Perplexity: 11.1796
Epoch [3/100], Step [2520/3236], Loss: 2.1895, Perplexity: 8.9309
Epoch [3/100], Step [2530/3236], Loss: 2.2299, Perplexity: 9.2994
Epoch [3/100], Step [2540/3236], Loss: 2.1957, Perplexity: 8.9862
Epoch [3/100], Step [2550/3236], Loss: 2.3406, Perplexity: 10.3877
Epoch [3/100], Step [2560/3236], Loss: 2.5015, Perplexity: 12.2003
Epoch [3/100], Step [2570/3236], Loss: 2.2140, Perplexity: 9.1524
Epoch [3/100], Step [2580/3236], Loss: 2.2568, Perplexity: 9.5522
Epoch [3/100], Step [2590/3236], Loss: 2.3066, Perplexity: 10.0407
Epoch [3/100], Step [2600/3236], Loss: 2.2324, Perplexity: 9.3220
Epoch [3/100], Step [2610/3236], Loss: 2.3188, Perplexity: 10.1630
Epoch [3/100], Step [2620/3236], Loss: 2.3723, Perplexity: 10.7225
Epoch [3/100], Step [2630/3236], Loss: 2.2526, Perplexity: 9.5127
Epoch [3/100], Step [2640/3236], Loss: 2.2513, Perplexity: 9.5003
Epoch [3/100], Step [2650/3236], Loss: 2.4397, Perplexity: 11.4697
Epoch [3/100], Step [2660/3236], Loss: 2.4426, Perplexity: 11.5028
Epoch [3/100], Step [2670/3236], Loss: 2.3552, Perplexity: 10.5407
Epoch [3/100], Step [2680/3236], Loss: 2.2861, Perplexity: 9.8364
Epoch [3/100], Step [2690/3236], Loss: 2.1431, Perplexity: 8.5255
Epoch [3/100], Step [2700/3236], Loss: 2.2044, Perplexity: 9.0649
Epoch [3/100], Step [2710/3236], Loss: 2.3473, Perplexity: 10.4574
Epoch [3/100], Step [2720/3236], Loss: 2.2723, Perplexity: 9.7017
Epoch [3/100], Step [2730/3236], Loss: 2.2053, Perplexity: 9.0730
Epoch [3/100], Step [2740/3236], Loss: 2.3977, Perplexity: 10.9974
Epoch [3/100], Step [2750/3236], Loss: 2.2980, Perplexity: 9.9541
Epoch [3/100], Step [2760/3236], Loss: 2.4053, Perplexity: 11.0821
Epoch [3/100], Step [2770/3236], Loss: 2.2917, Perplexity: 9.8921
Epoch [3/100], Step [2780/3236], Loss: 2.2015, Perplexity: 9.0386
Epoch [3/100], Step [2790/3236], Loss: 2.1468, Perplexity: 8.5577
Epoch [3/100], Step [2800/3236], Loss: 2.2403, Perplexity: 9.3959
Epoch [3/100], Step [2810/3236], Loss: 2.3300, Perplexity: 10.2777
Epoch [3/100], Step [2820/3236], Loss: 2.1843, Perplexity: 8.8844
Epoch [3/100], Step [2830/3236], Loss: 2.2431, Perplexity: 9.4221
Epoch [3/100], Step [2840/3236], Loss: 2.3784, Perplexity: 10.7881
Epoch [3/100], Step [2850/3236], Loss: 2.3096, Perplexity: 10.0702
Epoch [3/100], Step [2860/3236], Loss: 2.4096, Perplexity: 11.1300
Epoch [3/100], Step [2870/3236], Loss: 2.2093, Perplexity: 9.1093
Epoch [3/100], Step [2880/3236], Loss: 2.4413, Perplexity: 11.4881
Epoch [3/100], Step [2890/3236], Loss: 2.2880, Perplexity: 9.8551
Epoch [3/100], Step [2900/3236], Loss: 2.2798, Perplexity: 9.7743
Epoch [3/100], Step [2910/3236], Loss: 2.1469, Perplexity: 8.5587
Epoch [3/100], Step [2920/3236], Loss: 2.4555, Perplexity: 11.6528
Epoch [3/100], Step [2930/3236], Loss: 2.2495, Perplexity: 9.4832
Epoch [3/100], Step [2940/3236], Loss: 2.2831, Perplexity: 9.8066
Epoch [3/100], Step [2950/3236], Loss: 2.3171, Perplexity: 10.1467
Epoch [3/100], Step [2960/3236], Loss: 2.1073, Perplexity: 8.2264
Epoch [3/100], Step [2970/3236], Loss: 2.2466, Perplexity: 9.4557
Epoch [3/100], Step [2980/3236], Loss: 2.2603, Perplexity: 9.5864
Epoch [3/100], Step [2990/3236], Loss: 2.3265, Perplexity: 10.2420
Epoch [3/100], Step [3000/3236], Loss: 2.1929, Perplexity: 8.9611
Epoch [3/100], Step [3010/3236], Loss: 2.2096, Perplexity: 9.1120
Epoch [3/100], Step [3020/3236], Loss: 2.4197, Perplexity: 11.2428
Epoch [3/100], Step [3030/3236], Loss: 2.3946, Perplexity: 10.9640
Epoch [3/100], Step [3040/3236], Loss: 2.2243, Perplexity: 9.2469
Epoch [3/100], Step [3050/3236], Loss: 2.2993, Perplexity: 9.9668
Epoch [3/100], Step [3060/3236], Loss: 2.4116, Perplexity: 11.1514
Epoch [3/100], Step [3070/3236], Loss: 2.3774, Perplexity: 10.7770
Epoch [3/100], Step [3080/3236], Loss: 2.3649, Perplexity: 10.6425
Epoch [3/100], Step [3090/3236], Loss: 2.2330, Perplexity: 9.3277
Epoch [3/100], Step [3100/3236], Loss: 2.1661, Perplexity: 8.7241
Epoch [3/100], Step [3110/3236], Loss: 2.4099, Perplexity: 11.1331
Epoch [3/100], Step [3120/3236], Loss: 2.4058, Perplexity: 11.0867
Epoch [3/100], Step [3130/3236], Loss: 2.3889, Perplexity: 10.9014
Epoch [3/100], Step [3140/3236], Loss: 2.2555, Perplexity: 9.5397
Epoch [3/100], Step [3150/3236], Loss: 2.3519, Perplexity: 10.5052
Epoch [3/100], Step [3160/3236], Loss: 2.2432, Perplexity: 9.4235
Epoch [3/100], Step [3170/3236], Loss: 2.2163, Perplexity: 9.1730
Epoch [3/100], Step [3180/3236], Loss: 2.1727, Perplexity: 8.7817
Epoch [3/100], Step [3190/3236], Loss: 2.2810, Perplexity: 9.7864
Epoch [3/100], Step [3200/3236], Loss: 2.3695, Perplexity: 10.6917
Epoch [3/100], Step [3210/3236], Loss: 2.3599, Perplexity: 10.5897
Epoch [3/100], Step [3220/3236], Loss: 2.2373, Perplexity: 9.3676
Epoch [3/100], Step [3230/3236], Loss: 2.2413, Perplexity: 9.4052
start evaluate ...
223766 : a horse is standing in a field near a fence
535750 : a man is walking down the street with a backpack
33325 : a woman is sitting on a bench with a dog
572499 : a baseball player is swinging a bat at a ball
495376 : a man on a snowboard is in the snow
336372 : a black car is parked in a parking lot
266579 : a person on a surfboard in the water
271681 : a woman sitting at a table with a plate of food
478386 : a truck with a trailer attached to the back of it
206907 : a baseball player is swinging a bat at a ball
loading annotations into memory...
Done (t=0.84s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1224887.83 tokens per second.
PTBTokenizer tokenized 52807 tokens at 620326.51 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 47535, 'guess': [47808, 42808, 37808, 32808], 'testlen': 47808, 'correct': [32325, 15660, 6556, 2715]}
('ratio:', 1.0057431366361418)
Bleu_1: 0.676
Bleu_2: 0.497
Bleu_3: 0.350
Bleu_4: 0.244
computing METEOR score...
METEOR: 0.221
computing Rouge score...
ROUGE_L: 0.493
computing CIDEr score...
CIDEr: 0.767
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [30.68 seconds]
SPICE evaluation took: 41.00 s
SPICE: 0.150
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [4/100], Step [10/3236], Loss: 2.2572, Perplexity: 9.5565
Epoch [4/100], Step [20/3236], Loss: 2.2714, Perplexity: 9.6928
Epoch [4/100], Step [30/3236], Loss: 2.1843, Perplexity: 8.8848
Epoch [4/100], Step [40/3236], Loss: 2.1596, Perplexity: 8.6673
Epoch [4/100], Step [50/3236], Loss: 2.0677, Perplexity: 7.9063
Epoch [4/100], Step [60/3236], Loss: 2.2987, Perplexity: 9.9610
Epoch [4/100], Step [70/3236], Loss: 2.1282, Perplexity: 8.3997
Epoch [4/100], Step [80/3236], Loss: 2.2162, Perplexity: 9.1724
Epoch [4/100], Step [90/3236], Loss: 2.1790, Perplexity: 8.8372
Epoch [4/100], Step [100/3236], Loss: 2.2327, Perplexity: 9.3250
Epoch [4/100], Step [110/3236], Loss: 2.3544, Perplexity: 10.5318
Epoch [4/100], Step [120/3236], Loss: 2.1595, Perplexity: 8.6671
Epoch [4/100], Step [130/3236], Loss: 2.1276, Perplexity: 8.3950
Epoch [4/100], Step [140/3236], Loss: 1.9444, Perplexity: 6.9892
Epoch [4/100], Step [150/3236], Loss: 2.3176, Perplexity: 10.1510
Epoch [4/100], Step [160/3236], Loss: 2.2140, Perplexity: 9.1521
Epoch [4/100], Step [170/3236], Loss: 2.1498, Perplexity: 8.5830
Epoch [4/100], Step [180/3236], Loss: 2.2450, Perplexity: 9.4408
Epoch [4/100], Step [190/3236], Loss: 2.3081, Perplexity: 10.0554
Epoch [4/100], Step [200/3236], Loss: 2.1413, Perplexity: 8.5109
Epoch [4/100], Step [210/3236], Loss: 2.1052, Perplexity: 8.2087
Epoch [4/100], Step [220/3236], Loss: 2.3079, Perplexity: 10.0529
Epoch [4/100], Step [230/3236], Loss: 2.0844, Perplexity: 8.0396
Epoch [4/100], Step [240/3236], Loss: 2.3673, Perplexity: 10.6685
Epoch [4/100], Step [250/3236], Loss: 2.1934, Perplexity: 8.9659
Epoch [4/100], Step [260/3236], Loss: 2.3015, Perplexity: 9.9897
Epoch [4/100], Step [270/3236], Loss: 2.1591, Perplexity: 8.6636
Epoch [4/100], Step [280/3236], Loss: 2.2316, Perplexity: 9.3146
Epoch [4/100], Step [290/3236], Loss: 2.1290, Perplexity: 8.4063
Epoch [4/100], Step [300/3236], Loss: 2.1379, Perplexity: 8.4812
Epoch [4/100], Step [310/3236], Loss: 2.2387, Perplexity: 9.3816
Epoch [4/100], Step [320/3236], Loss: 2.2206, Perplexity: 9.2130
Epoch [4/100], Step [330/3236], Loss: 2.2213, Perplexity: 9.2190
Epoch [4/100], Step [340/3236], Loss: 2.2395, Perplexity: 9.3889
Epoch [4/100], Step [350/3236], Loss: 2.2087, Perplexity: 9.1036
Epoch [4/100], Step [360/3236], Loss: 2.2817, Perplexity: 9.7934
Epoch [4/100], Step [370/3236], Loss: 2.3289, Perplexity: 10.2663
Epoch [4/100], Step [380/3236], Loss: 2.2403, Perplexity: 9.3966
Epoch [4/100], Step [390/3236], Loss: 2.0962, Perplexity: 8.1348
Epoch [4/100], Step [400/3236], Loss: 2.1082, Perplexity: 8.2332
Epoch [4/100], Step [410/3236], Loss: 2.2245, Perplexity: 9.2487
Epoch [4/100], Step [420/3236], Loss: 2.2151, Perplexity: 9.1627
Epoch [4/100], Step [430/3236], Loss: 2.1925, Perplexity: 8.9574
Epoch [4/100], Step [440/3236], Loss: 2.3161, Perplexity: 10.1365
Epoch [4/100], Step [450/3236], Loss: 2.1677, Perplexity: 8.7381
Epoch [4/100], Step [460/3236], Loss: 2.2701, Perplexity: 9.6803
Epoch [4/100], Step [470/3236], Loss: 2.2439, Perplexity: 9.4299
Epoch [4/100], Step [480/3236], Loss: 2.0677, Perplexity: 7.9065
Epoch [4/100], Step [490/3236], Loss: 2.2778, Perplexity: 9.7548
Epoch [4/100], Step [500/3236], Loss: 2.1750, Perplexity: 8.8025
Epoch [4/100], Step [510/3236], Loss: 2.1592, Perplexity: 8.6642
Epoch [4/100], Step [520/3236], Loss: 2.3570, Perplexity: 10.5596
Epoch [4/100], Step [530/3236], Loss: 2.1714, Perplexity: 8.7706
Epoch [4/100], Step [540/3236], Loss: 2.2279, Perplexity: 9.2801
Epoch [4/100], Step [550/3236], Loss: 2.3775, Perplexity: 10.7778
Epoch [4/100], Step [560/3236], Loss: 2.0410, Perplexity: 7.6984
Epoch [4/100], Step [570/3236], Loss: 2.3500, Perplexity: 10.4852
Epoch [4/100], Step [580/3236], Loss: 2.1250, Perplexity: 8.3727
Epoch [4/100], Step [590/3236], Loss: 2.0304, Perplexity: 7.6174
Epoch [4/100], Step [600/3236], Loss: 2.1502, Perplexity: 8.5865
Epoch [4/100], Step [610/3236], Loss: 2.3050, Perplexity: 10.0239
Epoch [4/100], Step [620/3236], Loss: 2.2656, Perplexity: 9.6365
Epoch [4/100], Step [630/3236], Loss: 2.0921, Perplexity: 8.1015
Epoch [4/100], Step [640/3236], Loss: 2.0553, Perplexity: 7.8089
Epoch [4/100], Step [650/3236], Loss: 2.2278, Perplexity: 9.2791
Epoch [4/100], Step [660/3236], Loss: 2.2488, Perplexity: 9.4762
Epoch [4/100], Step [670/3236], Loss: 2.2839, Perplexity: 9.8148
Epoch [4/100], Step [680/3236], Loss: 2.0932, Perplexity: 8.1106
Epoch [4/100], Step [690/3236], Loss: 2.1415, Perplexity: 8.5121
Epoch [4/100], Step [700/3236], Loss: 2.2049, Perplexity: 9.0691
Epoch [4/100], Step [710/3236], Loss: 2.1447, Perplexity: 8.5397
Epoch [4/100], Step [720/3236], Loss: 2.1743, Perplexity: 8.7961
Epoch [4/100], Step [730/3236], Loss: 2.2069, Perplexity: 9.0874
Epoch [4/100], Step [740/3236], Loss: 2.2248, Perplexity: 9.2519
Epoch [4/100], Step [750/3236], Loss: 2.2628, Perplexity: 9.6097
Epoch [4/100], Step [760/3236], Loss: 2.1880, Perplexity: 8.9175
Epoch [4/100], Step [770/3236], Loss: 2.2610, Perplexity: 9.5931
Epoch [4/100], Step [780/3236], Loss: 2.2026, Perplexity: 9.0488
Epoch [4/100], Step [790/3236], Loss: 2.1682, Perplexity: 8.7425
Epoch [4/100], Step [800/3236], Loss: 2.2738, Perplexity: 9.7164
Epoch [4/100], Step [810/3236], Loss: 1.9778, Perplexity: 7.2269
Epoch [4/100], Step [820/3236], Loss: 2.1504, Perplexity: 8.5880
Epoch [4/100], Step [830/3236], Loss: 2.1689, Perplexity: 8.7489
Epoch [4/100], Step [840/3236], Loss: 2.1542, Perplexity: 8.6207
Epoch [4/100], Step [850/3236], Loss: 2.2353, Perplexity: 9.3490
Epoch [4/100], Step [860/3236], Loss: 2.2563, Perplexity: 9.5473
Epoch [4/100], Step [870/3236], Loss: 2.1982, Perplexity: 9.0090
Epoch [4/100], Step [880/3236], Loss: 2.2481, Perplexity: 9.4699
Epoch [4/100], Step [890/3236], Loss: 2.1803, Perplexity: 8.8490
Epoch [4/100], Step [900/3236], Loss: 2.1725, Perplexity: 8.7803
Epoch [4/100], Step [910/3236], Loss: 2.3220, Perplexity: 10.1958
Epoch [4/100], Step [920/3236], Loss: 2.1809, Perplexity: 8.8541
Epoch [4/100], Step [930/3236], Loss: 2.3763, Perplexity: 10.7655
Epoch [4/100], Step [940/3236], Loss: 2.2702, Perplexity: 9.6818
Epoch [4/100], Step [950/3236], Loss: 2.2112, Perplexity: 9.1267
Epoch [4/100], Step [960/3236], Loss: 2.2571, Perplexity: 9.5556
Epoch [4/100], Step [970/3236], Loss: 2.1309, Perplexity: 8.4221
Epoch [4/100], Step [980/3236], Loss: 2.2194, Perplexity: 9.2021
Epoch [4/100], Step [990/3236], Loss: 2.3516, Perplexity: 10.5019
Epoch [4/100], Step [1000/3236], Loss: 2.2438, Perplexity: 9.4288
Epoch [4/100], Step [1010/3236], Loss: 2.2115, Perplexity: 9.1295
Epoch [4/100], Step [1020/3236], Loss: 2.2607, Perplexity: 9.5901
Epoch [4/100], Step [1030/3236], Loss: 2.2605, Perplexity: 9.5878
Epoch [4/100], Step [1040/3236], Loss: 2.3576, Perplexity: 10.5651
Epoch [4/100], Step [1050/3236], Loss: 2.2149, Perplexity: 9.1608
Epoch [4/100], Step [1060/3236], Loss: 2.2263, Perplexity: 9.2659
Epoch [4/100], Step [1070/3236], Loss: 2.1821, Perplexity: 8.8649
Epoch [4/100], Step [1080/3236], Loss: 2.2192, Perplexity: 9.1995
Epoch [4/100], Step [1090/3236], Loss: 2.1030, Perplexity: 8.1904
Epoch [4/100], Step [1100/3236], Loss: 2.2723, Perplexity: 9.7013
Epoch [4/100], Step [1110/3236], Loss: 2.2083, Perplexity: 9.1005
Epoch [4/100], Step [1120/3236], Loss: 2.2248, Perplexity: 9.2517
Epoch [4/100], Step [1130/3236], Loss: 2.1446, Perplexity: 8.5387
Epoch [4/100], Step [1140/3236], Loss: 2.2066, Perplexity: 9.0851
Epoch [4/100], Step [1150/3236], Loss: 2.2333, Perplexity: 9.3307
Epoch [4/100], Step [1160/3236], Loss: 2.2399, Perplexity: 9.3921
Epoch [4/100], Step [1170/3236], Loss: 2.1389, Perplexity: 8.4901
Epoch [4/100], Step [1180/3236], Loss: 2.2228, Perplexity: 9.2332
Epoch [4/100], Step [1190/3236], Loss: 2.2211, Perplexity: 9.2173
Epoch [4/100], Step [1200/3236], Loss: 2.2970, Perplexity: 9.9445
Epoch [4/100], Step [1210/3236], Loss: 2.1314, Perplexity: 8.4263
Epoch [4/100], Step [1220/3236], Loss: 2.1898, Perplexity: 8.9330
Epoch [4/100], Step [1230/3236], Loss: 2.2634, Perplexity: 9.6156
Epoch [4/100], Step [1240/3236], Loss: 2.1690, Perplexity: 8.7493
Epoch [4/100], Step [1250/3236], Loss: 2.2026, Perplexity: 9.0481
Epoch [4/100], Step [1260/3236], Loss: 2.2787, Perplexity: 9.7636
Epoch [4/100], Step [1270/3236], Loss: 2.1384, Perplexity: 8.4856
Epoch [4/100], Step [1280/3236], Loss: 2.2707, Perplexity: 9.6861
Epoch [4/100], Step [1290/3236], Loss: 2.1778, Perplexity: 8.8266
Epoch [4/100], Step [1300/3236], Loss: 2.4557, Perplexity: 11.6549
Epoch [4/100], Step [1310/3236], Loss: 2.1115, Perplexity: 8.2604
Epoch [4/100], Step [1320/3236], Loss: 2.3437, Perplexity: 10.4197
Epoch [4/100], Step [1330/3236], Loss: 2.3745, Perplexity: 10.7460
Epoch [4/100], Step [1340/3236], Loss: 2.1044, Perplexity: 8.2025
Epoch [4/100], Step [1350/3236], Loss: 2.2149, Perplexity: 9.1607
Epoch [4/100], Step [1360/3236], Loss: 2.2084, Perplexity: 9.1015
Epoch [4/100], Step [1370/3236], Loss: 1.9961, Perplexity: 7.3602
Epoch [4/100], Step [1380/3236], Loss: 2.1471, Perplexity: 8.5602
Epoch [4/100], Step [1390/3236], Loss: 2.1818, Perplexity: 8.8620
Epoch [4/100], Step [1400/3236], Loss: 2.1347, Perplexity: 8.4545
Epoch [4/100], Step [1410/3236], Loss: 2.1837, Perplexity: 8.8793
Epoch [4/100], Step [1420/3236], Loss: 2.0654, Perplexity: 7.8887
Epoch [4/100], Step [1430/3236], Loss: 2.2628, Perplexity: 9.6103
Epoch [4/100], Step [1440/3236], Loss: 2.2527, Perplexity: 9.5130
Epoch [4/100], Step [1450/3236], Loss: 2.0565, Perplexity: 7.8182
Epoch [4/100], Step [1460/3236], Loss: 2.1868, Perplexity: 8.9068
Epoch [4/100], Step [1470/3236], Loss: 2.1666, Perplexity: 8.7285
Epoch [4/100], Step [1480/3236], Loss: 2.2137, Perplexity: 9.1491
Epoch [4/100], Step [1490/3236], Loss: 2.1265, Perplexity: 8.3856
Epoch [4/100], Step [1500/3236], Loss: 2.2079, Perplexity: 9.0969
Epoch [4/100], Step [1510/3236], Loss: 2.1619, Perplexity: 8.6875
Epoch [4/100], Step [1520/3236], Loss: 2.2303, Perplexity: 9.3029
Epoch [4/100], Step [1530/3236], Loss: 2.2385, Perplexity: 9.3795
Epoch [4/100], Step [1540/3236], Loss: 2.2878, Perplexity: 9.8535
Epoch [4/100], Step [1550/3236], Loss: 2.0989, Perplexity: 8.1576
Epoch [4/100], Step [1560/3236], Loss: 2.1635, Perplexity: 8.7018
Epoch [4/100], Step [1570/3236], Loss: 2.2159, Perplexity: 9.1694
Epoch [4/100], Step [1580/3236], Loss: 2.3947, Perplexity: 10.9654
Epoch [4/100], Step [1590/3236], Loss: 2.2668, Perplexity: 9.6488
Epoch [4/100], Step [1600/3236], Loss: 2.1433, Perplexity: 8.5279
Epoch [4/100], Step [1610/3236], Loss: 2.2063, Perplexity: 9.0821
Epoch [4/100], Step [1620/3236], Loss: 2.0978, Perplexity: 8.1481
Epoch [4/100], Step [1630/3236], Loss: 2.2028, Perplexity: 9.0505
Epoch [4/100], Step [1640/3236], Loss: 2.1188, Perplexity: 8.3210
Epoch [4/100], Step [1650/3236], Loss: 2.1379, Perplexity: 8.4816
Epoch [4/100], Step [1660/3236], Loss: 2.2448, Perplexity: 9.4382
Epoch [4/100], Step [1670/3236], Loss: 2.1990, Perplexity: 9.0158
Epoch [4/100], Step [1680/3236], Loss: 2.1766, Perplexity: 8.8163
Epoch [4/100], Step [1690/3236], Loss: 2.1814, Perplexity: 8.8587
Epoch [4/100], Step [1700/3236], Loss: 2.3044, Perplexity: 10.0179
Epoch [4/100], Step [1710/3236], Loss: 2.2633, Perplexity: 9.6148
Epoch [4/100], Step [1720/3236], Loss: 2.1524, Perplexity: 8.6056
Epoch [4/100], Step [1730/3236], Loss: 2.1915, Perplexity: 8.9484
Epoch [4/100], Step [1740/3236], Loss: 2.2857, Perplexity: 9.8324
Epoch [4/100], Step [1750/3236], Loss: 2.1049, Perplexity: 8.2065
Epoch [4/100], Step [1760/3236], Loss: 2.2432, Perplexity: 9.4236
Epoch [4/100], Step [1770/3236], Loss: 2.2394, Perplexity: 9.3872
Epoch [4/100], Step [1780/3236], Loss: 2.2950, Perplexity: 9.9247
Epoch [4/100], Step [1790/3236], Loss: 2.1110, Perplexity: 8.2567
Epoch [4/100], Step [1800/3236], Loss: 2.3096, Perplexity: 10.0708
Epoch [4/100], Step [1810/3236], Loss: 2.3057, Perplexity: 10.0308
Epoch [4/100], Step [1820/3236], Loss: 2.1749, Perplexity: 8.8012
Epoch [4/100], Step [1830/3236], Loss: 2.2466, Perplexity: 9.4552
Epoch [4/100], Step [1840/3236], Loss: 2.1740, Perplexity: 8.7931
Epoch [4/100], Step [1850/3236], Loss: 2.2473, Perplexity: 9.4621
Epoch [4/100], Step [1860/3236], Loss: 2.1421, Perplexity: 8.5174
Epoch [4/100], Step [1870/3236], Loss: 2.2231, Perplexity: 9.2355
Epoch [4/100], Step [1880/3236], Loss: 2.2956, Perplexity: 9.9304
Epoch [4/100], Step [1890/3236], Loss: 2.2786, Perplexity: 9.7626
Epoch [4/100], Step [1900/3236], Loss: 2.2803, Perplexity: 9.7794
Epoch [4/100], Step [1910/3236], Loss: 2.1818, Perplexity: 8.8624
Epoch [4/100], Step [1920/3236], Loss: 2.1998, Perplexity: 9.0230
Epoch [4/100], Step [1930/3236], Loss: 2.1781, Perplexity: 8.8299
Epoch [4/100], Step [1940/3236], Loss: 2.1900, Perplexity: 8.9354
Epoch [4/100], Step [1950/3236], Loss: 2.3093, Perplexity: 10.0674
Epoch [4/100], Step [1960/3236], Loss: 2.2105, Perplexity: 9.1202
Epoch [4/100], Step [1970/3236], Loss: 2.1513, Perplexity: 8.5961
Epoch [4/100], Step [1980/3236], Loss: 2.2480, Perplexity: 9.4684
Epoch [4/100], Step [1990/3236], Loss: 2.1911, Perplexity: 8.9452
Epoch [4/100], Step [2000/3236], Loss: 2.2830, Perplexity: 9.8060
Epoch [4/100], Step [2010/3236], Loss: 2.3042, Perplexity: 10.0164
Epoch [4/100], Step [2020/3236], Loss: 2.3414, Perplexity: 10.3954
Epoch [4/100], Step [2030/3236], Loss: 2.0939, Perplexity: 8.1168
Epoch [4/100], Step [2040/3236], Loss: 2.1505, Perplexity: 8.5889
Epoch [4/100], Step [2050/3236], Loss: 2.1868, Perplexity: 8.9064
Epoch [4/100], Step [2060/3236], Loss: 2.2770, Perplexity: 9.7476
Epoch [4/100], Step [2070/3236], Loss: 2.3228, Perplexity: 10.2040
Epoch [4/100], Step [2080/3236], Loss: 2.1518, Perplexity: 8.6002
Epoch [4/100], Step [2090/3236], Loss: 2.1409, Perplexity: 8.5067
Epoch [4/100], Step [2100/3236], Loss: 2.2670, Perplexity: 9.6500
Epoch [4/100], Step [2110/3236], Loss: 2.2553, Perplexity: 9.5379
Epoch [4/100], Step [2120/3236], Loss: 2.1932, Perplexity: 8.9640
Epoch [4/100], Step [2130/3236], Loss: 2.3548, Perplexity: 10.5356
Epoch [4/100], Step [2140/3236], Loss: 2.0502, Perplexity: 7.7695
Epoch [4/100], Step [2150/3236], Loss: 2.2167, Perplexity: 9.1769
Epoch [4/100], Step [2160/3236], Loss: 2.1615, Perplexity: 8.6841
Epoch [4/100], Step [2170/3236], Loss: 2.0477, Perplexity: 7.7500
Epoch [4/100], Step [2180/3236], Loss: 2.1621, Perplexity: 8.6892
Epoch [4/100], Step [2190/3236], Loss: 2.1390, Perplexity: 8.4912
Epoch [4/100], Step [2200/3236], Loss: 2.1066, Perplexity: 8.2200
Epoch [4/100], Step [2210/3236], Loss: 2.1628, Perplexity: 8.6956
Epoch [4/100], Step [2220/3236], Loss: 2.1866, Perplexity: 8.9045
Epoch [4/100], Step [2230/3236], Loss: 2.2038, Perplexity: 9.0590
Epoch [4/100], Step [2240/3236], Loss: 2.2108, Perplexity: 9.1227
Epoch [4/100], Step [2250/3236], Loss: 2.2150, Perplexity: 9.1616
Epoch [4/100], Step [2260/3236], Loss: 2.3286, Perplexity: 10.2636
Epoch [4/100], Step [2270/3236], Loss: 2.0939, Perplexity: 8.1167
Epoch [4/100], Step [2280/3236], Loss: 2.2777, Perplexity: 9.7545
Epoch [4/100], Step [2290/3236], Loss: 2.1849, Perplexity: 8.8898
Epoch [4/100], Step [2300/3236], Loss: 2.2916, Perplexity: 9.8911
Epoch [4/100], Step [2310/3236], Loss: 2.2273, Perplexity: 9.2751
Epoch [4/100], Step [2320/3236], Loss: 2.2452, Perplexity: 9.4427
Epoch [4/100], Step [2330/3236], Loss: 2.2919, Perplexity: 9.8938
Epoch [4/100], Step [2340/3236], Loss: 2.1736, Perplexity: 8.7898
Epoch [4/100], Step [2350/3236], Loss: 2.0344, Perplexity: 7.6473
Epoch [4/100], Step [2360/3236], Loss: 2.1495, Perplexity: 8.5806
Epoch [4/100], Step [2370/3236], Loss: 2.2988, Perplexity: 9.9626
Epoch [4/100], Step [2380/3236], Loss: 2.2674, Perplexity: 9.6542
Epoch [4/100], Step [2390/3236], Loss: 2.1105, Perplexity: 8.2526
Epoch [4/100], Step [2400/3236], Loss: 2.3130, Perplexity: 10.1047
Epoch [4/100], Step [2410/3236], Loss: 2.2615, Perplexity: 9.5973
Epoch [4/100], Step [2420/3236], Loss: 2.3202, Perplexity: 10.1780
Epoch [4/100], Step [2430/3236], Loss: 2.1603, Perplexity: 8.6737
Epoch [4/100], Step [2440/3236], Loss: 2.1531, Perplexity: 8.6114
Epoch [4/100], Step [2450/3236], Loss: 2.3029, Perplexity: 10.0033
Epoch [4/100], Step [2460/3236], Loss: 2.4114, Perplexity: 11.1494
Epoch [4/100], Step [2470/3236], Loss: 2.2177, Perplexity: 9.1858
Epoch [4/100], Step [2480/3236], Loss: 2.3638, Perplexity: 10.6312
Epoch [4/100], Step [2490/3236], Loss: 2.1822, Perplexity: 8.8654
Epoch [4/100], Step [2500/3236], Loss: 2.1458, Perplexity: 8.5487
Epoch [4/100], Step [2510/3236], Loss: 2.1685, Perplexity: 8.7451
Epoch [4/100], Step [2520/3236], Loss: 2.1190, Perplexity: 8.3232
Epoch [4/100], Step [2530/3236], Loss: 2.2049, Perplexity: 9.0692
Epoch [4/100], Step [2540/3236], Loss: 2.1625, Perplexity: 8.6930
Epoch [4/100], Step [2550/3236], Loss: 2.1050, Perplexity: 8.2070
Epoch [4/100], Step [2560/3236], Loss: 2.2240, Perplexity: 9.2443
Epoch [4/100], Step [2570/3236], Loss: 2.1379, Perplexity: 8.4818
Epoch [4/100], Step [2580/3236], Loss: 2.2321, Perplexity: 9.3191
Epoch [4/100], Step [2590/3236], Loss: 2.2159, Perplexity: 9.1693
Epoch [4/100], Step [2600/3236], Loss: 2.3032, Perplexity: 10.0066
Epoch [4/100], Step [2610/3236], Loss: 2.2556, Perplexity: 9.5412
Epoch [4/100], Step [2620/3236], Loss: 2.1041, Perplexity: 8.2000
Epoch [4/100], Step [2630/3236], Loss: 2.0872, Perplexity: 8.0627
Epoch [4/100], Step [2640/3236], Loss: 2.1597, Perplexity: 8.6689
Epoch [4/100], Step [2650/3236], Loss: 2.2911, Perplexity: 9.8861
Epoch [4/100], Step [2660/3236], Loss: 2.2243, Perplexity: 9.2474
Epoch [4/100], Step [2670/3236], Loss: 2.1452, Perplexity: 8.5440
Epoch [4/100], Step [2680/3236], Loss: 2.2532, Perplexity: 9.5178
Epoch [4/100], Step [2690/3236], Loss: 2.1298, Perplexity: 8.4135
Epoch [4/100], Step [2700/3236], Loss: 2.1909, Perplexity: 8.9428
Epoch [4/100], Step [2710/3236], Loss: 2.2157, Perplexity: 9.1676
Epoch [4/100], Step [2720/3236], Loss: 2.2072, Perplexity: 9.0898
Epoch [4/100], Step [2730/3236], Loss: 2.1122, Perplexity: 8.2665
Epoch [4/100], Step [2740/3236], Loss: 2.2863, Perplexity: 9.8387
Epoch [4/100], Step [2750/3236], Loss: 2.1430, Perplexity: 8.5252
Epoch [4/100], Step [2760/3236], Loss: 2.2385, Perplexity: 9.3793
Epoch [4/100], Step [2770/3236], Loss: 2.2189, Perplexity: 9.1972
Epoch [4/100], Step [2780/3236], Loss: 2.3981, Perplexity: 11.0019
Epoch [4/100], Step [2790/3236], Loss: 2.1505, Perplexity: 8.5888
Epoch [4/100], Step [2800/3236], Loss: 2.1114, Perplexity: 8.2595
Epoch [4/100], Step [2810/3236], Loss: 2.1720, Perplexity: 8.7760
Epoch [4/100], Step [2820/3236], Loss: 2.2464, Perplexity: 9.4539
Epoch [4/100], Step [2830/3236], Loss: 2.1741, Perplexity: 8.7941
Epoch [4/100], Step [2840/3236], Loss: 2.2299, Perplexity: 9.2992
Epoch [4/100], Step [2850/3236], Loss: 2.2070, Perplexity: 9.0884
Epoch [4/100], Step [2860/3236], Loss: 2.2857, Perplexity: 9.8327
Epoch [4/100], Step [2870/3236], Loss: 2.1791, Perplexity: 8.8384
Epoch [4/100], Step [2880/3236], Loss: 2.2557, Perplexity: 9.5421
Epoch [4/100], Step [2890/3236], Loss: 2.1261, Perplexity: 8.3823
Epoch [4/100], Step [2900/3236], Loss: 2.1742, Perplexity: 8.7950
Epoch [4/100], Step [2910/3236], Loss: 2.4334, Perplexity: 11.3981
Epoch [4/100], Step [2920/3236], Loss: 2.2768, Perplexity: 9.7452
Epoch [4/100], Step [2930/3236], Loss: 2.1159, Perplexity: 8.2974
Epoch [4/100], Step [2940/3236], Loss: 2.1901, Perplexity: 8.9365
Epoch [4/100], Step [2950/3236], Loss: 2.2022, Perplexity: 9.0452
Epoch [4/100], Step [2960/3236], Loss: 2.1333, Perplexity: 8.4423
Epoch [4/100], Step [2970/3236], Loss: 2.3455, Perplexity: 10.4385
Epoch [4/100], Step [2980/3236], Loss: 2.2783, Perplexity: 9.7605
Epoch [4/100], Step [2990/3236], Loss: 2.3150, Perplexity: 10.1251
Epoch [4/100], Step [3000/3236], Loss: 2.1355, Perplexity: 8.4610
Epoch [4/100], Step [3010/3236], Loss: 2.1654, Perplexity: 8.7183
Epoch [4/100], Step [3020/3236], Loss: 2.1557, Perplexity: 8.6338
Epoch [4/100], Step [3030/3236], Loss: 2.0741, Perplexity: 7.9575
Epoch [4/100], Step [3040/3236], Loss: 2.2595, Perplexity: 9.5785
Epoch [4/100], Step [3050/3236], Loss: 2.2366, Perplexity: 9.3615
Epoch [4/100], Step [3060/3236], Loss: 2.1900, Perplexity: 8.9356
Epoch [4/100], Step [3070/3236], Loss: 2.1401, Perplexity: 8.5002
Epoch [4/100], Step [3080/3236], Loss: 2.0481, Perplexity: 7.7535
Epoch [4/100], Step [3090/3236], Loss: 2.1948, Perplexity: 8.9786
Epoch [4/100], Step [3100/3236], Loss: 2.0794, Perplexity: 7.9999
Epoch [4/100], Step [3110/3236], Loss: 2.1052, Perplexity: 8.2086
Epoch [4/100], Step [3120/3236], Loss: 2.0529, Perplexity: 7.7902
Epoch [4/100], Step [3130/3236], Loss: 2.2653, Perplexity: 9.6336
Epoch [4/100], Step [3140/3236], Loss: 2.2180, Perplexity: 9.1894
Epoch [4/100], Step [3150/3236], Loss: 2.1133, Perplexity: 8.2756
Epoch [4/100], Step [3160/3236], Loss: 2.2885, Perplexity: 9.8604
Epoch [4/100], Step [3170/3236], Loss: 2.1335, Perplexity: 8.4443
Epoch [4/100], Step [3180/3236], Loss: 1.9958, Perplexity: 7.3579
Epoch [4/100], Step [3190/3236], Loss: 2.1365, Perplexity: 8.4697
Epoch [4/100], Step [3200/3236], Loss: 2.1321, Perplexity: 8.4327
Epoch [4/100], Step [3210/3236], Loss: 2.2117, Perplexity: 9.1309
Epoch [4/100], Step [3220/3236], Loss: 2.2707, Perplexity: 9.6867
Epoch [4/100], Step [3230/3236], Loss: 2.2467, Perplexity: 9.4563
start evaluate ...
446209 : a man is flying a kite in a field
483165 : a man and a woman riding a bicycle down a street
454388 : a desk with a computer and a laptop
487421 : a bowl of pasta with broccoli and carrots
553443 : a man is sitting in a chair with a laptop
576327 : a zebra is standing in the dirt near a tree
435466 : a kitchen with a refrigerator and a stove
280918 : a woman in a kitchen with a stove top oven
446265 : a bunch of vegetables are in a kitchen
276693 : a man riding skis down a snow covered slope
loading annotations into memory...
Done (t=0.72s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1260232.23 tokens per second.
PTBTokenizer tokenized 53579 tokens at 619172.28 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48068, 'guess': [48580, 43580, 38580, 33580], 'testlen': 48580, 'correct': [32764, 15693, 6675, 2853]}
('ratio:', 1.0106515769326578)
Bleu_1: 0.674
Bleu_2: 0.493
Bleu_3: 0.348
Bleu_4: 0.244
computing METEOR score...
METEOR: 0.224
computing Rouge score...
ROUGE_L: 0.493
computing CIDEr score...
CIDEr: 0.776
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [31.490 seconds]
SPICE evaluation took: 42.37 s
SPICE: 0.154
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [5/100], Step [10/3236], Loss: 2.0845, Perplexity: 8.0408
Epoch [5/100], Step [20/3236], Loss: 2.0379, Perplexity: 7.6744
Epoch [5/100], Step [30/3236], Loss: 2.1883, Perplexity: 8.9200
Epoch [5/100], Step [40/3236], Loss: 2.1110, Perplexity: 8.2564
Epoch [5/100], Step [50/3236], Loss: 2.2163, Perplexity: 9.1731
Epoch [5/100], Step [60/3236], Loss: 2.1526, Perplexity: 8.6071
Epoch [5/100], Step [70/3236], Loss: 2.1000, Perplexity: 8.1660
Epoch [5/100], Step [80/3236], Loss: 2.0817, Perplexity: 8.0184
Epoch [5/100], Step [90/3236], Loss: 2.0153, Perplexity: 7.5028
Epoch [5/100], Step [100/3236], Loss: 1.9920, Perplexity: 7.3305
Epoch [5/100], Step [110/3236], Loss: 2.0944, Perplexity: 8.1203
Epoch [5/100], Step [120/3236], Loss: 1.9955, Perplexity: 7.3558
Epoch [5/100], Step [130/3236], Loss: 1.9826, Perplexity: 7.2616
Epoch [5/100], Step [140/3236], Loss: 2.0264, Perplexity: 7.5869
Epoch [5/100], Step [150/3236], Loss: 2.1480, Perplexity: 8.5679
Epoch [5/100], Step [160/3236], Loss: 2.1108, Perplexity: 8.2552
Epoch [5/100], Step [170/3236], Loss: 2.2046, Perplexity: 9.0665
Epoch [5/100], Step [180/3236], Loss: 2.1814, Perplexity: 8.8584
Epoch [5/100], Step [190/3236], Loss: 2.1153, Perplexity: 8.2924
Epoch [5/100], Step [200/3236], Loss: 2.2187, Perplexity: 9.1949
Epoch [5/100], Step [210/3236], Loss: 2.0787, Perplexity: 7.9942
Epoch [5/100], Step [220/3236], Loss: 2.1342, Perplexity: 8.4507
Epoch [5/100], Step [230/3236], Loss: 1.9036, Perplexity: 6.7100
Epoch [5/100], Step [240/3236], Loss: 2.0983, Perplexity: 8.1523
Epoch [5/100], Step [250/3236], Loss: 2.0225, Perplexity: 7.5573
Epoch [5/100], Step [260/3236], Loss: 2.0665, Perplexity: 7.8970
Epoch [5/100], Step [270/3236], Loss: 2.2518, Perplexity: 9.5050
Epoch [5/100], Step [280/3236], Loss: 2.0332, Perplexity: 7.6384
Epoch [5/100], Step [290/3236], Loss: 2.0818, Perplexity: 8.0187
Epoch [5/100], Step [300/3236], Loss: 2.1010, Perplexity: 8.1741
Epoch [5/100], Step [310/3236], Loss: 2.1779, Perplexity: 8.8277
Epoch [5/100], Step [320/3236], Loss: 2.1682, Perplexity: 8.7423
Epoch [5/100], Step [330/3236], Loss: 2.1544, Perplexity: 8.6223
Epoch [5/100], Step [340/3236], Loss: 2.1682, Perplexity: 8.7429
Epoch [5/100], Step [350/3236], Loss: 2.1366, Perplexity: 8.4706
Epoch [5/100], Step [360/3236], Loss: 2.1471, Perplexity: 8.5602
Epoch [5/100], Step [370/3236], Loss: 2.1347, Perplexity: 8.4542
Epoch [5/100], Step [380/3236], Loss: 2.1659, Perplexity: 8.7228
Epoch [5/100], Step [390/3236], Loss: 2.0234, Perplexity: 7.5643
Epoch [5/100], Step [400/3236], Loss: 2.0821, Perplexity: 8.0215
Epoch [5/100], Step [410/3236], Loss: 1.9786, Perplexity: 7.2327
Epoch [5/100], Step [420/3236], Loss: 2.1410, Perplexity: 8.5076
Epoch [5/100], Step [430/3236], Loss: 2.0914, Perplexity: 8.0963
Epoch [5/100], Step [440/3236], Loss: 2.1585, Perplexity: 8.6582
Epoch [5/100], Step [450/3236], Loss: 2.2047, Perplexity: 9.0672
Epoch [5/100], Step [460/3236], Loss: 2.1371, Perplexity: 8.4747
Epoch [5/100], Step [470/3236], Loss: 1.9915, Perplexity: 7.3268
Epoch [5/100], Step [480/3236], Loss: 2.0229, Perplexity: 7.5601
Epoch [5/100], Step [490/3236], Loss: 2.0325, Perplexity: 7.6334
Epoch [5/100], Step [500/3236], Loss: 2.0839, Perplexity: 8.0360
Epoch [5/100], Step [510/3236], Loss: 2.2331, Perplexity: 9.3291
Epoch [5/100], Step [520/3236], Loss: 1.9924, Perplexity: 7.3329
Epoch [5/100], Step [530/3236], Loss: 2.1651, Perplexity: 8.7154
Epoch [5/100], Step [540/3236], Loss: 2.1934, Perplexity: 8.9654
Epoch [5/100], Step [550/3236], Loss: 2.2145, Perplexity: 9.1571
Epoch [5/100], Step [560/3236], Loss: 2.0839, Perplexity: 8.0360
Epoch [5/100], Step [570/3236], Loss: 1.9923, Perplexity: 7.3325
Epoch [5/100], Step [580/3236], Loss: 2.1549, Perplexity: 8.6268
Epoch [5/100], Step [590/3236], Loss: 2.1258, Perplexity: 8.3794
Epoch [5/100], Step [600/3236], Loss: 2.1121, Perplexity: 8.2658
Epoch [5/100], Step [610/3236], Loss: 2.1691, Perplexity: 8.7506
Epoch [5/100], Step [620/3236], Loss: 2.1740, Perplexity: 8.7938
Epoch [5/100], Step [630/3236], Loss: 2.1951, Perplexity: 8.9811
Epoch [5/100], Step [640/3236], Loss: 2.0991, Perplexity: 8.1587
Epoch [5/100], Step [650/3236], Loss: 2.0400, Perplexity: 7.6903
Epoch [5/100], Step [660/3236], Loss: 2.1697, Perplexity: 8.7559
Epoch [5/100], Step [670/3236], Loss: 2.1358, Perplexity: 8.4639
Epoch [5/100], Step [680/3236], Loss: 2.1334, Perplexity: 8.4431
Epoch [5/100], Step [690/3236], Loss: 2.0826, Perplexity: 8.0252
Epoch [5/100], Step [700/3236], Loss: 2.0605, Perplexity: 7.8503
Epoch [5/100], Step [710/3236], Loss: 2.0862, Perplexity: 8.0545
Epoch [5/100], Step [720/3236], Loss: 2.1810, Perplexity: 8.8548
Epoch [5/100], Step [730/3236], Loss: 2.2382, Perplexity: 9.3761
Epoch [5/100], Step [740/3236], Loss: 2.1982, Perplexity: 9.0085
Epoch [5/100], Step [750/3236], Loss: 2.2812, Perplexity: 9.7881
Epoch [5/100], Step [760/3236], Loss: 2.1316, Perplexity: 8.4283
Epoch [5/100], Step [770/3236], Loss: 2.0306, Perplexity: 7.6185
Epoch [5/100], Step [780/3236], Loss: 2.1177, Perplexity: 8.3117
Epoch [5/100], Step [790/3236], Loss: 2.0732, Perplexity: 7.9506
Epoch [5/100], Step [800/3236], Loss: 2.1951, Perplexity: 8.9808
Epoch [5/100], Step [810/3236], Loss: 2.0798, Perplexity: 8.0030
Epoch [5/100], Step [820/3236], Loss: 2.1318, Perplexity: 8.4303
Epoch [5/100], Step [830/3236], Loss: 2.1566, Perplexity: 8.6418
Epoch [5/100], Step [840/3236], Loss: 1.9850, Perplexity: 7.2791
Epoch [5/100], Step [850/3236], Loss: 2.1544, Perplexity: 8.6223
Epoch [5/100], Step [860/3236], Loss: 2.2963, Perplexity: 9.9377
Epoch [5/100], Step [870/3236], Loss: 2.0385, Perplexity: 7.6789
Epoch [5/100], Step [880/3236], Loss: 2.2662, Perplexity: 9.6428
Epoch [5/100], Step [890/3236], Loss: 2.0672, Perplexity: 7.9031
Epoch [5/100], Step [900/3236], Loss: 2.1533, Perplexity: 8.6131
Epoch [5/100], Step [910/3236], Loss: 1.9399, Perplexity: 6.9579
Epoch [5/100], Step [920/3236], Loss: 2.0409, Perplexity: 7.6976
Epoch [5/100], Step [930/3236], Loss: 2.0863, Perplexity: 8.0548
Epoch [5/100], Step [940/3236], Loss: 2.1420, Perplexity: 8.5162
Epoch [5/100], Step [950/3236], Loss: 2.1785, Perplexity: 8.8329
Epoch [5/100], Step [960/3236], Loss: 2.1822, Perplexity: 8.8654
Epoch [5/100], Step [970/3236], Loss: 2.0742, Perplexity: 7.9581
Epoch [5/100], Step [980/3236], Loss: 2.0815, Perplexity: 8.0162
Epoch [5/100], Step [990/3236], Loss: 2.1391, Perplexity: 8.4919
Epoch [5/100], Step [1000/3236], Loss: 2.0965, Perplexity: 8.1376
Epoch [5/100], Step [1010/3236], Loss: 2.0980, Perplexity: 8.1502
Epoch [5/100], Step [1020/3236], Loss: 2.0302, Perplexity: 7.6154
Epoch [5/100], Step [1030/3236], Loss: 2.1026, Perplexity: 8.1877
Epoch [5/100], Step [1040/3236], Loss: 2.0815, Perplexity: 8.0163
Epoch [5/100], Step [1050/3236], Loss: 2.1622, Perplexity: 8.6900
Epoch [5/100], Step [1060/3236], Loss: 2.0393, Perplexity: 7.6852
Epoch [5/100], Step [1070/3236], Loss: 2.0538, Perplexity: 7.7976
Epoch [5/100], Step [1080/3236], Loss: 2.1001, Perplexity: 8.1674
Epoch [5/100], Step [1090/3236], Loss: 2.1903, Perplexity: 8.9376
Epoch [5/100], Step [1100/3236], Loss: 2.1448, Perplexity: 8.5404
Epoch [5/100], Step [1110/3236], Loss: 2.0946, Perplexity: 8.1222
Epoch [5/100], Step [1120/3236], Loss: 2.1092, Perplexity: 8.2419
Epoch [5/100], Step [1130/3236], Loss: 2.1752, Perplexity: 8.8040
Epoch [5/100], Step [1140/3236], Loss: 2.0711, Perplexity: 7.9333
Epoch [5/100], Step [1150/3236], Loss: 2.0337, Perplexity: 7.6420
Epoch [5/100], Step [1160/3236], Loss: 2.1660, Perplexity: 8.7237
Epoch [5/100], Step [1170/3236], Loss: 2.1123, Perplexity: 8.2669
Epoch [5/100], Step [1180/3236], Loss: 2.0990, Perplexity: 8.1577
Epoch [5/100], Step [1190/3236], Loss: 2.1294, Perplexity: 8.4100
Epoch [5/100], Step [1200/3236], Loss: 2.2027, Perplexity: 9.0495
Epoch [5/100], Step [1210/3236], Loss: 2.0827, Perplexity: 8.0258
Epoch [5/100], Step [1220/3236], Loss: 2.0756, Perplexity: 7.9691
Epoch [5/100], Step [1230/3236], Loss: 2.0239, Perplexity: 7.5681
Epoch [5/100], Step [1240/3236], Loss: 2.1687, Perplexity: 8.7470
Epoch [5/100], Step [1250/3236], Loss: 2.2118, Perplexity: 9.1318
Epoch [5/100], Step [1260/3236], Loss: 2.0882, Perplexity: 8.0701
Epoch [5/100], Step [1270/3236], Loss: 2.2525, Perplexity: 9.5117
Epoch [5/100], Step [1280/3236], Loss: 1.9914, Perplexity: 7.3256
Epoch [5/100], Step [1290/3236], Loss: 2.2258, Perplexity: 9.2612
Epoch [5/100], Step [1300/3236], Loss: 2.2553, Perplexity: 9.5381
Epoch [5/100], Step [1310/3236], Loss: 2.1377, Perplexity: 8.4797
Epoch [5/100], Step [1320/3236], Loss: 2.0027, Perplexity: 7.4088
Epoch [5/100], Step [1330/3236], Loss: 2.2088, Perplexity: 9.1043
Epoch [5/100], Step [1340/3236], Loss: 2.1382, Perplexity: 8.4844
Epoch [5/100], Step [1350/3236], Loss: 2.0646, Perplexity: 7.8820
Epoch [5/100], Step [1360/3236], Loss: 2.1014, Perplexity: 8.1779
Epoch [5/100], Step [1370/3236], Loss: 2.1446, Perplexity: 8.5387
Epoch [5/100], Step [1380/3236], Loss: 2.2442, Perplexity: 9.4332
Epoch [5/100], Step [1390/3236], Loss: 2.2154, Perplexity: 9.1652
Epoch [5/100], Step [1400/3236], Loss: 2.1067, Perplexity: 8.2208
Epoch [5/100], Step [1410/3236], Loss: 2.0091, Perplexity: 7.4564
Epoch [5/100], Step [1420/3236], Loss: 2.2162, Perplexity: 9.1726
Epoch [5/100], Step [1430/3236], Loss: 2.1469, Perplexity: 8.5584
Epoch [5/100], Step [1440/3236], Loss: 2.1440, Perplexity: 8.5333
Epoch [5/100], Step [1450/3236], Loss: 2.1080, Perplexity: 8.2315
Epoch [5/100], Step [1460/3236], Loss: 2.2584, Perplexity: 9.5681
Epoch [5/100], Step [1470/3236], Loss: 2.1859, Perplexity: 8.8991
Epoch [5/100], Step [1480/3236], Loss: 2.0101, Perplexity: 7.4641
Epoch [5/100], Step [1490/3236], Loss: 2.1838, Perplexity: 8.8800
Epoch [5/100], Step [1500/3236], Loss: 2.2312, Perplexity: 9.3107
Epoch [5/100], Step [1510/3236], Loss: 2.0548, Perplexity: 7.8055
Epoch [5/100], Step [1520/3236], Loss: 2.0493, Perplexity: 7.7624
Epoch [5/100], Step [1530/3236], Loss: 2.1458, Perplexity: 8.5487
Epoch [5/100], Step [1540/3236], Loss: 2.1474, Perplexity: 8.5629
Epoch [5/100], Step [1550/3236], Loss: 2.2026, Perplexity: 9.0482
Epoch [5/100], Step [1560/3236], Loss: 2.0272, Perplexity: 7.5930
Epoch [5/100], Step [1570/3236], Loss: 2.1178, Perplexity: 8.3132
Epoch [5/100], Step [1580/3236], Loss: 2.3955, Perplexity: 10.9741
Epoch [5/100], Step [1590/3236], Loss: 2.1661, Perplexity: 8.7244
Epoch [5/100], Step [1600/3236], Loss: 2.0913, Perplexity: 8.0953
Epoch [5/100], Step [1610/3236], Loss: 2.2502, Perplexity: 9.4900
Epoch [5/100], Step [1620/3236], Loss: 2.1107, Perplexity: 8.2539
Epoch [5/100], Step [1630/3236], Loss: 2.2250, Perplexity: 9.2538
Epoch [5/100], Step [1640/3236], Loss: 2.1181, Perplexity: 8.3155
Epoch [5/100], Step [1650/3236], Loss: 2.2000, Perplexity: 9.0254
Epoch [5/100], Step [1660/3236], Loss: 2.3005, Perplexity: 9.9795
Epoch [5/100], Step [1670/3236], Loss: 2.1069, Perplexity: 8.2226
Epoch [5/100], Step [1680/3236], Loss: 2.1655, Perplexity: 8.7194
Epoch [5/100], Step [1690/3236], Loss: 2.1741, Perplexity: 8.7942
Epoch [5/100], Step [1700/3236], Loss: 2.0892, Perplexity: 8.0788
Epoch [5/100], Step [1710/3236], Loss: 2.0382, Perplexity: 7.6764
Epoch [5/100], Step [1720/3236], Loss: 2.1296, Perplexity: 8.4116
Epoch [5/100], Step [1730/3236], Loss: 2.2725, Perplexity: 9.7039
Epoch [5/100], Step [1740/3236], Loss: 2.0762, Perplexity: 7.9739
Epoch [5/100], Step [1750/3236], Loss: 1.9290, Perplexity: 6.8826
Epoch [5/100], Step [1760/3236], Loss: 2.1163, Perplexity: 8.3005
Epoch [5/100], Step [1770/3236], Loss: 2.2549, Perplexity: 9.5339
Epoch [5/100], Step [1780/3236], Loss: 2.1388, Perplexity: 8.4894
Epoch [5/100], Step [1790/3236], Loss: 2.1324, Perplexity: 8.4347
Epoch [5/100], Step [1800/3236], Loss: 2.2093, Perplexity: 9.1089
Epoch [5/100], Step [1810/3236], Loss: 2.1571, Perplexity: 8.6458
Epoch [5/100], Step [1820/3236], Loss: 2.2150, Perplexity: 9.1612
Epoch [5/100], Step [1830/3236], Loss: 2.0443, Perplexity: 7.7237
Epoch [5/100], Step [1840/3236], Loss: 2.1370, Perplexity: 8.4737
Epoch [5/100], Step [1850/3236], Loss: 2.2422, Perplexity: 9.4141
Epoch [5/100], Step [1860/3236], Loss: 1.9796, Perplexity: 7.2395
Epoch [5/100], Step [1870/3236], Loss: 2.1768, Perplexity: 8.8185
Epoch [5/100], Step [1880/3236], Loss: 2.2891, Perplexity: 9.8659
Epoch [5/100], Step [1890/3236], Loss: 2.2169, Perplexity: 9.1791
Epoch [5/100], Step [1900/3236], Loss: 2.3324, Perplexity: 10.3031
Epoch [5/100], Step [1910/3236], Loss: 2.1297, Perplexity: 8.4125
Epoch [5/100], Step [1920/3236], Loss: 2.0679, Perplexity: 7.9079
Epoch [5/100], Step [1930/3236], Loss: 2.1059, Perplexity: 8.2141
Epoch [5/100], Step [1940/3236], Loss: 2.2207, Perplexity: 9.2138
Epoch [5/100], Step [1950/3236], Loss: 2.2189, Perplexity: 9.1969
Epoch [5/100], Step [1960/3236], Loss: 2.2579, Perplexity: 9.5632
Epoch [5/100], Step [1970/3236], Loss: 1.9702, Perplexity: 7.1724
Epoch [5/100], Step [1980/3236], Loss: 2.0974, Perplexity: 8.1451
Epoch [5/100], Step [1990/3236], Loss: 2.1920, Perplexity: 8.9527
Epoch [5/100], Step [2000/3236], Loss: 2.1891, Perplexity: 8.9274
Epoch [5/100], Step [2010/3236], Loss: 2.1071, Perplexity: 8.2240
Epoch [5/100], Step [2020/3236], Loss: 2.1696, Perplexity: 8.7545
Epoch [5/100], Step [2030/3236], Loss: 2.3898, Perplexity: 10.9117
Epoch [5/100], Step [2040/3236], Loss: 2.1800, Perplexity: 8.8467
Epoch [5/100], Step [2050/3236], Loss: 2.2097, Perplexity: 9.1129
Epoch [5/100], Step [2060/3236], Loss: 2.0691, Perplexity: 7.9175
Epoch [5/100], Step [2070/3236], Loss: 2.1150, Perplexity: 8.2893
Epoch [5/100], Step [2080/3236], Loss: 2.1614, Perplexity: 8.6834
Epoch [5/100], Step [2090/3236], Loss: 2.2619, Perplexity: 9.6010
Epoch [5/100], Step [2100/3236], Loss: 2.0598, Perplexity: 7.8441
Epoch [5/100], Step [2110/3236], Loss: 2.0923, Perplexity: 8.1037
Epoch [5/100], Step [2120/3236], Loss: 1.9948, Perplexity: 7.3509
Epoch [5/100], Step [2130/3236], Loss: 2.1545, Perplexity: 8.6234
Epoch [5/100], Step [2140/3236], Loss: 2.0423, Perplexity: 7.7084
Epoch [5/100], Step [2150/3236], Loss: 2.1483, Perplexity: 8.5703
Epoch [5/100], Step [2160/3236], Loss: 2.1112, Perplexity: 8.2578
Epoch [5/100], Step [2170/3236], Loss: 2.1381, Perplexity: 8.4837
Epoch [5/100], Step [2180/3236], Loss: 2.1136, Perplexity: 8.2784
Epoch [5/100], Step [2190/3236], Loss: 2.1228, Perplexity: 8.3547
Epoch [5/100], Step [2200/3236], Loss: 2.1299, Perplexity: 8.4144
Epoch [5/100], Step [2210/3236], Loss: 2.0167, Perplexity: 7.5137
Epoch [5/100], Step [2220/3236], Loss: 2.1579, Perplexity: 8.6533
Epoch [5/100], Step [2230/3236], Loss: 2.1110, Perplexity: 8.2564
Epoch [5/100], Step [2240/3236], Loss: 2.1522, Perplexity: 8.6034
Epoch [5/100], Step [2250/3236], Loss: 2.0460, Perplexity: 7.7372
Epoch [5/100], Step [2260/3236], Loss: 2.1877, Perplexity: 8.9146
Epoch [5/100], Step [2270/3236], Loss: 2.1349, Perplexity: 8.4558
Epoch [5/100], Step [2280/3236], Loss: 2.1785, Perplexity: 8.8331
Epoch [5/100], Step [2290/3236], Loss: 2.0843, Perplexity: 8.0392
Epoch [5/100], Step [2300/3236], Loss: 2.2807, Perplexity: 9.7831
Epoch [5/100], Step [2310/3236], Loss: 2.1116, Perplexity: 8.2610
Epoch [5/100], Step [2320/3236], Loss: 2.2410, Perplexity: 9.4025
Epoch [5/100], Step [2330/3236], Loss: 2.1417, Perplexity: 8.5141
Epoch [5/100], Step [2340/3236], Loss: 2.1890, Perplexity: 8.9260
Epoch [5/100], Step [2350/3236], Loss: 2.2988, Perplexity: 9.9625
Epoch [5/100], Step [2360/3236], Loss: 2.1991, Perplexity: 9.0173
Epoch [5/100], Step [2370/3236], Loss: 2.1609, Perplexity: 8.6786
Epoch [5/100], Step [2380/3236], Loss: 2.1318, Perplexity: 8.4298
Epoch [5/100], Step [2390/3236], Loss: 2.2060, Perplexity: 9.0789
Epoch [5/100], Step [2400/3236], Loss: 2.2499, Perplexity: 9.4865
Epoch [5/100], Step [2410/3236], Loss: 2.0401, Perplexity: 7.6917
Epoch [5/100], Step [2420/3236], Loss: 2.2630, Perplexity: 9.6123
Epoch [5/100], Step [2430/3236], Loss: 2.0880, Perplexity: 8.0689
Epoch [5/100], Step [2440/3236], Loss: 2.2270, Perplexity: 9.2723
Epoch [5/100], Step [2450/3236], Loss: 2.1692, Perplexity: 8.7516
Epoch [5/100], Step [2460/3236], Loss: 2.0491, Perplexity: 7.7609
Epoch [5/100], Step [2470/3236], Loss: 2.1137, Perplexity: 8.2785
Epoch [5/100], Step [2480/3236], Loss: 2.2271, Perplexity: 9.2729
Epoch [5/100], Step [2490/3236], Loss: 2.2039, Perplexity: 9.0602
Epoch [5/100], Step [2500/3236], Loss: 2.1692, Perplexity: 8.7511
Epoch [5/100], Step [2510/3236], Loss: 2.1755, Perplexity: 8.8068
Epoch [5/100], Step [2520/3236], Loss: 2.1022, Perplexity: 8.1846
Epoch [5/100], Step [2530/3236], Loss: 2.0978, Perplexity: 8.1478
Epoch [5/100], Step [2540/3236], Loss: 2.1103, Perplexity: 8.2510
Epoch [5/100], Step [2550/3236], Loss: 2.2271, Perplexity: 9.2731
Epoch [5/100], Step [2560/3236], Loss: 2.2376, Perplexity: 9.3707
Epoch [5/100], Step [2570/3236], Loss: 2.1941, Perplexity: 8.9723
Epoch [5/100], Step [2580/3236], Loss: 2.0487, Perplexity: 7.7577
Epoch [5/100], Step [2590/3236], Loss: 2.0601, Perplexity: 7.8469
Epoch [5/100], Step [2600/3236], Loss: 2.0357, Perplexity: 7.6576
Epoch [5/100], Step [2610/3236], Loss: 2.3014, Perplexity: 9.9882
Epoch [5/100], Step [2620/3236], Loss: 2.2381, Perplexity: 9.3756
Epoch [5/100], Step [2630/3236], Loss: 2.1966, Perplexity: 8.9940
Epoch [5/100], Step [2640/3236], Loss: 2.0770, Perplexity: 7.9806
Epoch [5/100], Step [2650/3236], Loss: 2.0795, Perplexity: 8.0007
Epoch [5/100], Step [2660/3236], Loss: 2.0868, Perplexity: 8.0592
Epoch [5/100], Step [2670/3236], Loss: 2.0797, Perplexity: 8.0020
Epoch [5/100], Step [2680/3236], Loss: 2.2233, Perplexity: 9.2377
Epoch [5/100], Step [2690/3236], Loss: 2.0771, Perplexity: 7.9810
Epoch [5/100], Step [2700/3236], Loss: 2.1706, Perplexity: 8.7635
Epoch [5/100], Step [2710/3236], Loss: 2.0061, Perplexity: 7.4345
Epoch [5/100], Step [2720/3236], Loss: 2.0895, Perplexity: 8.0812
Epoch [5/100], Step [2730/3236], Loss: 2.1268, Perplexity: 8.3878
Epoch [5/100], Step [2740/3236], Loss: 2.1079, Perplexity: 8.2311
Epoch [5/100], Step [2750/3236], Loss: 2.2008, Perplexity: 9.0320
Epoch [5/100], Step [2760/3236], Loss: 2.2174, Perplexity: 9.1834
Epoch [5/100], Step [2770/3236], Loss: 1.9840, Perplexity: 7.2719
Epoch [5/100], Step [2780/3236], Loss: 2.1769, Perplexity: 8.8192
Epoch [5/100], Step [2790/3236], Loss: 2.0423, Perplexity: 7.7087
Epoch [5/100], Step [2800/3236], Loss: 2.1240, Perplexity: 8.3644
Epoch [5/100], Step [2810/3236], Loss: 2.0867, Perplexity: 8.0580
Epoch [5/100], Step [2820/3236], Loss: 2.1809, Perplexity: 8.8538
Epoch [5/100], Step [2830/3236], Loss: 2.0607, Perplexity: 7.8518
Epoch [5/100], Step [2840/3236], Loss: 2.1202, Perplexity: 8.3324
Epoch [5/100], Step [2850/3236], Loss: 2.1295, Perplexity: 8.4107
Epoch [5/100], Step [2860/3236], Loss: 2.1349, Perplexity: 8.4564
Epoch [5/100], Step [2870/3236], Loss: 2.2416, Perplexity: 9.4087
Epoch [5/100], Step [2880/3236], Loss: 2.1185, Perplexity: 8.3183
Epoch [5/100], Step [2890/3236], Loss: 2.1157, Perplexity: 8.2958
Epoch [5/100], Step [2900/3236], Loss: 2.1570, Perplexity: 8.6453
Epoch [5/100], Step [2910/3236], Loss: 2.2680, Perplexity: 9.6603
Epoch [5/100], Step [2920/3236], Loss: 2.0642, Perplexity: 7.8792
Epoch [5/100], Step [2930/3236], Loss: 2.1104, Perplexity: 8.2516
Epoch [5/100], Step [2940/3236], Loss: 2.1844, Perplexity: 8.8853
Epoch [5/100], Step [2950/3236], Loss: 2.2533, Perplexity: 9.5193
Epoch [5/100], Step [2960/3236], Loss: 2.0428, Perplexity: 7.7125
Epoch [5/100], Step [2970/3236], Loss: 2.0411, Perplexity: 7.6991
Epoch [5/100], Step [2980/3236], Loss: 2.1218, Perplexity: 8.3463
Epoch [5/100], Step [2990/3236], Loss: 2.1535, Perplexity: 8.6150
Epoch [5/100], Step [3000/3236], Loss: 2.2767, Perplexity: 9.7445
Epoch [5/100], Step [3010/3236], Loss: 2.1002, Perplexity: 8.1681
Epoch [5/100], Step [3020/3236], Loss: 2.1727, Perplexity: 8.7824
Epoch [5/100], Step [3030/3236], Loss: 2.2295, Perplexity: 9.2954
Epoch [5/100], Step [3040/3236], Loss: 2.1910, Perplexity: 8.9439
Epoch [5/100], Step [3050/3236], Loss: 2.1938, Perplexity: 8.9694
Epoch [5/100], Step [3060/3236], Loss: 1.9644, Perplexity: 7.1304
Epoch [5/100], Step [3070/3236], Loss: 2.2180, Perplexity: 9.1891
Epoch [5/100], Step [3080/3236], Loss: 2.1865, Perplexity: 8.9041
Epoch [5/100], Step [3090/3236], Loss: 2.2142, Perplexity: 9.1541
Epoch [5/100], Step [3100/3236], Loss: 2.1433, Perplexity: 8.5278
Epoch [5/100], Step [3110/3236], Loss: 2.1589, Perplexity: 8.6615
Epoch [5/100], Step [3120/3236], Loss: 2.1962, Perplexity: 8.9904
Epoch [5/100], Step [3130/3236], Loss: 2.1198, Perplexity: 8.3296
Epoch [5/100], Step [3140/3236], Loss: 2.0904, Perplexity: 8.0881
Epoch [5/100], Step [3150/3236], Loss: 2.1322, Perplexity: 8.4333
Epoch [5/100], Step [3160/3236], Loss: 2.1371, Perplexity: 8.4746
Epoch [5/100], Step [3170/3236], Loss: 2.3172, Perplexity: 10.1473
Epoch [5/100], Step [3180/3236], Loss: 2.1714, Perplexity: 8.7704
Epoch [5/100], Step [3190/3236], Loss: 2.1686, Perplexity: 8.7464
Epoch [5/100], Step [3200/3236], Loss: 2.1165, Perplexity: 8.3016
Epoch [5/100], Step [3210/3236], Loss: 2.2093, Perplexity: 9.1098
Epoch [5/100], Step [3220/3236], Loss: 2.1849, Perplexity: 8.8902
Epoch [5/100], Step [3230/3236], Loss: 2.1131, Perplexity: 8.2737
start evaluate ...
466981 : a man is standing in the street with his dog
113606 : a person para sailing in the ocean on a clear day
272391 : a group of people standing around a table with a large white cake
76384 : a plate of food and a glass of wine
143560 : a white and black fire hydrant sitting on a corner of a room
47916 : a dog and a dog are in the grass
191169 : a woman is standing in front of a large black and white cat
283168 : a plastic container with a plastic container of food in it
232993 : a baby is eating a piece of pizza
144202 : a table with a plate of food and a cup of coffee
loading annotations into memory...
Done (t=0.75s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1545550.04 tokens per second.
PTBTokenizer tokenized 53110 tokens at 603679.71 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 47733, 'guess': [48111, 43111, 38111, 33111], 'testlen': 48111, 'correct': [32651, 15703, 6738, 2863]}
('ratio:', 1.0079190497140134)
Bleu_1: 0.679
Bleu_2: 0.497
Bleu_3: 0.352
Bleu_4: 0.248
computing METEOR score...
METEOR: 0.224
computing Rouge score...
ROUGE_L: 0.494
computing CIDEr score...
CIDEr: 0.793
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [28.913 seconds]
SPICE evaluation took: 38.61 s
SPICE: 0.156
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [6/100], Step [10/3236], Loss: 2.1802, Perplexity: 8.8477
Epoch [6/100], Step [20/3236], Loss: 2.0539, Perplexity: 7.7985
Epoch [6/100], Step [30/3236], Loss: 2.0279, Perplexity: 7.5980
Epoch [6/100], Step [40/3236], Loss: 2.0295, Perplexity: 7.6102
Epoch [6/100], Step [50/3236], Loss: 2.1189, Perplexity: 8.3216
Epoch [6/100], Step [60/3236], Loss: 2.0684, Perplexity: 7.9119
Epoch [6/100], Step [70/3236], Loss: 2.0311, Perplexity: 7.6222
Epoch [6/100], Step [80/3236], Loss: 2.0331, Perplexity: 7.6378
Epoch [6/100], Step [90/3236], Loss: 2.1112, Perplexity: 8.2585
Epoch [6/100], Step [100/3236], Loss: 2.0909, Perplexity: 8.0925
Epoch [6/100], Step [110/3236], Loss: 2.0036, Perplexity: 7.4155
Epoch [6/100], Step [120/3236], Loss: 1.9252, Perplexity: 6.8565
Epoch [6/100], Step [130/3236], Loss: 2.0827, Perplexity: 8.0259
Epoch [6/100], Step [140/3236], Loss: 2.1562, Perplexity: 8.6382
Epoch [6/100], Step [150/3236], Loss: 2.0487, Perplexity: 7.7574
Epoch [6/100], Step [160/3236], Loss: 2.1074, Perplexity: 8.2267
Epoch [6/100], Step [170/3236], Loss: 2.0573, Perplexity: 7.8246
Epoch [6/100], Step [180/3236], Loss: 2.0096, Perplexity: 7.4605
Epoch [6/100], Step [190/3236], Loss: 2.1674, Perplexity: 8.7355
Epoch [6/100], Step [200/3236], Loss: 2.0714, Perplexity: 7.9359
Epoch [6/100], Step [210/3236], Loss: 2.0471, Perplexity: 7.7451
Epoch [6/100], Step [220/3236], Loss: 2.0941, Perplexity: 8.1185
Epoch [6/100], Step [230/3236], Loss: 2.0990, Perplexity: 8.1576
Epoch [6/100], Step [240/3236], Loss: 2.0475, Perplexity: 7.7487
Epoch [6/100], Step [250/3236], Loss: 2.1240, Perplexity: 8.3648
Epoch [6/100], Step [260/3236], Loss: 1.9713, Perplexity: 7.1802
Epoch [6/100], Step [270/3236], Loss: 1.9913, Perplexity: 7.3252
Epoch [6/100], Step [280/3236], Loss: 1.9312, Perplexity: 6.8976
Epoch [6/100], Step [290/3236], Loss: 2.0283, Perplexity: 7.6015
Epoch [6/100], Step [300/3236], Loss: 2.0584, Perplexity: 7.8333
Epoch [6/100], Step [310/3236], Loss: 2.0080, Perplexity: 7.4487
Epoch [6/100], Step [320/3236], Loss: 2.1141, Perplexity: 8.2825
Epoch [6/100], Step [330/3236], Loss: 2.0734, Perplexity: 7.9517
Epoch [6/100], Step [340/3236], Loss: 2.0482, Perplexity: 7.7537
Epoch [6/100], Step [350/3236], Loss: 2.1410, Perplexity: 8.5078
Epoch [6/100], Step [360/3236], Loss: 1.9894, Perplexity: 7.3112
Epoch [6/100], Step [370/3236], Loss: 2.1321, Perplexity: 8.4326
Epoch [6/100], Step [380/3236], Loss: 1.8910, Perplexity: 6.6260
Epoch [6/100], Step [390/3236], Loss: 1.9880, Perplexity: 7.3012
Epoch [6/100], Step [400/3236], Loss: 2.1382, Perplexity: 8.4840
Epoch [6/100], Step [410/3236], Loss: 2.1319, Perplexity: 8.4309
Epoch [6/100], Step [420/3236], Loss: 2.0296, Perplexity: 7.6112
Epoch [6/100], Step [430/3236], Loss: 2.0523, Perplexity: 7.7856
Epoch [6/100], Step [440/3236], Loss: 2.0565, Perplexity: 7.8186
Epoch [6/100], Step [450/3236], Loss: 2.1755, Perplexity: 8.8066
Epoch [6/100], Step [460/3236], Loss: 2.1204, Perplexity: 8.3342
Epoch [6/100], Step [470/3236], Loss: 2.0078, Perplexity: 7.4471
Epoch [6/100], Step [480/3236], Loss: 2.0970, Perplexity: 8.1420
Epoch [6/100], Step [490/3236], Loss: 2.0300, Perplexity: 7.6140
Epoch [6/100], Step [500/3236], Loss: 2.0933, Perplexity: 8.1119
Epoch [6/100], Step [510/3236], Loss: 2.1390, Perplexity: 8.4910
Epoch [6/100], Step [520/3236], Loss: 1.9854, Perplexity: 7.2822
Epoch [6/100], Step [530/3236], Loss: 2.0218, Perplexity: 7.5517
Epoch [6/100], Step [540/3236], Loss: 2.1309, Perplexity: 8.4222
Epoch [6/100], Step [550/3236], Loss: 2.0788, Perplexity: 7.9949
Epoch [6/100], Step [560/3236], Loss: 2.1622, Perplexity: 8.6901
Epoch [6/100], Step [570/3236], Loss: 2.0608, Perplexity: 7.8526
Epoch [6/100], Step [580/3236], Loss: 2.0064, Perplexity: 7.4366
Epoch [6/100], Step [590/3236], Loss: 2.0422, Perplexity: 7.7074
Epoch [6/100], Step [600/3236], Loss: 2.1297, Perplexity: 8.4125
Epoch [6/100], Step [610/3236], Loss: 2.1010, Perplexity: 8.1747
Epoch [6/100], Step [620/3236], Loss: 1.9688, Perplexity: 7.1617
Epoch [6/100], Step [630/3236], Loss: 2.0961, Perplexity: 8.1340
Epoch [6/100], Step [640/3236], Loss: 2.1174, Perplexity: 8.3099
Epoch [6/100], Step [650/3236], Loss: 2.1793, Perplexity: 8.8397
Epoch [6/100], Step [660/3236], Loss: 2.1651, Perplexity: 8.7153
Epoch [6/100], Step [670/3236], Loss: 1.9567, Perplexity: 7.0758
Epoch [6/100], Step [680/3236], Loss: 2.0875, Perplexity: 8.0644
Epoch [6/100], Step [690/3236], Loss: 1.9654, Perplexity: 7.1376
Epoch [6/100], Step [700/3236], Loss: 2.0567, Perplexity: 7.8201
Epoch [6/100], Step [710/3236], Loss: 2.0356, Perplexity: 7.6569
Epoch [6/100], Step [720/3236], Loss: 2.0568, Perplexity: 7.8206
Epoch [6/100], Step [730/3236], Loss: 2.1139, Perplexity: 8.2808
Epoch [6/100], Step [740/3236], Loss: 2.2686, Perplexity: 9.6654
Epoch [6/100], Step [750/3236], Loss: 1.9962, Perplexity: 7.3612
Epoch [6/100], Step [760/3236], Loss: 2.1626, Perplexity: 8.6937
Epoch [6/100], Step [770/3236], Loss: 2.0752, Perplexity: 7.9663
Epoch [6/100], Step [780/3236], Loss: 2.0993, Perplexity: 8.1608
Epoch [6/100], Step [790/3236], Loss: 2.0934, Perplexity: 8.1127
Epoch [6/100], Step [800/3236], Loss: 2.2547, Perplexity: 9.5321
Epoch [6/100], Step [810/3236], Loss: 1.9532, Perplexity: 7.0513
Epoch [6/100], Step [820/3236], Loss: 2.1306, Perplexity: 8.4196
Epoch [6/100], Step [830/3236], Loss: 2.0418, Perplexity: 7.7047
Epoch [6/100], Step [840/3236], Loss: 2.1156, Perplexity: 8.2949
Epoch [6/100], Step [850/3236], Loss: 1.9632, Perplexity: 7.1219
Epoch [6/100], Step [860/3236], Loss: 2.0556, Perplexity: 7.8119
Epoch [6/100], Step [870/3236], Loss: 2.1379, Perplexity: 8.4818
Epoch [6/100], Step [880/3236], Loss: 2.0884, Perplexity: 8.0720
Epoch [6/100], Step [890/3236], Loss: 1.9849, Perplexity: 7.2784
Epoch [6/100], Step [900/3236], Loss: 2.0389, Perplexity: 7.6820
Epoch [6/100], Step [910/3236], Loss: 2.0520, Perplexity: 7.7837
Epoch [6/100], Step [920/3236], Loss: 2.1329, Perplexity: 8.4396
Epoch [6/100], Step [930/3236], Loss: 2.0167, Perplexity: 7.5132
Epoch [6/100], Step [940/3236], Loss: 2.0928, Perplexity: 8.1077
Epoch [6/100], Step [950/3236], Loss: 2.0567, Perplexity: 7.8204
Epoch [6/100], Step [960/3236], Loss: 2.1428, Perplexity: 8.5235
Epoch [6/100], Step [970/3236], Loss: 2.1367, Perplexity: 8.4713
Epoch [6/100], Step [980/3236], Loss: 1.9964, Perplexity: 7.3628
Epoch [6/100], Step [990/3236], Loss: 1.9822, Perplexity: 7.2584
Epoch [6/100], Step [1000/3236], Loss: 2.2389, Perplexity: 9.3834
Epoch [6/100], Step [1010/3236], Loss: 2.0975, Perplexity: 8.1456
Epoch [6/100], Step [1020/3236], Loss: 2.0768, Perplexity: 7.9789
Epoch [6/100], Step [1030/3236], Loss: 2.0967, Perplexity: 8.1393
Epoch [6/100], Step [1040/3236], Loss: 1.8753, Perplexity: 6.5230
Epoch [6/100], Step [1050/3236], Loss: 2.0372, Perplexity: 7.6690
Epoch [6/100], Step [1060/3236], Loss: 2.0698, Perplexity: 7.9235
Epoch [6/100], Step [1070/3236], Loss: 1.9969, Perplexity: 7.3659
Epoch [6/100], Step [1080/3236], Loss: 2.0080, Perplexity: 7.4486
Epoch [6/100], Step [1090/3236], Loss: 2.2226, Perplexity: 9.2312
Epoch [6/100], Step [1100/3236], Loss: 2.1105, Perplexity: 8.2528
Epoch [6/100], Step [1110/3236], Loss: 2.0836, Perplexity: 8.0334
Epoch [6/100], Step [1120/3236], Loss: 2.1554, Perplexity: 8.6309
Epoch [6/100], Step [1130/3236], Loss: 2.1227, Perplexity: 8.3537
Epoch [6/100], Step [1140/3236], Loss: 2.0907, Perplexity: 8.0904
Epoch [6/100], Step [1150/3236], Loss: 2.0977, Perplexity: 8.1476
Epoch [6/100], Step [1160/3236], Loss: 2.1677, Perplexity: 8.7378
Epoch [6/100], Step [1170/3236], Loss: 2.0834, Perplexity: 8.0316
Epoch [6/100], Step [1180/3236], Loss: 2.0671, Perplexity: 7.9020
Epoch [6/100], Step [1190/3236], Loss: 2.0551, Perplexity: 7.8078
Epoch [6/100], Step [1200/3236], Loss: 2.0654, Perplexity: 7.8883
Epoch [6/100], Step [1210/3236], Loss: 2.0768, Perplexity: 7.9786
Epoch [6/100], Step [1220/3236], Loss: 2.0850, Perplexity: 8.0450
Epoch [6/100], Step [1230/3236], Loss: 2.0061, Perplexity: 7.4346
Epoch [6/100], Step [1240/3236], Loss: 2.0373, Perplexity: 7.6698
Epoch [6/100], Step [1250/3236], Loss: 2.1186, Perplexity: 8.3199
Epoch [6/100], Step [1260/3236], Loss: 2.1224, Perplexity: 8.3516
Epoch [6/100], Step [1270/3236], Loss: 2.0390, Perplexity: 7.6832
Epoch [6/100], Step [1280/3236], Loss: 2.0085, Perplexity: 7.4521
Epoch [6/100], Step [1290/3236], Loss: 2.1077, Perplexity: 8.2296
Epoch [6/100], Step [1300/3236], Loss: 1.9300, Perplexity: 6.8897
Epoch [6/100], Step [1310/3236], Loss: 2.1505, Perplexity: 8.5893
Epoch [6/100], Step [1320/3236], Loss: 2.0848, Perplexity: 8.0426
Epoch [6/100], Step [1330/3236], Loss: 2.0421, Perplexity: 7.7067
Epoch [6/100], Step [1340/3236], Loss: 2.0215, Perplexity: 7.5498
Epoch [6/100], Step [1350/3236], Loss: 1.8693, Perplexity: 6.4839
Epoch [6/100], Step [1360/3236], Loss: 2.0828, Perplexity: 8.0269
Epoch [6/100], Step [1370/3236], Loss: 1.9956, Perplexity: 7.3564
Epoch [6/100], Step [1380/3236], Loss: 2.0681, Perplexity: 7.9101
Epoch [6/100], Step [1390/3236], Loss: 2.1641, Perplexity: 8.7069
Epoch [6/100], Step [1400/3236], Loss: 2.1264, Perplexity: 8.3845
Epoch [6/100], Step [1410/3236], Loss: 2.2404, Perplexity: 9.3973
Epoch [6/100], Step [1420/3236], Loss: 2.0026, Perplexity: 7.4083
Epoch [6/100], Step [1430/3236], Loss: 2.1052, Perplexity: 8.2084
Epoch [6/100], Step [1440/3236], Loss: 2.0279, Perplexity: 7.5980
Epoch [6/100], Step [1450/3236], Loss: 2.1264, Perplexity: 8.3850
Epoch [6/100], Step [1460/3236], Loss: 2.1061, Perplexity: 8.2161
Epoch [6/100], Step [1470/3236], Loss: 2.1546, Perplexity: 8.6247
Epoch [6/100], Step [1480/3236], Loss: 2.0777, Perplexity: 7.9862
Epoch [6/100], Step [1490/3236], Loss: 2.1431, Perplexity: 8.5255
Epoch [6/100], Step [1500/3236], Loss: 1.9728, Perplexity: 7.1909
Epoch [6/100], Step [1510/3236], Loss: 2.1034, Perplexity: 8.1941
Epoch [6/100], Step [1520/3236], Loss: 2.0344, Perplexity: 7.6477
Epoch [6/100], Step [1530/3236], Loss: 2.0474, Perplexity: 7.7476
Epoch [6/100], Step [1540/3236], Loss: 2.1043, Perplexity: 8.2016
Epoch [6/100], Step [1550/3236], Loss: 2.0496, Perplexity: 7.7650
Epoch [6/100], Step [1560/3236], Loss: 2.0826, Perplexity: 8.0255
Epoch [6/100], Step [1570/3236], Loss: 1.9563, Perplexity: 7.0732
Epoch [6/100], Step [1580/3236], Loss: 2.1728, Perplexity: 8.7830
Epoch [6/100], Step [1590/3236], Loss: 1.9751, Perplexity: 7.2074
Epoch [6/100], Step [1600/3236], Loss: 2.1263, Perplexity: 8.3834
Epoch [6/100], Step [1610/3236], Loss: 2.0365, Perplexity: 7.6634
Epoch [6/100], Step [1620/3236], Loss: 1.9970, Perplexity: 7.3670
Epoch [6/100], Step [1630/3236], Loss: 2.2005, Perplexity: 9.0293
Epoch [6/100], Step [1640/3236], Loss: 2.1174, Perplexity: 8.3099
Epoch [6/100], Step [1650/3236], Loss: 2.0356, Perplexity: 7.6568
Epoch [6/100], Step [1660/3236], Loss: 2.1551, Perplexity: 8.6285
Epoch [6/100], Step [1670/3236], Loss: 2.1711, Perplexity: 8.7682
Epoch [6/100], Step [1680/3236], Loss: 2.0713, Perplexity: 7.9353
Epoch [6/100], Step [1690/3236], Loss: 2.1079, Perplexity: 8.2310
Epoch [6/100], Step [1700/3236], Loss: 2.0741, Perplexity: 7.9576
Epoch [6/100], Step [1710/3236], Loss: 2.0911, Perplexity: 8.0939
Epoch [6/100], Step [1720/3236], Loss: 2.0777, Perplexity: 7.9860
Epoch [6/100], Step [1730/3236], Loss: 2.1831, Perplexity: 8.8742
Epoch [6/100], Step [1740/3236], Loss: 2.0766, Perplexity: 7.9771
Epoch [6/100], Step [1750/3236], Loss: 1.9873, Perplexity: 7.2957
Epoch [6/100], Step [1760/3236], Loss: 1.9663, Perplexity: 7.1441
Epoch [6/100], Step [1770/3236], Loss: 2.1066, Perplexity: 8.2204
Epoch [6/100], Step [1780/3236], Loss: 2.0518, Perplexity: 7.7822
Epoch [6/100], Step [1790/3236], Loss: 2.0246, Perplexity: 7.5730
Epoch [6/100], Step [1800/3236], Loss: 1.9979, Perplexity: 7.3734
Epoch [6/100], Step [1810/3236], Loss: 2.2729, Perplexity: 9.7074
Epoch [6/100], Step [1820/3236], Loss: 2.1680, Perplexity: 8.7408
Epoch [6/100], Step [1830/3236], Loss: 2.0915, Perplexity: 8.0967
Epoch [6/100], Step [1840/3236], Loss: 1.9674, Perplexity: 7.1519
Epoch [6/100], Step [1850/3236], Loss: 2.1353, Perplexity: 8.4595
Epoch [6/100], Step [1860/3236], Loss: 2.2834, Perplexity: 9.8101
Epoch [6/100], Step [1870/3236], Loss: 2.0642, Perplexity: 7.8788
Epoch [6/100], Step [1880/3236], Loss: 2.1374, Perplexity: 8.4773
Epoch [6/100], Step [1890/3236], Loss: 2.0149, Perplexity: 7.4999
Epoch [6/100], Step [1900/3236], Loss: 2.0501, Perplexity: 7.7690
Epoch [6/100], Step [1910/3236], Loss: 2.0169, Perplexity: 7.5152
Epoch [6/100], Step [1920/3236], Loss: 2.1105, Perplexity: 8.2526
Epoch [6/100], Step [1930/3236], Loss: 2.0734, Perplexity: 7.9521
Epoch [6/100], Step [1940/3236], Loss: 2.0338, Perplexity: 7.6432
Epoch [6/100], Step [1950/3236], Loss: 2.0442, Perplexity: 7.7232
Epoch [6/100], Step [1960/3236], Loss: 2.1299, Perplexity: 8.4137
Epoch [6/100], Step [1970/3236], Loss: 1.9917, Perplexity: 7.3283
Epoch [6/100], Step [1980/3236], Loss: 2.1069, Perplexity: 8.2231
Epoch [6/100], Step [1990/3236], Loss: 1.9377, Perplexity: 6.9428
Epoch [6/100], Step [2000/3236], Loss: 2.0741, Perplexity: 7.9570
Epoch [6/100], Step [2010/3236], Loss: 2.0784, Perplexity: 7.9920
Epoch [6/100], Step [2020/3236], Loss: 2.1157, Perplexity: 8.2957
Epoch [6/100], Step [2030/3236], Loss: 2.0020, Perplexity: 7.4040
Epoch [6/100], Step [2040/3236], Loss: 2.0055, Perplexity: 7.4299
Epoch [6/100], Step [2050/3236], Loss: 2.1608, Perplexity: 8.6780
Epoch [6/100], Step [2060/3236], Loss: 2.0498, Perplexity: 7.7667
Epoch [6/100], Step [2070/3236], Loss: 2.0761, Perplexity: 7.9735
Epoch [6/100], Step [2080/3236], Loss: 1.9937, Perplexity: 7.3426
Epoch [6/100], Step [2090/3236], Loss: 2.0168, Perplexity: 7.5141
Epoch [6/100], Step [2100/3236], Loss: 2.1097, Perplexity: 8.2459
Epoch [6/100], Step [2110/3236], Loss: 2.0941, Perplexity: 8.1184
Epoch [6/100], Step [2120/3236], Loss: 2.0759, Perplexity: 7.9713
Epoch [6/100], Step [2130/3236], Loss: 2.1187, Perplexity: 8.3206
Epoch [6/100], Step [2140/3236], Loss: 2.0737, Perplexity: 7.9541
Epoch [6/100], Step [2150/3236], Loss: 2.0677, Perplexity: 7.9066
Epoch [6/100], Step [2160/3236], Loss: 2.0378, Perplexity: 7.6741
Epoch [6/100], Step [2170/3236], Loss: 1.9159, Perplexity: 6.7930
Epoch [6/100], Step [2180/3236], Loss: 2.0390, Perplexity: 7.6829
Epoch [6/100], Step [2190/3236], Loss: 2.1410, Perplexity: 8.5075
Epoch [6/100], Step [2200/3236], Loss: 1.9947, Perplexity: 7.3502
Epoch [6/100], Step [2210/3236], Loss: 2.0432, Perplexity: 7.7155
Epoch [6/100], Step [2220/3236], Loss: 1.9542, Perplexity: 7.0583
Epoch [6/100], Step [2230/3236], Loss: 2.1203, Perplexity: 8.3334
Epoch [6/100], Step [2240/3236], Loss: 2.1275, Perplexity: 8.3936
Epoch [6/100], Step [2250/3236], Loss: 2.0646, Perplexity: 7.8819
Epoch [6/100], Step [2260/3236], Loss: 2.1445, Perplexity: 8.5374
Epoch [6/100], Step [2270/3236], Loss: 2.0247, Perplexity: 7.5739
Epoch [6/100], Step [2280/3236], Loss: 2.2220, Perplexity: 9.2255
Epoch [6/100], Step [2290/3236], Loss: 2.1634, Perplexity: 8.7010
Epoch [6/100], Step [2300/3236], Loss: 2.1777, Perplexity: 8.8258
Epoch [6/100], Step [2310/3236], Loss: 2.0561, Perplexity: 7.8155
Epoch [6/100], Step [2320/3236], Loss: 2.1228, Perplexity: 8.3548
Epoch [6/100], Step [2330/3236], Loss: 2.1608, Perplexity: 8.6777
Epoch [6/100], Step [2340/3236], Loss: 2.1030, Perplexity: 8.1903
Epoch [6/100], Step [2350/3236], Loss: 2.0993, Perplexity: 8.1603
Epoch [6/100], Step [2360/3236], Loss: 2.0996, Perplexity: 8.1633
Epoch [6/100], Step [2370/3236], Loss: 2.1169, Perplexity: 8.3050
Epoch [6/100], Step [2380/3236], Loss: 2.1213, Perplexity: 8.3419
Epoch [6/100], Step [2390/3236], Loss: 2.0950, Perplexity: 8.1251
Epoch [6/100], Step [2400/3236], Loss: 2.0919, Perplexity: 8.1005
Epoch [6/100], Step [2410/3236], Loss: 2.1110, Perplexity: 8.2569
Epoch [6/100], Step [2420/3236], Loss: 1.9871, Perplexity: 7.2943
Epoch [6/100], Step [2430/3236], Loss: 2.1459, Perplexity: 8.5496
Epoch [6/100], Step [2440/3236], Loss: 1.9726, Perplexity: 7.1891
Epoch [6/100], Step [2450/3236], Loss: 2.1232, Perplexity: 8.3576
Epoch [6/100], Step [2460/3236], Loss: 2.0295, Perplexity: 7.6104
Epoch [6/100], Step [2470/3236], Loss: 2.0628, Perplexity: 7.8676
Epoch [6/100], Step [2480/3236], Loss: 2.1268, Perplexity: 8.3881
Epoch [6/100], Step [2490/3236], Loss: 2.0986, Perplexity: 8.1546
Epoch [6/100], Step [2500/3236], Loss: 2.0388, Perplexity: 7.6810
Epoch [6/100], Step [2510/3236], Loss: 2.0597, Perplexity: 7.8438
Epoch [6/100], Step [2520/3236], Loss: 2.1445, Perplexity: 8.5381
Epoch [6/100], Step [2530/3236], Loss: 2.2591, Perplexity: 9.5748
Epoch [6/100], Step [2540/3236], Loss: 2.1604, Perplexity: 8.6749
Epoch [6/100], Step [2550/3236], Loss: 2.1582, Perplexity: 8.6559
Epoch [6/100], Step [2560/3236], Loss: 2.0503, Perplexity: 7.7699
Epoch [6/100], Step [2570/3236], Loss: 2.1198, Perplexity: 8.3298
Epoch [6/100], Step [2580/3236], Loss: 2.1671, Perplexity: 8.7327
Epoch [6/100], Step [2590/3236], Loss: 1.9067, Perplexity: 6.7305
Epoch [6/100], Step [2600/3236], Loss: 2.1123, Perplexity: 8.2672
Epoch [6/100], Step [2610/3236], Loss: 1.9671, Perplexity: 7.1500
Epoch [6/100], Step [2620/3236], Loss: 2.0598, Perplexity: 7.8447
Epoch [6/100], Step [2630/3236], Loss: 2.2368, Perplexity: 9.3635
Epoch [6/100], Step [2640/3236], Loss: 2.1234, Perplexity: 8.3596
Epoch [6/100], Step [2650/3236], Loss: 2.0904, Perplexity: 8.0886
Epoch [6/100], Step [2660/3236], Loss: 2.0588, Perplexity: 7.8367
Epoch [6/100], Step [2670/3236], Loss: 2.1516, Perplexity: 8.5990
Epoch [6/100], Step [2680/3236], Loss: 2.0480, Perplexity: 7.7524
Epoch [6/100], Step [2690/3236], Loss: 2.1216, Perplexity: 8.3447
Epoch [6/100], Step [2700/3236], Loss: 2.0445, Perplexity: 7.7251
Epoch [6/100], Step [2710/3236], Loss: 1.9887, Perplexity: 7.3060
Epoch [6/100], Step [2720/3236], Loss: 2.0863, Perplexity: 8.0551
Epoch [6/100], Step [2730/3236], Loss: 2.1779, Perplexity: 8.8278
Epoch [6/100], Step [2740/3236], Loss: 2.1484, Perplexity: 8.5715
Epoch [6/100], Step [2750/3236], Loss: 2.0871, Perplexity: 8.0612
Epoch [6/100], Step [2760/3236], Loss: 2.2316, Perplexity: 9.3148
Epoch [6/100], Step [2770/3236], Loss: 2.1278, Perplexity: 8.3966
Epoch [6/100], Step [2780/3236], Loss: 2.0044, Perplexity: 7.4220
Epoch [6/100], Step [2790/3236], Loss: 2.1590, Perplexity: 8.6626
Epoch [6/100], Step [2800/3236], Loss: 2.1237, Perplexity: 8.3621
Epoch [6/100], Step [2810/3236], Loss: 2.0159, Perplexity: 7.5076
Epoch [6/100], Step [2820/3236], Loss: 2.1567, Perplexity: 8.6428
Epoch [6/100], Step [2830/3236], Loss: 2.0644, Perplexity: 7.8803
Epoch [6/100], Step [2840/3236], Loss: 2.1706, Perplexity: 8.7635
Epoch [6/100], Step [2850/3236], Loss: 2.0981, Perplexity: 8.1505
Epoch [6/100], Step [2860/3236], Loss: 2.2197, Perplexity: 9.2048
Epoch [6/100], Step [2870/3236], Loss: 2.1244, Perplexity: 8.3677
Epoch [6/100], Step [2880/3236], Loss: 2.3120, Perplexity: 10.0950
Epoch [6/100], Step [2890/3236], Loss: 1.9615, Perplexity: 7.1101
Epoch [6/100], Step [2900/3236], Loss: 2.0506, Perplexity: 7.7724
Epoch [6/100], Step [2910/3236], Loss: 2.0867, Perplexity: 8.0580
Epoch [6/100], Step [2920/3236], Loss: 2.0611, Perplexity: 7.8548
Epoch [6/100], Step [2930/3236], Loss: 1.9704, Perplexity: 7.1733
Epoch [6/100], Step [2940/3236], Loss: 2.1698, Perplexity: 8.7568
Epoch [6/100], Step [2950/3236], Loss: 1.9753, Perplexity: 7.2086
Epoch [6/100], Step [2960/3236], Loss: 2.1160, Perplexity: 8.2983
Epoch [6/100], Step [2970/3236], Loss: 2.1015, Perplexity: 8.1781
Epoch [6/100], Step [2980/3236], Loss: 2.0441, Perplexity: 7.7219
Epoch [6/100], Step [2990/3236], Loss: 1.9833, Perplexity: 7.2665
Epoch [6/100], Step [3000/3236], Loss: 1.9903, Perplexity: 7.3179
Epoch [6/100], Step [3010/3236], Loss: 2.1605, Perplexity: 8.6752
Epoch [6/100], Step [3020/3236], Loss: 2.1843, Perplexity: 8.8841
Epoch [6/100], Step [3030/3236], Loss: 2.0481, Perplexity: 7.7534
Epoch [6/100], Step [3040/3236], Loss: 2.0881, Perplexity: 8.0694
Epoch [6/100], Step [3050/3236], Loss: 2.0774, Perplexity: 7.9836
Epoch [6/100], Step [3060/3236], Loss: 2.1764, Perplexity: 8.8146
Epoch [6/100], Step [3070/3236], Loss: 2.0217, Perplexity: 7.5510
Epoch [6/100], Step [3080/3236], Loss: 2.1230, Perplexity: 8.3565
Epoch [6/100], Step [3090/3236], Loss: 2.0500, Perplexity: 7.7676
Epoch [6/100], Step [3100/3236], Loss: 2.0665, Perplexity: 7.8974
Epoch [6/100], Step [3110/3236], Loss: 2.0261, Perplexity: 7.5845
Epoch [6/100], Step [3120/3236], Loss: 2.2879, Perplexity: 9.8547
Epoch [6/100], Step [3130/3236], Loss: 2.0348, Perplexity: 7.6507
Epoch [6/100], Step [3140/3236], Loss: 2.1827, Perplexity: 8.8699
Epoch [6/100], Step [3150/3236], Loss: 2.0760, Perplexity: 7.9722
Epoch [6/100], Step [3160/3236], Loss: 2.2309, Perplexity: 9.3083
Epoch [6/100], Step [3170/3236], Loss: 2.0338, Perplexity: 7.6429
Epoch [6/100], Step [3180/3236], Loss: 2.2622, Perplexity: 9.6038
Epoch [6/100], Step [3190/3236], Loss: 2.1375, Perplexity: 8.4779
Epoch [6/100], Step [3200/3236], Loss: 2.0722, Perplexity: 7.9420
Epoch [6/100], Step [3210/3236], Loss: 2.1175, Perplexity: 8.3107
Epoch [6/100], Step [3220/3236], Loss: 2.1314, Perplexity: 8.4264
Epoch [6/100], Step [3230/3236], Loss: 2.0312, Perplexity: 7.6235
start evaluate ...
233483 : a man and woman sitting at a table with a laptop
327656 : a truck with a large crane on the back of it
218012 : a plate with a piece of cake and a fork
41257 : two cats laying on a bed with a blanket
412639 : a man is walking down the street with a bus
277025 : a man sitting at a table with a plate of food
350799 : a bathroom with a toilet and a sink
389869 : a man on a beach with a surfboard
304389 : a bathroom with a sink mirror and toilet
34869 : a sandwich is sitting on a table next to a soda
loading annotations into memory...
Done (t=0.71s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1571808.59 tokens per second.
PTBTokenizer tokenized 53604 tokens at 635692.54 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48153, 'guess': [48605, 43605, 38605, 33605], 'testlen': 48605, 'correct': [32693, 15814, 6798, 2909]}
('ratio:', 1.009386746412456)
Bleu_1: 0.673
Bleu_2: 0.494
Bleu_3: 0.350
Bleu_4: 0.247
computing METEOR score...
METEOR: 0.227
computing Rouge score...
ROUGE_L: 0.495
computing CIDEr score...
CIDEr: 0.793
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].
Threads( StanfordCoreNLP ) [27.398 seconds]
SPICE evaluation took: 38.94 s
SPICE: 0.155
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [7/100], Step [10/3236], Loss: 2.0130, Perplexity: 7.4858
Epoch [7/100], Step [20/3236], Loss: 1.9513, Perplexity: 7.0376
Epoch [7/100], Step [30/3236], Loss: 2.1126, Perplexity: 8.2698
Epoch [7/100], Step [40/3236], Loss: 2.0285, Perplexity: 7.6024
Epoch [7/100], Step [50/3236], Loss: 1.9219, Perplexity: 6.8341
Epoch [7/100], Step [60/3236], Loss: 1.8779, Perplexity: 6.5400
Epoch [7/100], Step [70/3236], Loss: 1.9978, Perplexity: 7.3727
Epoch [7/100], Step [80/3236], Loss: 2.0891, Perplexity: 8.0773
Epoch [7/100], Step [90/3236], Loss: 1.9873, Perplexity: 7.2956
Epoch [7/100], Step [100/3236], Loss: 1.8692, Perplexity: 6.4831
Epoch [7/100], Step [110/3236], Loss: 2.0268, Perplexity: 7.5896
Epoch [7/100], Step [120/3236], Loss: 2.1600, Perplexity: 8.6715
Epoch [7/100], Step [130/3236], Loss: 1.9992, Perplexity: 7.3835
Epoch [7/100], Step [140/3236], Loss: 2.0721, Perplexity: 7.9418
Epoch [7/100], Step [150/3236], Loss: 2.0506, Perplexity: 7.7724
Epoch [7/100], Step [160/3236], Loss: 2.0420, Perplexity: 7.7060
Epoch [7/100], Step [170/3236], Loss: 1.9160, Perplexity: 6.7936
Epoch [7/100], Step [180/3236], Loss: 1.8806, Perplexity: 6.5576
Epoch [7/100], Step [190/3236], Loss: 1.9971, Perplexity: 7.3679
Epoch [7/100], Step [200/3236], Loss: 1.9500, Perplexity: 7.0288
Epoch [7/100], Step [210/3236], Loss: 1.9038, Perplexity: 6.7115
Epoch [7/100], Step [220/3236], Loss: 1.9261, Perplexity: 6.8625
Epoch [7/100], Step [230/3236], Loss: 2.0304, Perplexity: 7.6172
Epoch [7/100], Step [240/3236], Loss: 2.0269, Perplexity: 7.5901
Epoch [7/100], Step [250/3236], Loss: 2.0701, Perplexity: 7.9257
Epoch [7/100], Step [260/3236], Loss: 1.9944, Perplexity: 7.3474
Epoch [7/100], Step [270/3236], Loss: 2.1366, Perplexity: 8.4705
Epoch [7/100], Step [280/3236], Loss: 1.9442, Perplexity: 6.9881
Epoch [7/100], Step [290/3236], Loss: 2.0353, Perplexity: 7.6544
Epoch [7/100], Step [300/3236], Loss: 2.1626, Perplexity: 8.6938
Epoch [7/100], Step [310/3236], Loss: 2.0334, Perplexity: 7.6398
Epoch [7/100], Step [320/3236], Loss: 1.9642, Perplexity: 7.1294
Epoch [7/100], Step [330/3236], Loss: 1.9924, Perplexity: 7.3333
Epoch [7/100], Step [340/3236], Loss: 2.0519, Perplexity: 7.7829
Epoch [7/100], Step [350/3236], Loss: 1.9541, Perplexity: 7.0577
Epoch [7/100], Step [360/3236], Loss: 1.9433, Perplexity: 6.9818
Epoch [7/100], Step [370/3236], Loss: 1.9422, Perplexity: 6.9743
Epoch [7/100], Step [380/3236], Loss: 2.1572, Perplexity: 8.6470
Epoch [7/100], Step [390/3236], Loss: 1.9354, Perplexity: 6.9269
Epoch [7/100], Step [400/3236], Loss: 2.0569, Perplexity: 7.8214
Epoch [7/100], Step [410/3236], Loss: 2.0977, Perplexity: 8.1475
Epoch [7/100], Step [420/3236], Loss: 1.8560, Perplexity: 6.3981
Epoch [7/100], Step [430/3236], Loss: 1.9185, Perplexity: 6.8109
Epoch [7/100], Step [440/3236], Loss: 2.0291, Perplexity: 7.6071
Epoch [7/100], Step [450/3236], Loss: 1.9639, Perplexity: 7.1272
Epoch [7/100], Step [460/3236], Loss: 1.9799, Perplexity: 7.2421
Epoch [7/100], Step [470/3236], Loss: 2.0390, Perplexity: 7.6828
Epoch [7/100], Step [480/3236], Loss: 2.0883, Perplexity: 8.0713
Epoch [7/100], Step [490/3236], Loss: 1.9505, Perplexity: 7.0324
Epoch [7/100], Step [500/3236], Loss: 1.9847, Perplexity: 7.2767
Epoch [7/100], Step [510/3236], Loss: 1.9922, Perplexity: 7.3316
Epoch [7/100], Step [520/3236], Loss: 1.9116, Perplexity: 6.7639
Epoch [7/100], Step [530/3236], Loss: 1.9478, Perplexity: 7.0130
Epoch [7/100], Step [540/3236], Loss: 1.9369, Perplexity: 6.9369
Epoch [7/100], Step [550/3236], Loss: 2.0321, Perplexity: 7.6303
Epoch [7/100], Step [560/3236], Loss: 2.0436, Perplexity: 7.7186
Epoch [7/100], Step [570/3236], Loss: 2.0126, Perplexity: 7.4824
Epoch [7/100], Step [580/3236], Loss: 1.8742, Perplexity: 6.5159
Epoch [7/100], Step [590/3236], Loss: 1.9413, Perplexity: 6.9679
Epoch [7/100], Step [600/3236], Loss: 2.0672, Perplexity: 7.9029
Epoch [7/100], Step [610/3236], Loss: 2.0346, Perplexity: 7.6492
Epoch [7/100], Step [620/3236], Loss: 2.0459, Perplexity: 7.7361
Epoch [7/100], Step [630/3236], Loss: 1.9893, Perplexity: 7.3104
Epoch [7/100], Step [640/3236], Loss: 1.9397, Perplexity: 6.9567
Epoch [7/100], Step [650/3236], Loss: 2.0428, Perplexity: 7.7123
Epoch [7/100], Step [660/3236], Loss: 2.0028, Perplexity: 7.4095
Epoch [7/100], Step [670/3236], Loss: 2.0166, Perplexity: 7.5131
Epoch [7/100], Step [680/3236], Loss: 1.9914, Perplexity: 7.3254
Epoch [7/100], Step [690/3236], Loss: 1.9579, Perplexity: 7.0848
Epoch [7/100], Step [700/3236], Loss: 2.0350, Perplexity: 7.6520
Epoch [7/100], Step [710/3236], Loss: 1.9789, Perplexity: 7.2351
Epoch [7/100], Step [720/3236], Loss: 2.1010, Perplexity: 8.1740
Epoch [7/100], Step [730/3236], Loss: 2.0139, Perplexity: 7.4925
Epoch [7/100], Step [740/3236], Loss: 2.0012, Perplexity: 7.3977
Epoch [7/100], Step [750/3236], Loss: 2.0041, Perplexity: 7.4195
Epoch [7/100], Step [760/3236], Loss: 1.9867, Perplexity: 7.2915
Epoch [7/100], Step [770/3236], Loss: 2.0508, Perplexity: 7.7739
Epoch [7/100], Step [780/3236], Loss: 2.0759, Perplexity: 7.9721
Epoch [7/100], Step [790/3236], Loss: 2.0293, Perplexity: 7.6088
Epoch [7/100], Step [800/3236], Loss: 1.9875, Perplexity: 7.2975
Epoch [7/100], Step [810/3236], Loss: 2.0576, Perplexity: 7.8271
Epoch [7/100], Step [820/3236], Loss: 2.0345, Perplexity: 7.6484
Epoch [7/100], Step [830/3236], Loss: 2.0057, Perplexity: 7.4311
Epoch [7/100], Step [840/3236], Loss: 1.9258, Perplexity: 6.8604
Epoch [7/100], Step [850/3236], Loss: 2.1060, Perplexity: 8.2153
Epoch [7/100], Step [860/3236], Loss: 2.0200, Perplexity: 7.5384
Epoch [7/100], Step [870/3236], Loss: 1.9817, Perplexity: 7.2549
Epoch [7/100], Step [880/3236], Loss: 1.9787, Perplexity: 7.2337
Epoch [7/100], Step [890/3236], Loss: 2.0999, Perplexity: 8.1651
Epoch [7/100], Step [900/3236], Loss: 2.0021, Perplexity: 7.4048
Epoch [7/100], Step [910/3236], Loss: 1.9068, Perplexity: 6.7314
Epoch [7/100], Step [920/3236], Loss: 1.9896, Perplexity: 7.3130
Epoch [7/100], Step [930/3236], Loss: 2.0065, Perplexity: 7.4374
Epoch [7/100], Step [940/3236], Loss: 2.0232, Perplexity: 7.5628
Epoch [7/100], Step [950/3236], Loss: 2.1617, Perplexity: 8.6860
Epoch [7/100], Step [960/3236], Loss: 2.0508, Perplexity: 7.7739
Epoch [7/100], Step [970/3236], Loss: 1.9326, Perplexity: 6.9071
Epoch [7/100], Step [980/3236], Loss: 2.0378, Perplexity: 7.6738
Epoch [7/100], Step [990/3236], Loss: 2.0631, Perplexity: 7.8700
Epoch [7/100], Step [1000/3236], Loss: 2.0374, Perplexity: 7.6707
Epoch [7/100], Step [1010/3236], Loss: 1.9983, Perplexity: 7.3761
Epoch [7/100], Step [1020/3236], Loss: 2.0459, Perplexity: 7.7358
Epoch [7/100], Step [1030/3236], Loss: 2.0718, Perplexity: 7.9394
Epoch [7/100], Step [1040/3236], Loss: 1.8591, Perplexity: 6.4179
Epoch [7/100], Step [1050/3236], Loss: 1.8899, Perplexity: 6.6188
Epoch [7/100], Step [1060/3236], Loss: 2.0685, Perplexity: 7.9131
Epoch [7/100], Step [1070/3236], Loss: 1.9134, Perplexity: 6.7759
Epoch [7/100], Step [1080/3236], Loss: 1.8725, Perplexity: 6.5045
Epoch [7/100], Step [1090/3236], Loss: 2.1471, Perplexity: 8.5602
Epoch [7/100], Step [1100/3236], Loss: 2.0167, Perplexity: 7.5137
Epoch [7/100], Step [1110/3236], Loss: 1.9657, Perplexity: 7.1402
Epoch [7/100], Step [1120/3236], Loss: 2.0119, Perplexity: 7.4772
Epoch [7/100], Step [1130/3236], Loss: 1.9876, Perplexity: 7.2977
Epoch [7/100], Step [1140/3236], Loss: 2.1157, Perplexity: 8.2957
Epoch [7/100], Step [1150/3236], Loss: 2.0125, Perplexity: 7.4818
Epoch [7/100], Step [1160/3236], Loss: 2.0978, Perplexity: 8.1482
Epoch [7/100], Step [1170/3236], Loss: 2.0740, Perplexity: 7.9565
Epoch [7/100], Step [1180/3236], Loss: 1.9896, Perplexity: 7.3123
Epoch [7/100], Step [1190/3236], Loss: 2.1064, Perplexity: 8.2184
Epoch [7/100], Step [1200/3236], Loss: 1.9273, Perplexity: 6.8708
Epoch [7/100], Step [1210/3236], Loss: 2.0348, Perplexity: 7.6509
Epoch [7/100], Step [1220/3236], Loss: 2.0642, Perplexity: 7.8790
Epoch [7/100], Step [1230/3236], Loss: 2.0843, Perplexity: 8.0389
Epoch [7/100], Step [1240/3236], Loss: 1.9227, Perplexity: 6.8395
Epoch [7/100], Step [1250/3236], Loss: 2.1038, Perplexity: 8.1977
Epoch [7/100], Step [1260/3236], Loss: 2.0054, Perplexity: 7.4291
Epoch [7/100], Step [1270/3236], Loss: 1.9969, Perplexity: 7.3660
Epoch [7/100], Step [1280/3236], Loss: 1.9853, Perplexity: 7.2814
Epoch [7/100], Step [1290/3236], Loss: 2.0273, Perplexity: 7.5933
Epoch [7/100], Step [1300/3236], Loss: 1.9829, Perplexity: 7.2640
Epoch [7/100], Step [1310/3236], Loss: 2.0730, Perplexity: 7.9490
Epoch [7/100], Step [1320/3236], Loss: 2.0380, Perplexity: 7.6752
Epoch [7/100], Step [1330/3236], Loss: 1.9896, Perplexity: 7.3128
Epoch [7/100], Step [1340/3236], Loss: 1.9249, Perplexity: 6.8546
Epoch [7/100], Step [1350/3236], Loss: 2.0283, Perplexity: 7.6015
Epoch [7/100], Step [1360/3236], Loss: 2.0302, Perplexity: 7.6155
Epoch [7/100], Step [1370/3236], Loss: 1.9781, Perplexity: 7.2287
Epoch [7/100], Step [1380/3236], Loss: 2.1030, Perplexity: 8.1907
Epoch [7/100], Step [1390/3236], Loss: 1.9082, Perplexity: 6.7407
Epoch [7/100], Step [1400/3236], Loss: 1.9557, Perplexity: 7.0690
Epoch [7/100], Step [1410/3236], Loss: 1.9514, Perplexity: 7.0385
Epoch [7/100], Step [1420/3236], Loss: 2.0138, Perplexity: 7.4915
Epoch [7/100], Step [1430/3236], Loss: 2.0010, Perplexity: 7.3962
Epoch [7/100], Step [1440/3236], Loss: 2.1015, Perplexity: 8.1786
Epoch [7/100], Step [1450/3236], Loss: 2.0243, Perplexity: 7.5707
Epoch [7/100], Step [1460/3236], Loss: 1.9841, Perplexity: 7.2723
Epoch [7/100], Step [1470/3236], Loss: 2.0848, Perplexity: 8.0434
Epoch [7/100], Step [1480/3236], Loss: 1.9413, Perplexity: 6.9677
Epoch [7/100], Step [1490/3236], Loss: 1.9723, Perplexity: 7.1869
Epoch [7/100], Step [1500/3236], Loss: 2.0278, Perplexity: 7.5971
Epoch [7/100], Step [1510/3236], Loss: 2.0958, Perplexity: 8.1316
Epoch [7/100], Step [1520/3236], Loss: 2.0549, Perplexity: 7.8064
Epoch [7/100], Step [1530/3236], Loss: 2.2060, Perplexity: 9.0795
Epoch [7/100], Step [1540/3236], Loss: 2.0748, Perplexity: 7.9629
Epoch [7/100], Step [1550/3236], Loss: 1.9607, Perplexity: 7.1044
Epoch [7/100], Step [1560/3236], Loss: 1.9286, Perplexity: 6.8802
Epoch [7/100], Step [1570/3236], Loss: 2.0027, Perplexity: 7.4093
Epoch [7/100], Step [1580/3236], Loss: 2.0306, Perplexity: 7.6184
Epoch [7/100], Step [1590/3236], Loss: 2.0661, Perplexity: 7.8941
Epoch [7/100], Step [1600/3236], Loss: 2.0613, Perplexity: 7.8559
Epoch [7/100], Step [1610/3236], Loss: 2.1321, Perplexity: 8.4325
Epoch [7/100], Step [1620/3236], Loss: 1.9593, Perplexity: 7.0943
Epoch [7/100], Step [1630/3236], Loss: 1.9890, Perplexity: 7.3085
Epoch [7/100], Step [1640/3236], Loss: 2.0858, Perplexity: 8.0513
Epoch [7/100], Step [1650/3236], Loss: 1.9224, Perplexity: 6.8371
Epoch [7/100], Step [1660/3236], Loss: 2.0540, Perplexity: 7.7987
Epoch [7/100], Step [1670/3236], Loss: 2.0021, Perplexity: 7.4043
Epoch [7/100], Step [1680/3236], Loss: 1.9818, Perplexity: 7.2559
Epoch [7/100], Step [1690/3236], Loss: 2.2504, Perplexity: 9.4918
Epoch [7/100], Step [1700/3236], Loss: 2.0666, Perplexity: 7.8977
Epoch [7/100], Step [1710/3236], Loss: 1.9796, Perplexity: 7.2401
Epoch [7/100], Step [1720/3236], Loss: 1.9230, Perplexity: 6.8415
Epoch [7/100], Step [1730/3236], Loss: 1.9230, Perplexity: 6.8414
Epoch [7/100], Step [1740/3236], Loss: 2.1146, Perplexity: 8.2862
Epoch [7/100], Step [1750/3236], Loss: 2.0442, Perplexity: 7.7232
Epoch [7/100], Step [1760/3236], Loss: 2.0274, Perplexity: 7.5943
Epoch [7/100], Step [1770/3236], Loss: 1.9276, Perplexity: 6.8732
Epoch [7/100], Step [1780/3236], Loss: 1.9104, Perplexity: 6.7561
Epoch [7/100], Step [1790/3236], Loss: 2.0517, Perplexity: 7.7810
Epoch [7/100], Step [1800/3236], Loss: 2.0899, Perplexity: 8.0843
Epoch [7/100], Step [1810/3236], Loss: 2.0097, Perplexity: 7.4609
Epoch [7/100], Step [1820/3236], Loss: 2.0070, Perplexity: 7.4412
Epoch [7/100], Step [1830/3236], Loss: 1.9926, Perplexity: 7.3344
Epoch [7/100], Step [1840/3236], Loss: 2.0226, Perplexity: 7.5581
Epoch [7/100], Step [1850/3236], Loss: 1.9926, Perplexity: 7.3345
Epoch [7/100], Step [1860/3236], Loss: 1.9388, Perplexity: 6.9501
Epoch [7/100], Step [1870/3236], Loss: 2.0662, Perplexity: 7.8946
Epoch [7/100], Step [1880/3236], Loss: 2.0564, Perplexity: 7.8180
Epoch [7/100], Step [1890/3236], Loss: 2.0117, Perplexity: 7.4762
Epoch [7/100], Step [1900/3236], Loss: 2.0633, Perplexity: 7.8722
Epoch [7/100], Step [1910/3236], Loss: 1.9956, Perplexity: 7.3566
Epoch [7/100], Step [1920/3236], Loss: 2.1032, Perplexity: 8.1927
Epoch [7/100], Step [1930/3236], Loss: 2.1216, Perplexity: 8.3442
Epoch [7/100], Step [1940/3236], Loss: 2.0011, Perplexity: 7.3970
Epoch [7/100], Step [1950/3236], Loss: 1.9865, Perplexity: 7.2900
Epoch [7/100], Step [1960/3236], Loss: 2.0757, Perplexity: 7.9704
Epoch [7/100], Step [1970/3236], Loss: 2.0085, Perplexity: 7.4523
Epoch [7/100], Step [1980/3236], Loss: 2.0801, Perplexity: 8.0056
Epoch [7/100], Step [1990/3236], Loss: 2.0125, Perplexity: 7.4821
Epoch [7/100], Step [2000/3236], Loss: 2.0433, Perplexity: 7.7164
Epoch [7/100], Step [2010/3236], Loss: 1.9881, Perplexity: 7.3017
Epoch [7/100], Step [2020/3236], Loss: 2.0749, Perplexity: 7.9634
Epoch [7/100], Step [2030/3236], Loss: 2.1916, Perplexity: 8.9495
Epoch [7/100], Step [2040/3236], Loss: 2.0437, Perplexity: 7.7189
Epoch [7/100], Step [2050/3236], Loss: 1.9181, Perplexity: 6.8082
Epoch [7/100], Step [2060/3236], Loss: 1.8954, Perplexity: 6.6555
Epoch [7/100], Step [2070/3236], Loss: 2.0158, Perplexity: 7.5068
Epoch [7/100], Step [2080/3236], Loss: 2.1632, Perplexity: 8.6992
Epoch [7/100], Step [2090/3236], Loss: 2.1553, Perplexity: 8.6301
Epoch [7/100], Step [2100/3236], Loss: 2.0609, Perplexity: 7.8531
Epoch [7/100], Step [2110/3236], Loss: 1.8933, Perplexity: 6.6411
Epoch [7/100], Step [2120/3236], Loss: 1.9708, Perplexity: 7.1763
Epoch [7/100], Step [2130/3236], Loss: 1.9704, Perplexity: 7.1736
Epoch [7/100], Step [2140/3236], Loss: 2.0616, Perplexity: 7.8589
Epoch [7/100], Step [2150/3236], Loss: 2.1919, Perplexity: 8.9524
Epoch [7/100], Step [2160/3236], Loss: 2.0159, Perplexity: 7.5076
Epoch [7/100], Step [2170/3236], Loss: 2.0267, Perplexity: 7.5887
Epoch [7/100], Step [2180/3236], Loss: 2.0278, Perplexity: 7.5970
Epoch [7/100], Step [2190/3236], Loss: 2.0398, Perplexity: 7.6893
Epoch [7/100], Step [2200/3236], Loss: 1.9632, Perplexity: 7.1219
Epoch [7/100], Step [2210/3236], Loss: 2.0545, Perplexity: 7.8033
Epoch [7/100], Step [2220/3236], Loss: 1.8773, Perplexity: 6.5356
Epoch [7/100], Step [2230/3236], Loss: 2.0299, Perplexity: 7.6132
Epoch [7/100], Step [2240/3236], Loss: 2.0781, Perplexity: 7.9891
Epoch [7/100], Step [2250/3236], Loss: 2.0389, Perplexity: 7.6820
Epoch [7/100], Step [2260/3236], Loss: 2.0853, Perplexity: 8.0474
Epoch [7/100], Step [2270/3236], Loss: 1.9602, Perplexity: 7.1010
Epoch [7/100], Step [2280/3236], Loss: 2.0964, Perplexity: 8.1366
Epoch [7/100], Step [2290/3236], Loss: 1.9933, Perplexity: 7.3400
Epoch [7/100], Step [2300/3236], Loss: 1.9840, Perplexity: 7.2715
Epoch [7/100], Step [2310/3236], Loss: 2.0803, Perplexity: 8.0067
Epoch [7/100], Step [2320/3236], Loss: 2.0252, Perplexity: 7.5774
Epoch [7/100], Step [2330/3236], Loss: 1.9642, Perplexity: 7.1290
Epoch [7/100], Step [2340/3236], Loss: 2.0460, Perplexity: 7.7372
Epoch [7/100], Step [2350/3236], Loss: 1.8975, Perplexity: 6.6692
Epoch [7/100], Step [2360/3236], Loss: 1.9004, Perplexity: 6.6885
Epoch [7/100], Step [2370/3236], Loss: 2.1393, Perplexity: 8.4936
Epoch [7/100], Step [2380/3236], Loss: 2.0810, Perplexity: 8.0123
Epoch [7/100], Step [2390/3236], Loss: 2.0442, Perplexity: 7.7230
Epoch [7/100], Step [2400/3236], Loss: 2.0399, Perplexity: 7.6895
Epoch [7/100], Step [2410/3236], Loss: 2.0005, Perplexity: 7.3925
Epoch [7/100], Step [2420/3236], Loss: 2.0350, Perplexity: 7.6523
Epoch [7/100], Step [2430/3236], Loss: 2.0412, Perplexity: 7.6997
Epoch [7/100], Step [2440/3236], Loss: 1.9793, Perplexity: 7.2379
Epoch [7/100], Step [2450/3236], Loss: 2.2147, Perplexity: 9.1583
Epoch [7/100], Step [2460/3236], Loss: 2.2330, Perplexity: 9.3282
Epoch [7/100], Step [2470/3236], Loss: 2.0124, Perplexity: 7.4814
Epoch [7/100], Step [2480/3236], Loss: 2.1061, Perplexity: 8.2163
Epoch [7/100], Step [2490/3236], Loss: 2.1363, Perplexity: 8.4682
Epoch [7/100], Step [2500/3236], Loss: 2.0346, Perplexity: 7.6495
Epoch [7/100], Step [2510/3236], Loss: 1.9613, Perplexity: 7.1086
Epoch [7/100], Step [2520/3236], Loss: 1.9636, Perplexity: 7.1247
Epoch [7/100], Step [2530/3236], Loss: 2.1387, Perplexity: 8.4885
Epoch [7/100], Step [2540/3236], Loss: 2.0354, Perplexity: 7.6554
Epoch [7/100], Step [2550/3236], Loss: 2.0643, Perplexity: 7.8797
Epoch [7/100], Step [2560/3236], Loss: 2.0936, Perplexity: 8.1139
Epoch [7/100], Step [2570/3236], Loss: 2.0390, Perplexity: 7.6833
Epoch [7/100], Step [2580/3236], Loss: 1.9580, Perplexity: 7.0853
Epoch [7/100], Step [2590/3236], Loss: 1.9836, Perplexity: 7.2689
Epoch [7/100], Step [2600/3236], Loss: 1.9924, Perplexity: 7.3330
Epoch [7/100], Step [2610/3236], Loss: 2.0145, Perplexity: 7.4970
Epoch [7/100], Step [2620/3236], Loss: 1.9672, Perplexity: 7.1507
Epoch [7/100], Step [2630/3236], Loss: 2.0836, Perplexity: 8.0330
Epoch [7/100], Step [2640/3236], Loss: 1.9718, Perplexity: 7.1834
Epoch [7/100], Step [2650/3236], Loss: 2.0262, Perplexity: 7.5851
Epoch [7/100], Step [2660/3236], Loss: 1.9520, Perplexity: 7.0429
Epoch [7/100], Step [2670/3236], Loss: 2.0456, Perplexity: 7.7338
Epoch [7/100], Step [2680/3236], Loss: 1.9841, Perplexity: 7.2723
Epoch [7/100], Step [2690/3236], Loss: 2.0084, Perplexity: 7.4511
Epoch [7/100], Step [2700/3236], Loss: 2.0550, Perplexity: 7.8065
Epoch [7/100], Step [2710/3236], Loss: 2.0663, Perplexity: 7.8955
Epoch [7/100], Step [2720/3236], Loss: 2.0469, Perplexity: 7.7436
Epoch [7/100], Step [2730/3236], Loss: 1.9377, Perplexity: 6.9426
Epoch [7/100], Step [2740/3236], Loss: 2.0467, Perplexity: 7.7422
Epoch [7/100], Step [2750/3236], Loss: 2.0760, Perplexity: 7.9722
Epoch [7/100], Step [2760/3236], Loss: 2.0854, Perplexity: 8.0477
Epoch [7/100], Step [2770/3236], Loss: 2.0739, Perplexity: 7.9560
Epoch [7/100], Step [2780/3236], Loss: 1.9805, Perplexity: 7.2460
Epoch [7/100], Step [2790/3236], Loss: 2.1941, Perplexity: 8.9718
Epoch [7/100], Step [2800/3236], Loss: 2.1645, Perplexity: 8.7101
Epoch [7/100], Step [2810/3236], Loss: 2.1301, Perplexity: 8.4156
Epoch [7/100], Step [2820/3236], Loss: 2.0403, Perplexity: 7.6929
Epoch [7/100], Step [2830/3236], Loss: 1.9868, Perplexity: 7.2922
Epoch [7/100], Step [2840/3236], Loss: 1.8972, Perplexity: 6.6669
Epoch [7/100], Step [2850/3236], Loss: 1.9912, Perplexity: 7.3240
Epoch [7/100], Step [2860/3236], Loss: 2.1899, Perplexity: 8.9343
Epoch [7/100], Step [2870/3236], Loss: 1.8645, Perplexity: 6.4526
Epoch [7/100], Step [2880/3236], Loss: 2.1054, Perplexity: 8.2100
Epoch [7/100], Step [2890/3236], Loss: 2.0765, Perplexity: 7.9765
Epoch [7/100], Step [2900/3236], Loss: 2.0106, Perplexity: 7.4676
Epoch [7/100], Step [2910/3236], Loss: 2.0317, Perplexity: 7.6267
Epoch [7/100], Step [2920/3236], Loss: 2.1082, Perplexity: 8.2333
Epoch [7/100], Step [2930/3236], Loss: 1.9640, Perplexity: 7.1275
Epoch [7/100], Step [2940/3236], Loss: 2.1065, Perplexity: 8.2195
Epoch [7/100], Step [2950/3236], Loss: 1.9631, Perplexity: 7.1211
Epoch [7/100], Step [2960/3236], Loss: 2.0648, Perplexity: 7.8835
Epoch [7/100], Step [2970/3236], Loss: 2.0042, Perplexity: 7.4199
Epoch [7/100], Step [2980/3236], Loss: 2.1352, Perplexity: 8.4590
Epoch [7/100], Step [2990/3236], Loss: 2.0382, Perplexity: 7.6764
Epoch [7/100], Step [3000/3236], Loss: 2.0983, Perplexity: 8.1521
Epoch [7/100], Step [3010/3236], Loss: 1.9203, Perplexity: 6.8229
Epoch [7/100], Step [3020/3236], Loss: 2.1026, Perplexity: 8.1873
Epoch [7/100], Step [3030/3236], Loss: 2.0694, Perplexity: 7.9200
Epoch [7/100], Step [3040/3236], Loss: 1.9940, Perplexity: 7.3450
Epoch [7/100], Step [3050/3236], Loss: 1.9347, Perplexity: 6.9217
Epoch [7/100], Step [3060/3236], Loss: 1.8736, Perplexity: 6.5115
Epoch [7/100], Step [3070/3236], Loss: 2.0326, Perplexity: 7.6338
Epoch [7/100], Step [3080/3236], Loss: 1.9282, Perplexity: 6.8771
Epoch [7/100], Step [3090/3236], Loss: 2.0382, Perplexity: 7.6769
Epoch [7/100], Step [3100/3236], Loss: 1.9252, Perplexity: 6.8564
Epoch [7/100], Step [3110/3236], Loss: 2.0634, Perplexity: 7.8725
Epoch [7/100], Step [3120/3236], Loss: 2.0848, Perplexity: 8.0431
Epoch [7/100], Step [3130/3236], Loss: 2.0194, Perplexity: 7.5335
Epoch [7/100], Step [3140/3236], Loss: 1.9295, Perplexity: 6.8861
Epoch [7/100], Step [3150/3236], Loss: 2.0482, Perplexity: 7.7543
Epoch [7/100], Step [3160/3236], Loss: 2.1187, Perplexity: 8.3204
Epoch [7/100], Step [3170/3236], Loss: 2.0847, Perplexity: 8.0425
Epoch [7/100], Step [3180/3236], Loss: 2.1334, Perplexity: 8.4436
Epoch [7/100], Step [3190/3236], Loss: 2.0090, Perplexity: 7.4556
Epoch [7/100], Step [3200/3236], Loss: 1.9171, Perplexity: 6.8009
Epoch [7/100], Step [3210/3236], Loss: 1.9053, Perplexity: 6.7213
Epoch [7/100], Step [3220/3236], Loss: 2.1093, Perplexity: 8.2422
Epoch [7/100], Step [3230/3236], Loss: 2.1521, Perplexity: 8.6032
start evaluate ...
355143 : a person sitting on a couch with a cat on the lap
299074 : a bus is parked on the side of the road
314515 : a group of people walking down a street
328098 : a red stop sign sitting on the side of a road
131597 : a group of motorcycles parked in a parking lot
481628 : a group of birds flying over a body of water
501443 : a large body of water with a large city in the background
514016 : a blue bus is driving down the street
73927 : a baseball player swinging a bat at a ball
275722 : a clock on a pedestal in a building
loading annotations into memory...
Done (t=0.77s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1306818.22 tokens per second.
PTBTokenizer tokenized 53318 tokens at 607964.61 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 47910, 'guess': [48319, 43319, 38319, 33319], 'testlen': 48319, 'correct': [32869, 15977, 6887, 2946]}
('ratio:', 1.0085368399081402)
Bleu_1: 0.680
Bleu_2: 0.501
Bleu_3: 0.356
Bleu_4: 0.251
computing METEOR score...
METEOR: 0.227
computing Rouge score...
ROUGE_L: 0.498
computing CIDEr score...
CIDEr: 0.803
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [27.451 seconds]
SPICE evaluation took: 38.66 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [8/100], Step [10/3236], Loss: 1.9392, Perplexity: 6.9530
Epoch [8/100], Step [20/3236], Loss: 1.9970, Perplexity: 7.3668
Epoch [8/100], Step [30/3236], Loss: 1.9552, Perplexity: 7.0653
Epoch [8/100], Step [40/3236], Loss: 1.9258, Perplexity: 6.8607
Epoch [8/100], Step [50/3236], Loss: 1.8130, Perplexity: 6.1286
Epoch [8/100], Step [60/3236], Loss: 1.8959, Perplexity: 6.6589
Epoch [8/100], Step [70/3236], Loss: 1.8780, Perplexity: 6.5403
Epoch [8/100], Step [80/3236], Loss: 1.7911, Perplexity: 5.9959
Epoch [8/100], Step [90/3236], Loss: 1.9451, Perplexity: 6.9940
Epoch [8/100], Step [100/3236], Loss: 1.8653, Perplexity: 6.4579
Epoch [8/100], Step [110/3236], Loss: 1.8588, Perplexity: 6.4158
Epoch [8/100], Step [120/3236], Loss: 1.8939, Perplexity: 6.6449
Epoch [8/100], Step [130/3236], Loss: 1.8452, Perplexity: 6.3296
Epoch [8/100], Step [140/3236], Loss: 1.8831, Perplexity: 6.5741
Epoch [8/100], Step [150/3236], Loss: 1.9754, Perplexity: 7.2096
Epoch [8/100], Step [160/3236], Loss: 1.9110, Perplexity: 6.7598
Epoch [8/100], Step [170/3236], Loss: 1.9156, Perplexity: 6.7907
Epoch [8/100], Step [180/3236], Loss: 2.0148, Perplexity: 7.4993
Epoch [8/100], Step [190/3236], Loss: 1.9685, Perplexity: 7.1602
Epoch [8/100], Step [200/3236], Loss: 1.9181, Perplexity: 6.8081
Epoch [8/100], Step [210/3236], Loss: 1.9835, Perplexity: 7.2679
Epoch [8/100], Step [220/3236], Loss: 1.9246, Perplexity: 6.8522
Epoch [8/100], Step [230/3236], Loss: 1.9365, Perplexity: 6.9344
Epoch [8/100], Step [240/3236], Loss: 1.9702, Perplexity: 7.1720
Epoch [8/100], Step [250/3236], Loss: 2.0917, Perplexity: 8.0983
Epoch [8/100], Step [260/3236], Loss: 1.9832, Perplexity: 7.2662
Epoch [8/100], Step [270/3236], Loss: 1.8639, Perplexity: 6.4490
Epoch [8/100], Step [280/3236], Loss: 1.8705, Perplexity: 6.4919
Epoch [8/100], Step [290/3236], Loss: 2.0257, Perplexity: 7.5813
Epoch [8/100], Step [300/3236], Loss: 1.9199, Perplexity: 6.8200
Epoch [8/100], Step [310/3236], Loss: 2.1258, Perplexity: 8.3800
Epoch [8/100], Step [320/3236], Loss: 1.9212, Perplexity: 6.8291
Epoch [8/100], Step [330/3236], Loss: 1.9742, Perplexity: 7.2010
Epoch [8/100], Step [340/3236], Loss: 1.9129, Perplexity: 6.7724
Epoch [8/100], Step [350/3236], Loss: 2.2069, Perplexity: 9.0871
Epoch [8/100], Step [360/3236], Loss: 1.9136, Perplexity: 6.7777
Epoch [8/100], Step [370/3236], Loss: 2.0515, Perplexity: 7.7799
Epoch [8/100], Step [380/3236], Loss: 1.9248, Perplexity: 6.8539
Epoch [8/100], Step [390/3236], Loss: 1.9344, Perplexity: 6.9201
Epoch [8/100], Step [400/3236], Loss: 1.9945, Perplexity: 7.3488
Epoch [8/100], Step [410/3236], Loss: 1.9767, Perplexity: 7.2191
Epoch [8/100], Step [420/3236], Loss: 1.9378, Perplexity: 6.9435
Epoch [8/100], Step [430/3236], Loss: 1.9593, Perplexity: 7.0942
Epoch [8/100], Step [440/3236], Loss: 1.9214, Perplexity: 6.8302
Epoch [8/100], Step [450/3236], Loss: 1.8978, Perplexity: 6.6715
Epoch [8/100], Step [460/3236], Loss: 1.9369, Perplexity: 6.9372
Epoch [8/100], Step [470/3236], Loss: 2.0388, Perplexity: 7.6813
Epoch [8/100], Step [480/3236], Loss: 1.9989, Perplexity: 7.3807
Epoch [8/100], Step [490/3236], Loss: 1.9037, Perplexity: 6.7106
Epoch [8/100], Step [500/3236], Loss: 1.9593, Perplexity: 7.0946
Epoch [8/100], Step [510/3236], Loss: 2.0072, Perplexity: 7.4422
Epoch [8/100], Step [520/3236], Loss: 2.0702, Perplexity: 7.9263
Epoch [8/100], Step [530/3236], Loss: 1.9526, Perplexity: 7.0473
Epoch [8/100], Step [540/3236], Loss: 1.9428, Perplexity: 6.9780
Epoch [8/100], Step [550/3236], Loss: 1.9745, Perplexity: 7.2033
Epoch [8/100], Step [560/3236], Loss: 1.9297, Perplexity: 6.8871
Epoch [8/100], Step [570/3236], Loss: 1.9549, Perplexity: 7.0630
Epoch [8/100], Step [580/3236], Loss: 2.0287, Perplexity: 7.6042
Epoch [8/100], Step [590/3236], Loss: 1.9628, Perplexity: 7.1190
Epoch [8/100], Step [600/3236], Loss: 1.9510, Perplexity: 7.0361
Epoch [8/100], Step [610/3236], Loss: 1.8347, Perplexity: 6.2631
Epoch [8/100], Step [620/3236], Loss: 1.9635, Perplexity: 7.1240
Epoch [8/100], Step [630/3236], Loss: 1.9324, Perplexity: 6.9062
Epoch [8/100], Step [640/3236], Loss: 1.9295, Perplexity: 6.8859
Epoch [8/100], Step [650/3236], Loss: 2.0212, Perplexity: 7.5471
Epoch [8/100], Step [660/3236], Loss: 1.9313, Perplexity: 6.8986
Epoch [8/100], Step [670/3236], Loss: 2.0654, Perplexity: 7.8886
Epoch [8/100], Step [680/3236], Loss: 2.0210, Perplexity: 7.5461
Epoch [8/100], Step [690/3236], Loss: 1.9584, Perplexity: 7.0877
Epoch [8/100], Step [700/3236], Loss: 1.9842, Perplexity: 7.2736
Epoch [8/100], Step [710/3236], Loss: 1.9704, Perplexity: 7.1736
Epoch [8/100], Step [720/3236], Loss: 1.9807, Perplexity: 7.2475
Epoch [8/100], Step [730/3236], Loss: 2.0452, Perplexity: 7.7309
Epoch [8/100], Step [740/3236], Loss: 1.9632, Perplexity: 7.1220
Epoch [8/100], Step [750/3236], Loss: 1.8786, Perplexity: 6.5441
Epoch [8/100], Step [760/3236], Loss: 2.0824, Perplexity: 8.0241
Epoch [8/100], Step [770/3236], Loss: 1.9610, Perplexity: 7.1065
Epoch [8/100], Step [780/3236], Loss: 2.0212, Perplexity: 7.5472
Epoch [8/100], Step [790/3236], Loss: 2.0400, Perplexity: 7.6903
Epoch [8/100], Step [800/3236], Loss: 1.9697, Perplexity: 7.1688
Epoch [8/100], Step [810/3236], Loss: 2.0467, Perplexity: 7.7422
Epoch [8/100], Step [820/3236], Loss: 1.9131, Perplexity: 6.7742
Epoch [8/100], Step [830/3236], Loss: 1.9605, Perplexity: 7.1026
Epoch [8/100], Step [840/3236], Loss: 1.9828, Perplexity: 7.2632
Epoch [8/100], Step [850/3236], Loss: 2.0571, Perplexity: 7.8234
Epoch [8/100], Step [860/3236], Loss: 1.8742, Perplexity: 6.5158
Epoch [8/100], Step [870/3236], Loss: 1.8395, Perplexity: 6.2936
Epoch [8/100], Step [880/3236], Loss: 1.8947, Perplexity: 6.6508
Epoch [8/100], Step [890/3236], Loss: 1.9922, Perplexity: 7.3318
Epoch [8/100], Step [900/3236], Loss: 2.0011, Perplexity: 7.3971
Epoch [8/100], Step [910/3236], Loss: 2.0559, Perplexity: 7.8140
Epoch [8/100], Step [920/3236], Loss: 1.9367, Perplexity: 6.9358
Epoch [8/100], Step [930/3236], Loss: 1.9605, Perplexity: 7.1025
Epoch [8/100], Step [940/3236], Loss: 2.0561, Perplexity: 7.8155
Epoch [8/100], Step [950/3236], Loss: 1.9947, Perplexity: 7.3497
Epoch [8/100], Step [960/3236], Loss: 2.0794, Perplexity: 8.0001
Epoch [8/100], Step [970/3236], Loss: 1.9702, Perplexity: 7.1722
Epoch [8/100], Step [980/3236], Loss: 1.8196, Perplexity: 6.1692
Epoch [8/100], Step [990/3236], Loss: 1.9983, Perplexity: 7.3764
Epoch [8/100], Step [1000/3236], Loss: 1.9828, Perplexity: 7.2630
Epoch [8/100], Step [1010/3236], Loss: 1.9312, Perplexity: 6.8979
Epoch [8/100], Step [1020/3236], Loss: 2.1311, Perplexity: 8.4243
Epoch [8/100], Step [1030/3236], Loss: 1.9487, Perplexity: 7.0194
Epoch [8/100], Step [1040/3236], Loss: 2.0133, Perplexity: 7.4882
Epoch [8/100], Step [1050/3236], Loss: 2.0657, Perplexity: 7.8908
Epoch [8/100], Step [1060/3236], Loss: 1.9516, Perplexity: 7.0401
Epoch [8/100], Step [1070/3236], Loss: 1.9413, Perplexity: 6.9676
Epoch [8/100], Step [1080/3236], Loss: 1.9814, Perplexity: 7.2528
Epoch [8/100], Step [1090/3236], Loss: 1.8655, Perplexity: 6.4592
Epoch [8/100], Step [1100/3236], Loss: 1.9864, Perplexity: 7.2890
Epoch [8/100], Step [1110/3236], Loss: 2.1496, Perplexity: 8.5818
Epoch [8/100], Step [1120/3236], Loss: 2.0030, Perplexity: 7.4115
Epoch [8/100], Step [1130/3236], Loss: 2.0279, Perplexity: 7.5984
Epoch [8/100], Step [1140/3236], Loss: 1.9356, Perplexity: 6.9279
Epoch [8/100], Step [1150/3236], Loss: 2.0461, Perplexity: 7.7378
Epoch [8/100], Step [1160/3236], Loss: 1.8513, Perplexity: 6.3680
Epoch [8/100], Step [1170/3236], Loss: 1.9965, Perplexity: 7.3632
Epoch [8/100], Step [1180/3236], Loss: 1.9738, Perplexity: 7.1983
Epoch [8/100], Step [1190/3236], Loss: 1.9825, Perplexity: 7.2609
Epoch [8/100], Step [1200/3236], Loss: 2.1374, Perplexity: 8.4776
Epoch [8/100], Step [1210/3236], Loss: 2.0237, Perplexity: 7.5659
Epoch [8/100], Step [1220/3236], Loss: 2.0269, Perplexity: 7.5904
Epoch [8/100], Step [1230/3236], Loss: 1.9056, Perplexity: 6.7235
Epoch [8/100], Step [1240/3236], Loss: 2.0443, Perplexity: 7.7235
Epoch [8/100], Step [1250/3236], Loss: 1.8601, Perplexity: 6.4246
Epoch [8/100], Step [1260/3236], Loss: 2.0332, Perplexity: 7.6388
Epoch [8/100], Step [1270/3236], Loss: 2.0377, Perplexity: 7.6730
Epoch [8/100], Step [1280/3236], Loss: 1.9891, Perplexity: 7.3088
Epoch [8/100], Step [1290/3236], Loss: 1.8749, Perplexity: 6.5200
Epoch [8/100], Step [1300/3236], Loss: 1.9323, Perplexity: 6.9051
Epoch [8/100], Step [1310/3236], Loss: 2.1038, Perplexity: 8.1973
Epoch [8/100], Step [1320/3236], Loss: 2.0297, Perplexity: 7.6115
Epoch [8/100], Step [1330/3236], Loss: 2.0629, Perplexity: 7.8684
Epoch [8/100], Step [1340/3236], Loss: 2.0150, Perplexity: 7.5010
Epoch [8/100], Step [1350/3236], Loss: 1.9305, Perplexity: 6.8928
Epoch [8/100], Step [1360/3236], Loss: 2.0669, Perplexity: 7.9003
Epoch [8/100], Step [1370/3236], Loss: 2.0224, Perplexity: 7.5561
Epoch [8/100], Step [1380/3236], Loss: 1.9915, Perplexity: 7.3264
Epoch [8/100], Step [1390/3236], Loss: 1.8639, Perplexity: 6.4491
Epoch [8/100], Step [1400/3236], Loss: 2.0244, Perplexity: 7.5719
Epoch [8/100], Step [1410/3236], Loss: 1.9020, Perplexity: 6.6994
Epoch [8/100], Step [1420/3236], Loss: 2.0415, Perplexity: 7.7022
Epoch [8/100], Step [1430/3236], Loss: 1.9978, Perplexity: 7.3725
Epoch [8/100], Step [1440/3236], Loss: 1.8363, Perplexity: 6.2734
Epoch [8/100], Step [1450/3236], Loss: 2.0608, Perplexity: 7.8522
Epoch [8/100], Step [1460/3236], Loss: 2.0325, Perplexity: 7.6334
Epoch [8/100], Step [1470/3236], Loss: 1.9544, Perplexity: 7.0599
Epoch [8/100], Step [1480/3236], Loss: 1.9776, Perplexity: 7.2255
Epoch [8/100], Step [1490/3236], Loss: 2.0757, Perplexity: 7.9705
Epoch [8/100], Step [1500/3236], Loss: 2.0163, Perplexity: 7.5108
Epoch [8/100], Step [1510/3236], Loss: 1.9414, Perplexity: 6.9687
Epoch [8/100], Step [1520/3236], Loss: 2.0942, Perplexity: 8.1192
Epoch [8/100], Step [1530/3236], Loss: 1.8949, Perplexity: 6.6517
Epoch [8/100], Step [1540/3236], Loss: 1.9886, Perplexity: 7.3050
Epoch [8/100], Step [1550/3236], Loss: 1.9830, Perplexity: 7.2643
Epoch [8/100], Step [1560/3236], Loss: 1.9100, Perplexity: 6.7531
Epoch [8/100], Step [1570/3236], Loss: 1.9880, Perplexity: 7.3009
Epoch [8/100], Step [1580/3236], Loss: 2.0236, Perplexity: 7.5657
Epoch [8/100], Step [1590/3236], Loss: 1.9568, Perplexity: 7.0764
Epoch [8/100], Step [1600/3236], Loss: 1.9455, Perplexity: 6.9974
Epoch [8/100], Step [1610/3236], Loss: 1.9023, Perplexity: 6.7013
Epoch [8/100], Step [1620/3236], Loss: 1.9427, Perplexity: 6.9772
Epoch [8/100], Step [1630/3236], Loss: 1.9956, Perplexity: 7.3568
Epoch [8/100], Step [1640/3236], Loss: 1.9398, Perplexity: 6.9576
Epoch [8/100], Step [1650/3236], Loss: 2.0919, Perplexity: 8.1003
Epoch [8/100], Step [1660/3236], Loss: 1.9927, Perplexity: 7.3355
Epoch [8/100], Step [1670/3236], Loss: 2.0209, Perplexity: 7.5450
Epoch [8/100], Step [1680/3236], Loss: 1.8399, Perplexity: 6.2956
Epoch [8/100], Step [1690/3236], Loss: 2.0274, Perplexity: 7.5940
Epoch [8/100], Step [1700/3236], Loss: 2.0316, Perplexity: 7.6264
Epoch [8/100], Step [1710/3236], Loss: 2.1191, Perplexity: 8.3233
Epoch [8/100], Step [1720/3236], Loss: 1.8919, Perplexity: 6.6320
Epoch [8/100], Step [1730/3236], Loss: 1.9620, Perplexity: 7.1139
Epoch [8/100], Step [1740/3236], Loss: 1.9028, Perplexity: 6.7049
Epoch [8/100], Step [1750/3236], Loss: 1.9025, Perplexity: 6.7027
Epoch [8/100], Step [1760/3236], Loss: 2.0348, Perplexity: 7.6509
Epoch [8/100], Step [1770/3236], Loss: 1.8342, Perplexity: 6.2602
Epoch [8/100], Step [1780/3236], Loss: 1.8964, Perplexity: 6.6616
Epoch [8/100], Step [1790/3236], Loss: 1.9931, Perplexity: 7.3380
Epoch [8/100], Step [1800/3236], Loss: 2.0545, Perplexity: 7.8032
Epoch [8/100], Step [1810/3236], Loss: 2.0006, Perplexity: 7.3936
Epoch [8/100], Step [1820/3236], Loss: 2.0527, Perplexity: 7.7889
Epoch [8/100], Step [1830/3236], Loss: 1.9475, Perplexity: 7.0115
Epoch [8/100], Step [1840/3236], Loss: 2.0164, Perplexity: 7.5113
Epoch [8/100], Step [1850/3236], Loss: 2.0474, Perplexity: 7.7477
Epoch [8/100], Step [1860/3236], Loss: 1.8043, Perplexity: 6.0760
Epoch [8/100], Step [1870/3236], Loss: 2.0375, Perplexity: 7.6712
Epoch [8/100], Step [1880/3236], Loss: 1.9044, Perplexity: 6.7155
Epoch [8/100], Step [1890/3236], Loss: 1.8863, Perplexity: 6.5948
Epoch [8/100], Step [1900/3236], Loss: 2.0082, Perplexity: 7.4498
Epoch [8/100], Step [1910/3236], Loss: 1.9525, Perplexity: 7.0461
Epoch [8/100], Step [1920/3236], Loss: 1.9915, Perplexity: 7.3268
Epoch [8/100], Step [1930/3236], Loss: 1.8849, Perplexity: 6.5856
Epoch [8/100], Step [1940/3236], Loss: 2.0081, Perplexity: 7.4494
Epoch [8/100], Step [1950/3236], Loss: 1.9569, Perplexity: 7.0775
Epoch [8/100], Step [1960/3236], Loss: 2.0565, Perplexity: 7.8182
Epoch [8/100], Step [1970/3236], Loss: 1.9696, Perplexity: 7.1677
Epoch [8/100], Step [1980/3236], Loss: 2.0549, Perplexity: 7.8058
Epoch [8/100], Step [1990/3236], Loss: 1.9161, Perplexity: 6.7947
Epoch [8/100], Step [2000/3236], Loss: 2.0686, Perplexity: 7.9139
Epoch [8/100], Step [2010/3236], Loss: 2.0474, Perplexity: 7.7480
Epoch [8/100], Step [2020/3236], Loss: 1.9512, Perplexity: 7.0370
Epoch [8/100], Step [2030/3236], Loss: 1.9460, Perplexity: 7.0003
Epoch [8/100], Step [2040/3236], Loss: 1.9968, Perplexity: 7.3653
Epoch [8/100], Step [2050/3236], Loss: 1.9176, Perplexity: 6.8044
Epoch [8/100], Step [2060/3236], Loss: 1.9535, Perplexity: 7.0535
Epoch [8/100], Step [2070/3236], Loss: 2.0202, Perplexity: 7.5397
Epoch [8/100], Step [2080/3236], Loss: 2.0416, Perplexity: 7.7032
Epoch [8/100], Step [2090/3236], Loss: 2.0043, Perplexity: 7.4205
Epoch [8/100], Step [2100/3236], Loss: 2.0481, Perplexity: 7.7534
Epoch [8/100], Step [2110/3236], Loss: 2.0091, Perplexity: 7.4564
Epoch [8/100], Step [2120/3236], Loss: 1.9443, Perplexity: 6.9885
Epoch [8/100], Step [2130/3236], Loss: 2.1055, Perplexity: 8.2109
Epoch [8/100], Step [2140/3236], Loss: 1.9448, Perplexity: 6.9919
Epoch [8/100], Step [2150/3236], Loss: 2.0009, Perplexity: 7.3957
Epoch [8/100], Step [2160/3236], Loss: 2.0828, Perplexity: 8.0265
Epoch [8/100], Step [2170/3236], Loss: 2.0386, Perplexity: 7.6797
Epoch [8/100], Step [2180/3236], Loss: 2.0531, Perplexity: 7.7922
Epoch [8/100], Step [2190/3236], Loss: 2.0619, Perplexity: 7.8609
Epoch [8/100], Step [2200/3236], Loss: 1.9775, Perplexity: 7.2249
Epoch [8/100], Step [2210/3236], Loss: 1.9540, Perplexity: 7.0571
Epoch [8/100], Step [2220/3236], Loss: 2.0850, Perplexity: 8.0444
Epoch [8/100], Step [2230/3236], Loss: 2.0145, Perplexity: 7.4972
Epoch [8/100], Step [2240/3236], Loss: 2.0298, Perplexity: 7.6126
Epoch [8/100], Step [2250/3236], Loss: 1.9537, Perplexity: 7.0550
Epoch [8/100], Step [2260/3236], Loss: 1.9356, Perplexity: 6.9281
Epoch [8/100], Step [2270/3236], Loss: 2.0969, Perplexity: 8.1412
Epoch [8/100], Step [2280/3236], Loss: 1.9810, Perplexity: 7.2503
Epoch [8/100], Step [2290/3236], Loss: 1.9303, Perplexity: 6.8918
Epoch [8/100], Step [2300/3236], Loss: 1.9441, Perplexity: 6.9873
Epoch [8/100], Step [2310/3236], Loss: 1.9902, Perplexity: 7.3171
Epoch [8/100], Step [2320/3236], Loss: 1.9676, Perplexity: 7.1534
Epoch [8/100], Step [2330/3236], Loss: 2.0299, Perplexity: 7.6135
Epoch [8/100], Step [2340/3236], Loss: 2.0530, Perplexity: 7.7912
Epoch [8/100], Step [2350/3236], Loss: 1.9857, Perplexity: 7.2844
Epoch [8/100], Step [2360/3236], Loss: 2.0037, Perplexity: 7.4164
Epoch [8/100], Step [2370/3236], Loss: 2.0119, Perplexity: 7.4772
Epoch [8/100], Step [2380/3236], Loss: 2.0479, Perplexity: 7.7518
Epoch [8/100], Step [2390/3236], Loss: 2.0437, Perplexity: 7.7189
Epoch [8/100], Step [2400/3236], Loss: 1.9459, Perplexity: 7.0002
Epoch [8/100], Step [2410/3236], Loss: 1.9516, Perplexity: 7.0402
Epoch [8/100], Step [2420/3236], Loss: 1.9528, Perplexity: 7.0487
Epoch [8/100], Step [2430/3236], Loss: 1.9682, Perplexity: 7.1578
Epoch [8/100], Step [2440/3236], Loss: 2.0397, Perplexity: 7.6885
Epoch [8/100], Step [2450/3236], Loss: 2.0845, Perplexity: 8.0407
Epoch [8/100], Step [2460/3236], Loss: 1.9039, Perplexity: 6.7118
Epoch [8/100], Step [2470/3236], Loss: 2.0750, Perplexity: 7.9646
Epoch [8/100], Step [2480/3236], Loss: 2.1244, Perplexity: 8.3676
Epoch [8/100], Step [2490/3236], Loss: 1.9391, Perplexity: 6.9528
Epoch [8/100], Step [2500/3236], Loss: 1.9203, Perplexity: 6.8227
Epoch [8/100], Step [2510/3236], Loss: 2.0778, Perplexity: 7.9872
Epoch [8/100], Step [2520/3236], Loss: 2.0317, Perplexity: 7.6269
Epoch [8/100], Step [2530/3236], Loss: 2.0794, Perplexity: 7.9993
Epoch [8/100], Step [2540/3236], Loss: 2.0504, Perplexity: 7.7707
Epoch [8/100], Step [2550/3236], Loss: 1.9917, Perplexity: 7.3282
Epoch [8/100], Step [2560/3236], Loss: 1.9621, Perplexity: 7.1140
Epoch [8/100], Step [2570/3236], Loss: 2.0251, Perplexity: 7.5766
Epoch [8/100], Step [2580/3236], Loss: 2.0095, Perplexity: 7.4599
Epoch [8/100], Step [2590/3236], Loss: 1.9696, Perplexity: 7.1678
Epoch [8/100], Step [2600/3236], Loss: 2.0274, Perplexity: 7.5942
Epoch [8/100], Step [2610/3236], Loss: 1.9483, Perplexity: 7.0168
Epoch [8/100], Step [2620/3236], Loss: 1.9983, Perplexity: 7.3768
Epoch [8/100], Step [2630/3236], Loss: 2.0975, Perplexity: 8.1458
Epoch [8/100], Step [2640/3236], Loss: 2.0558, Perplexity: 7.8130
Epoch [8/100], Step [2650/3236], Loss: 1.9528, Perplexity: 7.0484
Epoch [8/100], Step [2660/3236], Loss: 1.9834, Perplexity: 7.2675
Epoch [8/100], Step [2670/3236], Loss: 1.9687, Perplexity: 7.1612
Epoch [8/100], Step [2680/3236], Loss: 1.9694, Perplexity: 7.1665
Epoch [8/100], Step [2690/3236], Loss: 1.9184, Perplexity: 6.8103
Epoch [8/100], Step [2700/3236], Loss: 2.0041, Perplexity: 7.4192
Epoch [8/100], Step [2710/3236], Loss: 1.9512, Perplexity: 7.0369
Epoch [8/100], Step [2720/3236], Loss: 2.1129, Perplexity: 8.2719
Epoch [8/100], Step [2730/3236], Loss: 2.0129, Perplexity: 7.4846
Epoch [8/100], Step [2740/3236], Loss: 2.0662, Perplexity: 7.8948
Epoch [8/100], Step [2750/3236], Loss: 1.9916, Perplexity: 7.3272
Epoch [8/100], Step [2760/3236], Loss: 2.0004, Perplexity: 7.3921
Epoch [8/100], Step [2770/3236], Loss: 2.2723, Perplexity: 9.7020
Epoch [8/100], Step [2780/3236], Loss: 1.9633, Perplexity: 7.1225
Epoch [8/100], Step [2790/3236], Loss: 1.9627, Perplexity: 7.1184
Epoch [8/100], Step [2800/3236], Loss: 2.0361, Perplexity: 7.6603
Epoch [8/100], Step [2810/3236], Loss: 1.9539, Perplexity: 7.0565
Epoch [8/100], Step [2820/3236], Loss: 1.9018, Perplexity: 6.6980
Epoch [8/100], Step [2830/3236], Loss: 1.9267, Perplexity: 6.8670
Epoch [8/100], Step [2840/3236], Loss: 1.9951, Perplexity: 7.3528
Epoch [8/100], Step [2850/3236], Loss: 1.9435, Perplexity: 6.9833
Epoch [8/100], Step [2860/3236], Loss: 1.9927, Perplexity: 7.3357
Epoch [8/100], Step [2870/3236], Loss: 2.0176, Perplexity: 7.5202
Epoch [8/100], Step [2880/3236], Loss: 2.0542, Perplexity: 7.8009
Epoch [8/100], Step [2890/3236], Loss: 2.0611, Perplexity: 7.8543
Epoch [8/100], Step [2900/3236], Loss: 2.0388, Perplexity: 7.6816
Epoch [8/100], Step [2910/3236], Loss: 1.9361, Perplexity: 6.9318
Epoch [8/100], Step [2920/3236], Loss: 1.9656, Perplexity: 7.1391
Epoch [8/100], Step [2930/3236], Loss: 1.9656, Perplexity: 7.1393
Epoch [8/100], Step [2940/3236], Loss: 2.0048, Perplexity: 7.4246
Epoch [8/100], Step [2950/3236], Loss: 2.1292, Perplexity: 8.4085
Epoch [8/100], Step [2960/3236], Loss: 1.9239, Perplexity: 6.8474
Epoch [8/100], Step [2970/3236], Loss: 1.9815, Perplexity: 7.2537
Epoch [8/100], Step [2980/3236], Loss: 1.9320, Perplexity: 6.9035
Epoch [8/100], Step [2990/3236], Loss: 1.8994, Perplexity: 6.6816
Epoch [8/100], Step [3000/3236], Loss: 2.0338, Perplexity: 7.6434
Epoch [8/100], Step [3010/3236], Loss: 2.0008, Perplexity: 7.3950
Epoch [8/100], Step [3020/3236], Loss: 1.8941, Perplexity: 6.6469
Epoch [8/100], Step [3030/3236], Loss: 1.9455, Perplexity: 6.9970
Epoch [8/100], Step [3040/3236], Loss: 2.0819, Perplexity: 8.0200
Epoch [8/100], Step [3050/3236], Loss: 1.9782, Perplexity: 7.2299
Epoch [8/100], Step [3060/3236], Loss: 1.8814, Perplexity: 6.5624
Epoch [8/100], Step [3070/3236], Loss: 1.8711, Perplexity: 6.4952
Epoch [8/100], Step [3080/3236], Loss: 1.9448, Perplexity: 6.9920
Epoch [8/100], Step [3090/3236], Loss: 2.0415, Perplexity: 7.7025
Epoch [8/100], Step [3100/3236], Loss: 2.0296, Perplexity: 7.6107
Epoch [8/100], Step [3110/3236], Loss: 2.0681, Perplexity: 7.9101
Epoch [8/100], Step [3120/3236], Loss: 2.0085, Perplexity: 7.4524
Epoch [8/100], Step [3130/3236], Loss: 2.0516, Perplexity: 7.7803
Epoch [8/100], Step [3140/3236], Loss: 1.9618, Perplexity: 7.1123
Epoch [8/100], Step [3150/3236], Loss: 2.0339, Perplexity: 7.6436
Epoch [8/100], Step [3160/3236], Loss: 1.9777, Perplexity: 7.2261
Epoch [8/100], Step [3170/3236], Loss: 2.0059, Perplexity: 7.4328
Epoch [8/100], Step [3180/3236], Loss: 1.9855, Perplexity: 7.2824
Epoch [8/100], Step [3190/3236], Loss: 1.9851, Perplexity: 7.2801
Epoch [8/100], Step [3200/3236], Loss: 2.0662, Perplexity: 7.8945
Epoch [8/100], Step [3210/3236], Loss: 1.9747, Perplexity: 7.2044
Epoch [8/100], Step [3220/3236], Loss: 1.9823, Perplexity: 7.2594
Epoch [8/100], Step [3230/3236], Loss: 1.9354, Perplexity: 6.9270
start evaluate ...
261888 : a man riding a bike down a road next to a forest
44767 : a plate of food with carrots and a fork
230646 : a close up of a person holding a cake
523371 : a man riding a motorcycle with a helmet on
5225 : a baby sitting in a high chair with a teddy bear
325519 : a train traveling down tracks next to a river
187822 : a group of people on a street with skateboards
371564 : a woman holding an umbrella in the rain
514607 : a fire hydrant is on the side of a road
269020 : two zebras are standing in the snow with their butts
loading annotations into memory...
Done (t=0.80s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1369584.31 tokens per second.
PTBTokenizer tokenized 53704 tokens at 628882.06 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48208, 'guess': [48705, 43705, 38705, 33705], 'testlen': 48705, 'correct': [32935, 15888, 6833, 3008]}
('ratio:', 1.0103094922004439)
Bleu_1: 0.676
Bleu_2: 0.496
Bleu_3: 0.351
Bleu_4: 0.249
computing METEOR score...
METEOR: 0.229
computing Rouge score...
ROUGE_L: 0.497
computing CIDEr score...
CIDEr: 0.808
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.4 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].
Threads( StanfordCoreNLP ) [27.453 seconds]
SPICE evaluation took: 40.16 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [9/100], Step [10/3236], Loss: 1.9224, Perplexity: 6.8374
Epoch [9/100], Step [20/3236], Loss: 1.9769, Perplexity: 7.2207
Epoch [9/100], Step [30/3236], Loss: 2.0106, Perplexity: 7.4677
Epoch [9/100], Step [40/3236], Loss: 1.9166, Perplexity: 6.7978
Epoch [9/100], Step [50/3236], Loss: 1.8885, Perplexity: 6.6096
Epoch [9/100], Step [60/3236], Loss: 1.9964, Perplexity: 7.3622
Epoch [9/100], Step [70/3236], Loss: 1.9764, Perplexity: 7.2166
Epoch [9/100], Step [80/3236], Loss: 1.9531, Perplexity: 7.0506
Epoch [9/100], Step [90/3236], Loss: 1.9375, Perplexity: 6.9411
Epoch [9/100], Step [100/3236], Loss: 1.9646, Perplexity: 7.1323
Epoch [9/100], Step [110/3236], Loss: 2.0214, Perplexity: 7.5486
Epoch [9/100], Step [120/3236], Loss: 1.9235, Perplexity: 6.8446
Epoch [9/100], Step [130/3236], Loss: 1.9254, Perplexity: 6.8578
Epoch [9/100], Step [140/3236], Loss: 1.8798, Perplexity: 6.5522
Epoch [9/100], Step [150/3236], Loss: 1.8811, Perplexity: 6.5608
Epoch [9/100], Step [160/3236], Loss: 1.9628, Perplexity: 7.1195
Epoch [9/100], Step [170/3236], Loss: 1.8420, Perplexity: 6.3089
Epoch [9/100], Step [180/3236], Loss: 1.9828, Perplexity: 7.2634
Epoch [9/100], Step [190/3236], Loss: 1.8414, Perplexity: 6.3055
Epoch [9/100], Step [200/3236], Loss: 1.9231, Perplexity: 6.8420
Epoch [9/100], Step [210/3236], Loss: 1.9646, Perplexity: 7.1319
Epoch [9/100], Step [220/3236], Loss: 1.9188, Perplexity: 6.8129
Epoch [9/100], Step [230/3236], Loss: 1.9811, Perplexity: 7.2504
Epoch [9/100], Step [240/3236], Loss: 1.9025, Perplexity: 6.7027
Epoch [9/100], Step [250/3236], Loss: 1.8256, Perplexity: 6.2063
Epoch [9/100], Step [260/3236], Loss: 1.8853, Perplexity: 6.5882
Epoch [9/100], Step [270/3236], Loss: 1.9122, Perplexity: 6.7683
Epoch [9/100], Step [280/3236], Loss: 1.8754, Perplexity: 6.5233
Epoch [9/100], Step [290/3236], Loss: 1.9392, Perplexity: 6.9532
Epoch [9/100], Step [300/3236], Loss: 1.9456, Perplexity: 6.9978
Epoch [9/100], Step [310/3236], Loss: 1.9437, Perplexity: 6.9842
Epoch [9/100], Step [320/3236], Loss: 1.8308, Perplexity: 6.2391
Epoch [9/100], Step [330/3236], Loss: 1.9038, Perplexity: 6.7117
Epoch [9/100], Step [340/3236], Loss: 1.9535, Perplexity: 7.0534
Epoch [9/100], Step [350/3236], Loss: 1.8754, Perplexity: 6.5236
Epoch [9/100], Step [360/3236], Loss: 1.9747, Perplexity: 7.2042
Epoch [9/100], Step [370/3236], Loss: 1.8751, Perplexity: 6.5213
Epoch [9/100], Step [380/3236], Loss: 1.9570, Perplexity: 7.0784
Epoch [9/100], Step [390/3236], Loss: 1.9344, Perplexity: 6.9200
Epoch [9/100], Step [400/3236], Loss: 1.8533, Perplexity: 6.3806
Epoch [9/100], Step [410/3236], Loss: 2.1439, Perplexity: 8.5326
Epoch [9/100], Step [420/3236], Loss: 1.8522, Perplexity: 6.3738
Epoch [9/100], Step [430/3236], Loss: 1.9462, Perplexity: 7.0020
Epoch [9/100], Step [440/3236], Loss: 1.8477, Perplexity: 6.3451
Epoch [9/100], Step [450/3236], Loss: 1.8484, Perplexity: 6.3499
Epoch [9/100], Step [460/3236], Loss: 1.9358, Perplexity: 6.9296
Epoch [9/100], Step [470/3236], Loss: 1.8809, Perplexity: 6.5593
Epoch [9/100], Step [480/3236], Loss: 1.9856, Perplexity: 7.2833
Epoch [9/100], Step [490/3236], Loss: 1.8576, Perplexity: 6.4083
Epoch [9/100], Step [500/3236], Loss: 1.9174, Perplexity: 6.8035
Epoch [9/100], Step [510/3236], Loss: 1.8408, Perplexity: 6.3019
Epoch [9/100], Step [520/3236], Loss: 1.9827, Perplexity: 7.2620
Epoch [9/100], Step [530/3236], Loss: 1.9023, Perplexity: 6.7016
Epoch [9/100], Step [540/3236], Loss: 1.9054, Perplexity: 6.7223
Epoch [9/100], Step [550/3236], Loss: 2.0280, Perplexity: 7.5990
Epoch [9/100], Step [560/3236], Loss: 1.8214, Perplexity: 6.1805
Epoch [9/100], Step [570/3236], Loss: 1.8362, Perplexity: 6.2729
Epoch [9/100], Step [580/3236], Loss: 1.9476, Perplexity: 7.0120
Epoch [9/100], Step [590/3236], Loss: 1.9367, Perplexity: 6.9355
Epoch [9/100], Step [600/3236], Loss: 2.0404, Perplexity: 7.6934
Epoch [9/100], Step [610/3236], Loss: 1.9377, Perplexity: 6.9429
Epoch [9/100], Step [620/3236], Loss: 1.9761, Perplexity: 7.2144
Epoch [9/100], Step [630/3236], Loss: 1.9328, Perplexity: 6.9086
Epoch [9/100], Step [640/3236], Loss: 1.9007, Perplexity: 6.6903
Epoch [9/100], Step [650/3236], Loss: 1.9433, Perplexity: 6.9819
Epoch [9/100], Step [660/3236], Loss: 1.9203, Perplexity: 6.8231
Epoch [9/100], Step [670/3236], Loss: 1.9012, Perplexity: 6.6936
Epoch [9/100], Step [680/3236], Loss: 2.0438, Perplexity: 7.7196
Epoch [9/100], Step [690/3236], Loss: 2.0341, Perplexity: 7.6452
Epoch [9/100], Step [700/3236], Loss: 1.8582, Perplexity: 6.4119
Epoch [9/100], Step [710/3236], Loss: 1.8455, Perplexity: 6.3312
Epoch [9/100], Step [720/3236], Loss: 2.0517, Perplexity: 7.7814
Epoch [9/100], Step [730/3236], Loss: 2.0005, Perplexity: 7.3926
Epoch [9/100], Step [740/3236], Loss: 1.9800, Perplexity: 7.2428
Epoch [9/100], Step [750/3236], Loss: 1.9559, Perplexity: 7.0700
Epoch [9/100], Step [760/3236], Loss: 1.9426, Perplexity: 6.9770
Epoch [9/100], Step [770/3236], Loss: 1.9120, Perplexity: 6.7664
Epoch [9/100], Step [780/3236], Loss: 1.8930, Perplexity: 6.6393
Epoch [9/100], Step [790/3236], Loss: 1.8026, Perplexity: 6.0656
Epoch [9/100], Step [800/3236], Loss: 1.8789, Perplexity: 6.5463
Epoch [9/100], Step [810/3236], Loss: 1.8575, Perplexity: 6.4077
Epoch [9/100], Step [820/3236], Loss: 1.9073, Perplexity: 6.7346
Epoch [9/100], Step [830/3236], Loss: 1.8315, Perplexity: 6.2434
Epoch [9/100], Step [840/3236], Loss: 1.7737, Perplexity: 5.8924
Epoch [9/100], Step [850/3236], Loss: 1.8345, Perplexity: 6.2620
Epoch [9/100], Step [860/3236], Loss: 1.8699, Perplexity: 6.4873
Epoch [9/100], Step [870/3236], Loss: 1.9299, Perplexity: 6.8889
Epoch [9/100], Step [880/3236], Loss: 1.8805, Perplexity: 6.5565
Epoch [9/100], Step [890/3236], Loss: 1.9255, Perplexity: 6.8587
Epoch [9/100], Step [900/3236], Loss: 1.9184, Perplexity: 6.8099
Epoch [9/100], Step [910/3236], Loss: 1.9375, Perplexity: 6.9417
Epoch [9/100], Step [920/3236], Loss: 1.9281, Perplexity: 6.8764
Epoch [9/100], Step [930/3236], Loss: 1.9769, Perplexity: 7.2204
Epoch [9/100], Step [940/3236], Loss: 1.8534, Perplexity: 6.3816
Epoch [9/100], Step [950/3236], Loss: 1.9537, Perplexity: 7.0547
Epoch [9/100], Step [960/3236], Loss: 1.9040, Perplexity: 6.7127
Epoch [9/100], Step [970/3236], Loss: 1.9948, Perplexity: 7.3508
Epoch [9/100], Step [980/3236], Loss: 1.9441, Perplexity: 6.9876
Epoch [9/100], Step [990/3236], Loss: 1.9734, Perplexity: 7.1948
Epoch [9/100], Step [1000/3236], Loss: 2.0510, Perplexity: 7.7760
Epoch [9/100], Step [1010/3236], Loss: 1.9534, Perplexity: 7.0527
Epoch [9/100], Step [1020/3236], Loss: 2.0469, Perplexity: 7.7436
Epoch [9/100], Step [1030/3236], Loss: 1.9081, Perplexity: 6.7404
Epoch [9/100], Step [1040/3236], Loss: 1.8401, Perplexity: 6.2973
Epoch [9/100], Step [1050/3236], Loss: 1.8739, Perplexity: 6.5136
Epoch [9/100], Step [1060/3236], Loss: 1.9539, Perplexity: 7.0564
Epoch [9/100], Step [1070/3236], Loss: 2.0279, Perplexity: 7.5985
Epoch [9/100], Step [1080/3236], Loss: 1.8923, Perplexity: 6.6347
Epoch [9/100], Step [1090/3236], Loss: 1.8618, Perplexity: 6.4352
Epoch [9/100], Step [1100/3236], Loss: 2.0967, Perplexity: 8.1390
Epoch [9/100], Step [1110/3236], Loss: 1.8878, Perplexity: 6.6049
Epoch [9/100], Step [1120/3236], Loss: 1.9152, Perplexity: 6.7882
Epoch [9/100], Step [1130/3236], Loss: 1.9680, Perplexity: 7.1565
Epoch [9/100], Step [1140/3236], Loss: 1.9500, Perplexity: 7.0287
Epoch [9/100], Step [1150/3236], Loss: 2.0814, Perplexity: 8.0157
Epoch [9/100], Step [1160/3236], Loss: 2.0227, Perplexity: 7.5590
Epoch [9/100], Step [1170/3236], Loss: 1.9603, Perplexity: 7.1015
Epoch [9/100], Step [1180/3236], Loss: 1.9137, Perplexity: 6.7784
Epoch [9/100], Step [1190/3236], Loss: 1.9525, Perplexity: 7.0462
Epoch [9/100], Step [1200/3236], Loss: 1.9886, Perplexity: 7.3054
Epoch [9/100], Step [1210/3236], Loss: 1.9981, Perplexity: 7.3747
Epoch [9/100], Step [1220/3236], Loss: 2.0604, Perplexity: 7.8494
Epoch [9/100], Step [1230/3236], Loss: 1.9227, Perplexity: 6.8394
Epoch [9/100], Step [1240/3236], Loss: 1.9495, Perplexity: 7.0251
Epoch [9/100], Step [1250/3236], Loss: 1.9358, Perplexity: 6.9293
Epoch [9/100], Step [1260/3236], Loss: 1.9046, Perplexity: 6.7165
Epoch [9/100], Step [1270/3236], Loss: 1.8543, Perplexity: 6.3873
Epoch [9/100], Step [1280/3236], Loss: 1.9466, Perplexity: 7.0049
Epoch [9/100], Step [1290/3236], Loss: 1.9724, Perplexity: 7.1881
Epoch [9/100], Step [1300/3236], Loss: 1.9651, Perplexity: 7.1358
Epoch [9/100], Step [1310/3236], Loss: 1.9315, Perplexity: 6.8996
Epoch [9/100], Step [1320/3236], Loss: 1.9475, Perplexity: 7.0113
Epoch [9/100], Step [1330/3236], Loss: 2.1054, Perplexity: 8.2102
Epoch [9/100], Step [1340/3236], Loss: 2.0622, Perplexity: 7.8633
Epoch [9/100], Step [1350/3236], Loss: 1.8661, Perplexity: 6.4627
Epoch [9/100], Step [1360/3236], Loss: 2.0294, Perplexity: 7.6093
Epoch [9/100], Step [1370/3236], Loss: 1.8644, Perplexity: 6.4522
Epoch [9/100], Step [1380/3236], Loss: 1.8984, Perplexity: 6.6753
Epoch [9/100], Step [1390/3236], Loss: 2.0068, Perplexity: 7.4394
Epoch [9/100], Step [1400/3236], Loss: 2.0875, Perplexity: 8.0646
Epoch [9/100], Step [1410/3236], Loss: 1.9951, Perplexity: 7.3530
Epoch [9/100], Step [1420/3236], Loss: 2.0347, Perplexity: 7.6496
Epoch [9/100], Step [1430/3236], Loss: 1.9785, Perplexity: 7.2322
Epoch [9/100], Step [1440/3236], Loss: 2.0836, Perplexity: 8.0333
Epoch [9/100], Step [1450/3236], Loss: 1.9341, Perplexity: 6.9180
Epoch [9/100], Step [1460/3236], Loss: 1.9199, Perplexity: 6.8200
Epoch [9/100], Step [1470/3236], Loss: 2.0052, Perplexity: 7.4279
Epoch [9/100], Step [1480/3236], Loss: 2.0229, Perplexity: 7.5605
Epoch [9/100], Step [1490/3236], Loss: 2.0084, Perplexity: 7.4516
Epoch [9/100], Step [1500/3236], Loss: 1.9840, Perplexity: 7.2719
Epoch [9/100], Step [1510/3236], Loss: 1.8709, Perplexity: 6.4942
Epoch [9/100], Step [1520/3236], Loss: 1.8597, Perplexity: 6.4215
Epoch [9/100], Step [1530/3236], Loss: 1.8990, Perplexity: 6.6793
Epoch [9/100], Step [1540/3236], Loss: 1.8577, Perplexity: 6.4090
Epoch [9/100], Step [1550/3236], Loss: 1.9442, Perplexity: 6.9879
Epoch [9/100], Step [1560/3236], Loss: 2.0146, Perplexity: 7.4975
Epoch [9/100], Step [1570/3236], Loss: 2.0166, Perplexity: 7.5129
Epoch [9/100], Step [1580/3236], Loss: 1.9638, Perplexity: 7.1266
Epoch [9/100], Step [1590/3236], Loss: 1.9474, Perplexity: 7.0101
Epoch [9/100], Step [1600/3236], Loss: 1.9837, Perplexity: 7.2697
Epoch [9/100], Step [1610/3236], Loss: 2.0468, Perplexity: 7.7433
Epoch [9/100], Step [1620/3236], Loss: 1.9196, Perplexity: 6.8186
Epoch [9/100], Step [1630/3236], Loss: 1.9506, Perplexity: 7.0332
Epoch [9/100], Step [1640/3236], Loss: 1.9684, Perplexity: 7.1594
Epoch [9/100], Step [1650/3236], Loss: 2.0585, Perplexity: 7.8345
Epoch [9/100], Step [1660/3236], Loss: 1.8981, Perplexity: 6.6732
Epoch [9/100], Step [1670/3236], Loss: 1.9335, Perplexity: 6.9134
Epoch [9/100], Step [1680/3236], Loss: 1.9053, Perplexity: 6.7216
Epoch [9/100], Step [1690/3236], Loss: 2.0579, Perplexity: 7.8299
Epoch [9/100], Step [1700/3236], Loss: 2.0264, Perplexity: 7.5866
Epoch [9/100], Step [1710/3236], Loss: 1.9251, Perplexity: 6.8558
Epoch [9/100], Step [1720/3236], Loss: 1.9281, Perplexity: 6.8762
Epoch [9/100], Step [1730/3236], Loss: 1.9676, Perplexity: 7.1533
Epoch [9/100], Step [1740/3236], Loss: 1.9123, Perplexity: 6.7689
Epoch [9/100], Step [1750/3236], Loss: 1.9657, Perplexity: 7.1399
Epoch [9/100], Step [1760/3236], Loss: 2.0968, Perplexity: 8.1405
Epoch [9/100], Step [1770/3236], Loss: 1.9975, Perplexity: 7.3705
Epoch [9/100], Step [1780/3236], Loss: 1.9767, Perplexity: 7.2190
Epoch [9/100], Step [1790/3236], Loss: 1.9109, Perplexity: 6.7592
Epoch [9/100], Step [1800/3236], Loss: 1.8821, Perplexity: 6.5674
Epoch [9/100], Step [1810/3236], Loss: 2.0317, Perplexity: 7.6273
Epoch [9/100], Step [1820/3236], Loss: 1.7931, Perplexity: 6.0079
Epoch [9/100], Step [1830/3236], Loss: 2.1772, Perplexity: 8.8217
Epoch [9/100], Step [1840/3236], Loss: 2.0607, Perplexity: 7.8511
Epoch [9/100], Step [1850/3236], Loss: 2.0237, Perplexity: 7.5660
Epoch [9/100], Step [1860/3236], Loss: 2.0577, Perplexity: 7.8280
Epoch [9/100], Step [1870/3236], Loss: 1.8936, Perplexity: 6.6432
Epoch [9/100], Step [1880/3236], Loss: 1.9545, Perplexity: 7.0604
Epoch [9/100], Step [1890/3236], Loss: 1.8579, Perplexity: 6.4102
Epoch [9/100], Step [1900/3236], Loss: 1.9900, Perplexity: 7.3159
Epoch [9/100], Step [1910/3236], Loss: 1.9753, Perplexity: 7.2089
Epoch [9/100], Step [1920/3236], Loss: 1.9835, Perplexity: 7.2684
Epoch [9/100], Step [1930/3236], Loss: 1.9089, Perplexity: 6.7457
Epoch [9/100], Step [1940/3236], Loss: 1.9739, Perplexity: 7.1984
Epoch [9/100], Step [1950/3236], Loss: 1.9346, Perplexity: 6.9215
Epoch [9/100], Step [1960/3236], Loss: 1.9305, Perplexity: 6.8927
Epoch [9/100], Step [1970/3236], Loss: 1.8721, Perplexity: 6.5020
Epoch [9/100], Step [1980/3236], Loss: 1.9286, Perplexity: 6.8796
Epoch [9/100], Step [1990/3236], Loss: 1.9233, Perplexity: 6.8437
Epoch [9/100], Step [2000/3236], Loss: 2.0388, Perplexity: 7.6813
Epoch [9/100], Step [2010/3236], Loss: 2.1700, Perplexity: 8.7585
Epoch [9/100], Step [2020/3236], Loss: 2.0556, Perplexity: 7.8111
Epoch [9/100], Step [2030/3236], Loss: 2.0216, Perplexity: 7.5505
Epoch [9/100], Step [2040/3236], Loss: 2.0900, Perplexity: 8.0847
Epoch [9/100], Step [2050/3236], Loss: 1.9353, Perplexity: 6.9265
Epoch [9/100], Step [2060/3236], Loss: 1.9820, Perplexity: 7.2569
Epoch [9/100], Step [2070/3236], Loss: 1.9783, Perplexity: 7.2307
Epoch [9/100], Step [2080/3236], Loss: 1.9848, Perplexity: 7.2776
Epoch [9/100], Step [2090/3236], Loss: 2.0297, Perplexity: 7.6121
Epoch [9/100], Step [2100/3236], Loss: 1.9050, Perplexity: 6.7194
Epoch [9/100], Step [2110/3236], Loss: 2.0213, Perplexity: 7.5483
Epoch [9/100], Step [2120/3236], Loss: 1.8869, Perplexity: 6.5989
Epoch [9/100], Step [2130/3236], Loss: 1.9559, Perplexity: 7.0701
Epoch [9/100], Step [2140/3236], Loss: 2.0322, Perplexity: 7.6307
Epoch [9/100], Step [2150/3236], Loss: 2.0095, Perplexity: 7.4595
Epoch [9/100], Step [2160/3236], Loss: 1.9281, Perplexity: 6.8767
Epoch [9/100], Step [2170/3236], Loss: 1.9605, Perplexity: 7.1032
Epoch [9/100], Step [2180/3236], Loss: 1.9378, Perplexity: 6.9436
Epoch [9/100], Step [2190/3236], Loss: 1.9679, Perplexity: 7.1557
Epoch [9/100], Step [2200/3236], Loss: 1.9613, Perplexity: 7.1082
Epoch [9/100], Step [2210/3236], Loss: 1.9384, Perplexity: 6.9473
Epoch [9/100], Step [2220/3236], Loss: 1.9823, Perplexity: 7.2598
Epoch [9/100], Step [2230/3236], Loss: 1.8833, Perplexity: 6.5751
Epoch [9/100], Step [2240/3236], Loss: 1.9280, Perplexity: 6.8760
Epoch [9/100], Step [2250/3236], Loss: 1.9972, Perplexity: 7.3680
Epoch [9/100], Step [2260/3236], Loss: 1.9800, Perplexity: 7.2425
Epoch [9/100], Step [2270/3236], Loss: 2.0865, Perplexity: 8.0567
Epoch [9/100], Step [2280/3236], Loss: 1.9759, Perplexity: 7.2131
Epoch [9/100], Step [2290/3236], Loss: 1.9411, Perplexity: 6.9664
Epoch [9/100], Step [2300/3236], Loss: 1.9569, Perplexity: 7.0772
Epoch [9/100], Step [2310/3236], Loss: 1.9600, Perplexity: 7.0995
Epoch [9/100], Step [2320/3236], Loss: 1.9604, Perplexity: 7.1022
Epoch [9/100], Step [2330/3236], Loss: 1.9542, Perplexity: 7.0585
Epoch [9/100], Step [2340/3236], Loss: 1.8754, Perplexity: 6.5237
Epoch [9/100], Step [2350/3236], Loss: 1.9232, Perplexity: 6.8429
Epoch [9/100], Step [2360/3236], Loss: 1.8804, Perplexity: 6.5564
Epoch [9/100], Step [2370/3236], Loss: 1.9306, Perplexity: 6.8934
Epoch [9/100], Step [2380/3236], Loss: 1.8983, Perplexity: 6.6743
Epoch [9/100], Step [2390/3236], Loss: 1.9496, Perplexity: 7.0257
Epoch [9/100], Step [2400/3236], Loss: 1.9045, Perplexity: 6.7162
Epoch [9/100], Step [2410/3236], Loss: 2.0270, Perplexity: 7.5910
Epoch [9/100], Step [2420/3236], Loss: 1.9996, Perplexity: 7.3859
Epoch [9/100], Step [2430/3236], Loss: 2.0269, Perplexity: 7.5903
Epoch [9/100], Step [2440/3236], Loss: 2.1787, Perplexity: 8.8350
Epoch [9/100], Step [2450/3236], Loss: 1.9223, Perplexity: 6.8366
Epoch [9/100], Step [2460/3236], Loss: 1.8723, Perplexity: 6.5032
Epoch [9/100], Step [2470/3236], Loss: 1.9458, Perplexity: 6.9992
Epoch [9/100], Step [2480/3236], Loss: 1.9274, Perplexity: 6.8718
Epoch [9/100], Step [2490/3236], Loss: 1.8823, Perplexity: 6.5684
Epoch [9/100], Step [2500/3236], Loss: 1.9637, Perplexity: 7.1259
Epoch [9/100], Step [2510/3236], Loss: 1.8949, Perplexity: 6.6518
Epoch [9/100], Step [2520/3236], Loss: 1.8258, Perplexity: 6.2080
Epoch [9/100], Step [2530/3236], Loss: 1.9931, Perplexity: 7.3385
Epoch [9/100], Step [2540/3236], Loss: 2.0181, Perplexity: 7.5241
Epoch [9/100], Step [2550/3236], Loss: 1.9594, Perplexity: 7.0951
Epoch [9/100], Step [2560/3236], Loss: 1.9146, Perplexity: 6.7843
Epoch [9/100], Step [2570/3236], Loss: 1.9205, Perplexity: 6.8243
Epoch [9/100], Step [2580/3236], Loss: 2.0088, Perplexity: 7.4541
Epoch [9/100], Step [2590/3236], Loss: 1.9367, Perplexity: 6.9356
Epoch [9/100], Step [2600/3236], Loss: 1.9586, Perplexity: 7.0890
Epoch [9/100], Step [2610/3236], Loss: 1.9576, Perplexity: 7.0826
Epoch [9/100], Step [2620/3236], Loss: 1.9885, Perplexity: 7.3049
Epoch [9/100], Step [2630/3236], Loss: 1.8800, Perplexity: 6.5534
Epoch [9/100], Step [2640/3236], Loss: 1.8991, Perplexity: 6.6798
Epoch [9/100], Step [2650/3236], Loss: 1.8735, Perplexity: 6.5108
Epoch [9/100], Step [2660/3236], Loss: 1.9243, Perplexity: 6.8504
Epoch [9/100], Step [2670/3236], Loss: 1.9589, Perplexity: 7.0915
Epoch [9/100], Step [2680/3236], Loss: 1.9919, Perplexity: 7.3296
Epoch [9/100], Step [2690/3236], Loss: 1.8179, Perplexity: 6.1587
Epoch [9/100], Step [2700/3236], Loss: 2.1023, Perplexity: 8.1847
Epoch [9/100], Step [2710/3236], Loss: 1.8979, Perplexity: 6.6720
Epoch [9/100], Step [2720/3236], Loss: 1.8502, Perplexity: 6.3610
Epoch [9/100], Step [2730/3236], Loss: 1.9849, Perplexity: 7.2783
Epoch [9/100], Step [2740/3236], Loss: 1.9439, Perplexity: 6.9859
Epoch [9/100], Step [2750/3236], Loss: 1.9002, Perplexity: 6.6875
Epoch [9/100], Step [2760/3236], Loss: 1.9751, Perplexity: 7.2073
Epoch [9/100], Step [2770/3236], Loss: 1.9863, Perplexity: 7.2887
Epoch [9/100], Step [2780/3236], Loss: 1.9655, Perplexity: 7.1385
Epoch [9/100], Step [2790/3236], Loss: 2.0978, Perplexity: 8.1481
Epoch [9/100], Step [2800/3236], Loss: 2.1622, Perplexity: 8.6904
Epoch [9/100], Step [2810/3236], Loss: 1.9463, Perplexity: 7.0029
Epoch [9/100], Step [2820/3236], Loss: 2.0588, Perplexity: 7.8364
Epoch [9/100], Step [2830/3236], Loss: 1.9828, Perplexity: 7.2630
Epoch [9/100], Step [2840/3236], Loss: 1.8287, Perplexity: 6.2257
Epoch [9/100], Step [2850/3236], Loss: 1.8437, Perplexity: 6.3201
Epoch [9/100], Step [2860/3236], Loss: 2.0141, Perplexity: 7.4937
Epoch [9/100], Step [2870/3236], Loss: 2.0391, Perplexity: 7.6837
Epoch [9/100], Step [2880/3236], Loss: 2.0697, Perplexity: 7.9225
Epoch [9/100], Step [2890/3236], Loss: 1.9562, Perplexity: 7.0727
Epoch [9/100], Step [2900/3236], Loss: 2.0014, Perplexity: 7.3994
Epoch [9/100], Step [2910/3236], Loss: 1.9497, Perplexity: 7.0266
Epoch [9/100], Step [2920/3236], Loss: 2.0244, Perplexity: 7.5719
Epoch [9/100], Step [2930/3236], Loss: 2.0462, Perplexity: 7.7386
Epoch [9/100], Step [2940/3236], Loss: 1.8780, Perplexity: 6.5403
Epoch [9/100], Step [2950/3236], Loss: 1.9620, Perplexity: 7.1132
Epoch [9/100], Step [2960/3236], Loss: 1.9514, Perplexity: 7.0384
Epoch [9/100], Step [2970/3236], Loss: 1.9129, Perplexity: 6.7726
Epoch [9/100], Step [2980/3236], Loss: 1.9949, Perplexity: 7.3514
Epoch [9/100], Step [2990/3236], Loss: 1.8739, Perplexity: 6.5139
Epoch [9/100], Step [3000/3236], Loss: 1.9746, Perplexity: 7.2038
Epoch [9/100], Step [3010/3236], Loss: 2.0714, Perplexity: 7.9355
Epoch [9/100], Step [3020/3236], Loss: 2.0440, Perplexity: 7.7217
Epoch [9/100], Step [3030/3236], Loss: 1.8718, Perplexity: 6.5002
Epoch [9/100], Step [3040/3236], Loss: 1.9398, Perplexity: 6.9574
Epoch [9/100], Step [3050/3236], Loss: 2.0371, Perplexity: 7.6682
Epoch [9/100], Step [3060/3236], Loss: 1.9595, Perplexity: 7.0956
Epoch [9/100], Step [3070/3236], Loss: 1.9604, Perplexity: 7.1022
Epoch [9/100], Step [3080/3236], Loss: 1.9716, Perplexity: 7.1822
Epoch [9/100], Step [3090/3236], Loss: 1.9819, Perplexity: 7.2563
Epoch [9/100], Step [3100/3236], Loss: 1.9722, Perplexity: 7.1868
Epoch [9/100], Step [3110/3236], Loss: 1.9221, Perplexity: 6.8354
Epoch [9/100], Step [3120/3236], Loss: 1.8217, Perplexity: 6.1825
Epoch [9/100], Step [3130/3236], Loss: 1.9406, Perplexity: 6.9633
Epoch [9/100], Step [3140/3236], Loss: 2.1222, Perplexity: 8.3494
Epoch [9/100], Step [3150/3236], Loss: 2.0695, Perplexity: 7.9210
Epoch [9/100], Step [3160/3236], Loss: 2.0298, Perplexity: 7.6123
Epoch [9/100], Step [3170/3236], Loss: 1.9853, Perplexity: 7.2812
Epoch [9/100], Step [3180/3236], Loss: 2.0193, Perplexity: 7.5334
Epoch [9/100], Step [3190/3236], Loss: 1.8640, Perplexity: 6.4494
Epoch [9/100], Step [3200/3236], Loss: 2.0370, Perplexity: 7.6678
Epoch [9/100], Step [3210/3236], Loss: 1.8457, Perplexity: 6.3326
Epoch [9/100], Step [3220/3236], Loss: 1.9339, Perplexity: 6.9161
Epoch [9/100], Step [3230/3236], Loss: 1.9740, Perplexity: 7.1992
start evaluate ...
144809 : a bathroom with a toilet and a sink
56129 : a teddy bear sitting on a desk next to a book shelf
323552 : a woman in a black dress is standing in front of a suitcase
239894 : a woman in a red dress is holding a teddy bear
229601 : a baseball player is getting ready to hit a ball
322056 : a man in a hat and a horse on a horse
364608 : two men standing on a beach with a surfboard
331230 : a table with a plate of fruit and a cup
377352 : a man riding a motorcycle with a side car
169800 : a woman walking down a street while holding an umbrella
loading annotations into memory...
Done (t=0.87s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1293737.50 tokens per second.
PTBTokenizer tokenized 53543 tokens at 622272.54 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48115, 'guess': [48544, 43544, 38544, 33544], 'testlen': 48544, 'correct': [33004, 16048, 6901, 2935]}
('ratio:', 1.0089161384183518)
Bleu_1: 0.680
Bleu_2: 0.501
Bleu_3: 0.355
Bleu_4: 0.250
computing METEOR score...
METEOR: 0.229
computing Rouge score...
ROUGE_L: 0.498
computing CIDEr score...
CIDEr: 0.808
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [25.915 seconds]
SPICE evaluation took: 36.35 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
Epoch [10/100], Step [10/3236], Loss: 1.8953, Perplexity: 6.6545
Epoch [10/100], Step [20/3236], Loss: 1.9368, Perplexity: 6.9365
Epoch [10/100], Step [30/3236], Loss: 1.9530, Perplexity: 7.0500
Epoch [10/100], Step [40/3236], Loss: 1.7857, Perplexity: 5.9635
Epoch [10/100], Step [50/3236], Loss: 1.8028, Perplexity: 6.0666
Epoch [10/100], Step [60/3236], Loss: 1.8847, Perplexity: 6.5843
Epoch [10/100], Step [70/3236], Loss: 1.9146, Perplexity: 6.7844
Epoch [10/100], Step [80/3236], Loss: 1.9565, Perplexity: 7.0744
Epoch [10/100], Step [90/3236], Loss: 1.8942, Perplexity: 6.6471
Epoch [10/100], Step [100/3236], Loss: 1.9723, Perplexity: 7.1868
Epoch [10/100], Step [110/3236], Loss: 1.9514, Perplexity: 7.0385
Epoch [10/100], Step [120/3236], Loss: 1.7917, Perplexity: 5.9999
Epoch [10/100], Step [130/3236], Loss: 2.0091, Perplexity: 7.4563
Epoch [10/100], Step [140/3236], Loss: 1.9129, Perplexity: 6.7727
Epoch [10/100], Step [150/3236], Loss: 1.9521, Perplexity: 7.0438
Epoch [10/100], Step [160/3236], Loss: 1.8256, Perplexity: 6.2065
Epoch [10/100], Step [170/3236], Loss: 1.8639, Perplexity: 6.4489
Epoch [10/100], Step [180/3236], Loss: 1.7806, Perplexity: 5.9334
Epoch [10/100], Step [190/3236], Loss: 1.8297, Perplexity: 6.2323
Epoch [10/100], Step [200/3236], Loss: 1.8914, Perplexity: 6.6287
Epoch [10/100], Step [210/3236], Loss: 1.9095, Perplexity: 6.7495
Epoch [10/100], Step [220/3236], Loss: 1.8668, Perplexity: 6.4676
Epoch [10/100], Step [230/3236], Loss: 1.8519, Perplexity: 6.3718
Epoch [10/100], Step [240/3236], Loss: 1.8307, Perplexity: 6.2381
Epoch [10/100], Step [250/3236], Loss: 1.8727, Perplexity: 6.5060
Epoch [10/100], Step [260/3236], Loss: 1.8585, Perplexity: 6.4142
Epoch [10/100], Step [270/3236], Loss: 1.8306, Perplexity: 6.2377
Epoch [10/100], Step [280/3236], Loss: 1.8085, Perplexity: 6.1013
Epoch [10/100], Step [290/3236], Loss: 1.9452, Perplexity: 6.9953
Epoch [10/100], Step [300/3236], Loss: 1.9401, Perplexity: 6.9594
Epoch [10/100], Step [310/3236], Loss: 1.8552, Perplexity: 6.3933
Epoch [10/100], Step [320/3236], Loss: 1.7477, Perplexity: 5.7415
Epoch [10/100], Step [330/3236], Loss: 1.8159, Perplexity: 6.1465
Epoch [10/100], Step [340/3236], Loss: 1.9658, Perplexity: 7.1403
Epoch [10/100], Step [350/3236], Loss: 1.8464, Perplexity: 6.3371
Epoch [10/100], Step [360/3236], Loss: 1.8698, Perplexity: 6.4868
Epoch [10/100], Step [370/3236], Loss: 1.8591, Perplexity: 6.4177
Epoch [10/100], Step [380/3236], Loss: 1.8670, Perplexity: 6.4688
Epoch [10/100], Step [390/3236], Loss: 1.9420, Perplexity: 6.9727
Epoch [10/100], Step [400/3236], Loss: 1.8539, Perplexity: 6.3845
Epoch [10/100], Step [410/3236], Loss: 1.9160, Perplexity: 6.7938
Epoch [10/100], Step [420/3236], Loss: 1.8418, Perplexity: 6.3078
Epoch [10/100], Step [430/3236], Loss: 1.8125, Perplexity: 6.1260
Epoch [10/100], Step [440/3236], Loss: 1.7879, Perplexity: 5.9767
Epoch [10/100], Step [450/3236], Loss: 1.9305, Perplexity: 6.8931
Epoch [10/100], Step [460/3236], Loss: 1.8555, Perplexity: 6.3948
Epoch [10/100], Step [470/3236], Loss: 1.8869, Perplexity: 6.5986
Epoch [10/100], Step [480/3236], Loss: 1.9218, Perplexity: 6.8332
Epoch [10/100], Step [490/3236], Loss: 1.9660, Perplexity: 7.1418
Epoch [10/100], Step [500/3236], Loss: 1.8372, Perplexity: 6.2791
Epoch [10/100], Step [510/3236], Loss: 1.8803, Perplexity: 6.5554
Epoch [10/100], Step [520/3236], Loss: 1.7906, Perplexity: 5.9929
Epoch [10/100], Step [530/3236], Loss: 1.9062, Perplexity: 6.7274
Epoch [10/100], Step [540/3236], Loss: 1.9079, Perplexity: 6.7389
Epoch [10/100], Step [550/3236], Loss: 1.7781, Perplexity: 5.9186
Epoch [10/100], Step [560/3236], Loss: 1.9129, Perplexity: 6.7725
Epoch [10/100], Step [570/3236], Loss: 1.8761, Perplexity: 6.5281
Epoch [10/100], Step [580/3236], Loss: 1.8478, Perplexity: 6.3456
Epoch [10/100], Step [590/3236], Loss: 1.8001, Perplexity: 6.0501
Epoch [10/100], Step [600/3236], Loss: 1.8990, Perplexity: 6.6792
Epoch [10/100], Step [610/3236], Loss: 1.9388, Perplexity: 6.9506
Epoch [10/100], Step [620/3236], Loss: 1.9387, Perplexity: 6.9494
Epoch [10/100], Step [630/3236], Loss: 1.9209, Perplexity: 6.8274
Epoch [10/100], Step [640/3236], Loss: 1.8051, Perplexity: 6.0804
Epoch [10/100], Step [650/3236], Loss: 1.9398, Perplexity: 6.9572
Epoch [10/100], Step [660/3236], Loss: 1.9665, Perplexity: 7.1455
Epoch [10/100], Step [670/3236], Loss: 1.9087, Perplexity: 6.7441
Epoch [10/100], Step [680/3236], Loss: 1.9015, Perplexity: 6.6959
Epoch [10/100], Step [690/3236], Loss: 1.8676, Perplexity: 6.4728
Epoch [10/100], Step [700/3236], Loss: 1.8534, Perplexity: 6.3817
Epoch [10/100], Step [710/3236], Loss: 1.6951, Perplexity: 5.4472
Epoch [10/100], Step [720/3236], Loss: 1.8672, Perplexity: 6.4703
Epoch [10/100], Step [730/3236], Loss: 1.8869, Perplexity: 6.5988
Epoch [10/100], Step [740/3236], Loss: 1.8344, Perplexity: 6.2616
Epoch [10/100], Step [750/3236], Loss: 1.7300, Perplexity: 5.6409
Epoch [10/100], Step [760/3236], Loss: 1.9212, Perplexity: 6.8293
Epoch [10/100], Step [770/3236], Loss: 1.9277, Perplexity: 6.8737
Epoch [10/100], Step [780/3236], Loss: 1.8531, Perplexity: 6.3797
Epoch [10/100], Step [790/3236], Loss: 1.9366, Perplexity: 6.9351
Epoch [10/100], Step [800/3236], Loss: 1.9658, Perplexity: 7.1408
Epoch [10/100], Step [810/3236], Loss: 1.8653, Perplexity: 6.4577
Epoch [10/100], Step [820/3236], Loss: 1.9923, Perplexity: 7.3324
Epoch [10/100], Step [830/3236], Loss: 1.9788, Perplexity: 7.2342
Epoch [10/100], Step [840/3236], Loss: 1.8033, Perplexity: 6.0699
Epoch [10/100], Step [850/3236], Loss: 1.8442, Perplexity: 6.3231
Epoch [10/100], Step [860/3236], Loss: 1.7931, Perplexity: 6.0080
Epoch [10/100], Step [870/3236], Loss: 1.9212, Perplexity: 6.8289
Epoch [10/100], Step [880/3236], Loss: 1.7948, Perplexity: 6.0182
Epoch [10/100], Step [890/3236], Loss: 1.8716, Perplexity: 6.4986
Epoch [10/100], Step [900/3236], Loss: 1.8394, Perplexity: 6.2926
Epoch [10/100], Step [910/3236], Loss: 1.7647, Perplexity: 5.8401
Epoch [10/100], Step [920/3236], Loss: 1.8624, Perplexity: 6.4393
Epoch [10/100], Step [930/3236], Loss: 1.8340, Perplexity: 6.2586
Epoch [10/100], Step [940/3236], Loss: 1.8140, Perplexity: 6.1352
Epoch [10/100], Step [950/3236], Loss: 1.9798, Perplexity: 7.2412
Epoch [10/100], Step [960/3236], Loss: 1.8836, Perplexity: 6.5769
Epoch [10/100], Step [970/3236], Loss: 1.9331, Perplexity: 6.9108
Epoch [10/100], Step [980/3236], Loss: 1.9274, Perplexity: 6.8713
Epoch [10/100], Step [990/3236], Loss: 1.8635, Perplexity: 6.4465
Epoch [10/100], Step [1000/3236], Loss: 1.9730, Perplexity: 7.1925
Epoch [10/100], Step [1010/3236], Loss: 1.9335, Perplexity: 6.9135
Epoch [10/100], Step [1020/3236], Loss: 1.9153, Perplexity: 6.7892
Epoch [10/100], Step [1030/3236], Loss: 1.9175, Perplexity: 6.8042
Epoch [10/100], Step [1040/3236], Loss: 2.0140, Perplexity: 7.4934
Epoch [10/100], Step [1050/3236], Loss: 1.8889, Perplexity: 6.6120
Epoch [10/100], Step [1060/3236], Loss: 1.8942, Perplexity: 6.6473
Epoch [10/100], Step [1070/3236], Loss: 1.8942, Perplexity: 6.6473
Epoch [10/100], Step [1080/3236], Loss: 1.9779, Perplexity: 7.2279
Epoch [10/100], Step [1090/3236], Loss: 1.8761, Perplexity: 6.5282
Epoch [10/100], Step [1100/3236], Loss: 1.9813, Perplexity: 7.2522
Epoch [10/100], Step [1110/3236], Loss: 1.9218, Perplexity: 6.8335
Epoch [10/100], Step [1120/3236], Loss: 1.8635, Perplexity: 6.4465
Epoch [10/100], Step [1130/3236], Loss: 1.9757, Perplexity: 7.2116
Epoch [10/100], Step [1140/3236], Loss: 1.9021, Perplexity: 6.6999
Epoch [10/100], Step [1150/3236], Loss: 1.9889, Perplexity: 7.3073
Epoch [10/100], Step [1160/3236], Loss: 1.8428, Perplexity: 6.3144
Epoch [10/100], Step [1170/3236], Loss: 1.8522, Perplexity: 6.3736
Epoch [10/100], Step [1180/3236], Loss: 1.9677, Perplexity: 7.1541
Epoch [10/100], Step [1190/3236], Loss: 1.8345, Perplexity: 6.2618
Epoch [10/100], Step [1200/3236], Loss: 1.9097, Perplexity: 6.7509
Epoch [10/100], Step [1210/3236], Loss: 1.9311, Perplexity: 6.8969
Epoch [10/100], Step [1220/3236], Loss: 1.7783, Perplexity: 5.9199
Epoch [10/100], Step [1230/3236], Loss: 1.8488, Perplexity: 6.3523
Epoch [10/100], Step [1240/3236], Loss: 1.9880, Perplexity: 7.3010
Epoch [10/100], Step [1250/3236], Loss: 1.9090, Perplexity: 6.7461
Epoch [10/100], Step [1260/3236], Loss: 1.8323, Perplexity: 6.2485
Epoch [10/100], Step [1270/3236], Loss: 1.8742, Perplexity: 6.5155
Epoch [10/100], Step [1280/3236], Loss: 1.9053, Perplexity: 6.7216
Epoch [10/100], Step [1290/3236], Loss: 1.9936, Perplexity: 7.3417
Epoch [10/100], Step [1300/3236], Loss: 1.8797, Perplexity: 6.5517
Epoch [10/100], Step [1310/3236], Loss: 1.8528, Perplexity: 6.3778
Epoch [10/100], Step [1320/3236], Loss: 1.8823, Perplexity: 6.5685
Epoch [10/100], Step [1330/3236], Loss: 1.9657, Perplexity: 7.1396
Epoch [10/100], Step [1340/3236], Loss: 2.0128, Perplexity: 7.4844
Epoch [10/100], Step [1350/3236], Loss: 1.9063, Perplexity: 6.7282
Epoch [10/100], Step [1360/3236], Loss: 1.8798, Perplexity: 6.5523
Epoch [10/100], Step [1370/3236], Loss: 1.8349, Perplexity: 6.2645
Epoch [10/100], Step [1380/3236], Loss: 1.9822, Perplexity: 7.2588
Epoch [10/100], Step [1390/3236], Loss: 1.8990, Perplexity: 6.6790
Epoch [10/100], Step [1400/3236], Loss: 1.8677, Perplexity: 6.4733
Epoch [10/100], Step [1410/3236], Loss: 1.8622, Perplexity: 6.4382
Epoch [10/100], Step [1420/3236], Loss: 1.9457, Perplexity: 6.9983
Epoch [10/100], Step [1430/3236], Loss: 1.8850, Perplexity: 6.5865
Epoch [10/100], Step [1440/3236], Loss: 1.8712, Perplexity: 6.4963
Epoch [10/100], Step [1450/3236], Loss: 1.9534, Perplexity: 7.0526
Epoch [10/100], Step [1460/3236], Loss: 2.1192, Perplexity: 8.3243
Epoch [10/100], Step [1470/3236], Loss: 1.8682, Perplexity: 6.4765
Epoch [10/100], Step [1480/3236], Loss: 1.9434, Perplexity: 6.9825
Epoch [10/100], Step [1490/3236], Loss: 1.9328, Perplexity: 6.9091
Epoch [10/100], Step [1500/3236], Loss: 1.9105, Perplexity: 6.7566
Epoch [10/100], Step [1510/3236], Loss: 1.8462, Perplexity: 6.3359
Epoch [10/100], Step [1520/3236], Loss: 1.8766, Perplexity: 6.5312
Epoch [10/100], Step [1530/3236], Loss: 1.9176, Perplexity: 6.8043
Epoch [10/100], Step [1540/3236], Loss: 1.9094, Perplexity: 6.7490
Epoch [10/100], Step [1550/3236], Loss: 1.9706, Perplexity: 7.1752
Epoch [10/100], Step [1560/3236], Loss: 1.9612, Perplexity: 7.1082
Epoch [10/100], Step [1570/3236], Loss: 1.9121, Perplexity: 6.7670
Epoch [10/100], Step [1580/3236], Loss: 1.9069, Perplexity: 6.7320
Epoch [10/100], Step [1590/3236], Loss: 1.8744, Perplexity: 6.5168
Epoch [10/100], Step [1600/3236], Loss: 1.9578, Perplexity: 7.0837
Epoch [10/100], Step [1610/3236], Loss: 1.9490, Perplexity: 7.0217
Epoch [10/100], Step [1620/3236], Loss: 1.8024, Perplexity: 6.0641
Epoch [10/100], Step [1630/3236], Loss: 1.9046, Perplexity: 6.7168
Epoch [10/100], Step [1640/3236], Loss: 1.9211, Perplexity: 6.8281
Epoch [10/100], Step [1650/3236], Loss: 1.8623, Perplexity: 6.4383
Epoch [10/100], Step [1660/3236], Loss: 1.7897, Perplexity: 5.9879
Epoch [10/100], Step [1670/3236], Loss: 1.9358, Perplexity: 6.9295
Epoch [10/100], Step [1680/3236], Loss: 1.8626, Perplexity: 6.4405
Epoch [10/100], Step [1690/3236], Loss: 1.9481, Perplexity: 7.0150
Epoch [10/100], Step [1700/3236], Loss: 2.0217, Perplexity: 7.5509
Epoch [10/100], Step [1710/3236], Loss: 1.9033, Perplexity: 6.7079
Epoch [10/100], Step [1720/3236], Loss: 1.9239, Perplexity: 6.8478
Epoch [10/100], Step [1730/3236], Loss: 1.8649, Perplexity: 6.4553
Epoch [10/100], Step [1740/3236], Loss: 1.8940, Perplexity: 6.6456
Epoch [10/100], Step [1750/3236], Loss: 1.9477, Perplexity: 7.0128
Epoch [10/100], Step [1760/3236], Loss: 2.0227, Perplexity: 7.5590
Epoch [10/100], Step [1770/3236], Loss: 1.9791, Perplexity: 7.2364
Epoch [10/100], Step [1780/3236], Loss: 1.9842, Perplexity: 7.2730
Epoch [10/100], Step [1790/3236], Loss: 1.9092, Perplexity: 6.7479
Epoch [10/100], Step [1800/3236], Loss: 1.9645, Perplexity: 7.1312
Epoch [10/100], Step [1810/3236], Loss: 1.9548, Perplexity: 7.0625
Epoch [10/100], Step [1820/3236], Loss: 1.8447, Perplexity: 6.3260
Epoch [10/100], Step [1830/3236], Loss: 1.9116, Perplexity: 6.7642
Epoch [10/100], Step [1840/3236], Loss: 1.9640, Perplexity: 7.1277
Epoch [10/100], Step [1850/3236], Loss: 1.9251, Perplexity: 6.8559
Epoch [10/100], Step [1860/3236], Loss: 1.8241, Perplexity: 6.1975
Epoch [10/100], Step [1870/3236], Loss: 1.9721, Perplexity: 7.1857
Epoch [10/100], Step [1880/3236], Loss: 1.9961, Perplexity: 7.3606
Epoch [10/100], Step [1890/3236], Loss: 1.9637, Perplexity: 7.1258
Epoch [10/100], Step [1900/3236], Loss: 1.8748, Perplexity: 6.5193
Epoch [10/100], Step [1910/3236], Loss: 1.9952, Perplexity: 7.3536
Epoch [10/100], Step [1920/3236], Loss: 1.8905, Perplexity: 6.6224
Epoch [10/100], Step [1930/3236], Loss: 1.8018, Perplexity: 6.0605
Epoch [10/100], Step [1940/3236], Loss: 1.9319, Perplexity: 6.9028
Epoch [10/100], Step [1950/3236], Loss: 1.9073, Perplexity: 6.7346
Epoch [10/100], Step [1960/3236], Loss: 1.8400, Perplexity: 6.2964
Epoch [10/100], Step [1970/3236], Loss: 1.8715, Perplexity: 6.4981
Epoch [10/100], Step [1980/3236], Loss: 1.9026, Perplexity: 6.7031
Epoch [10/100], Step [1990/3236], Loss: 1.9131, Perplexity: 6.7742
Epoch [10/100], Step [2000/3236], Loss: 2.0357, Perplexity: 7.6573
Epoch [10/100], Step [2010/3236], Loss: 2.0768, Perplexity: 7.9785
Epoch [10/100], Step [2020/3236], Loss: 1.9065, Perplexity: 6.7293
Epoch [10/100], Step [2030/3236], Loss: 1.8029, Perplexity: 6.0673
Epoch [10/100], Step [2040/3236], Loss: 1.8271, Perplexity: 6.2158
Epoch [10/100], Step [2050/3236], Loss: 1.8929, Perplexity: 6.6389
Epoch [10/100], Step [2060/3236], Loss: 2.0776, Perplexity: 7.9857
Epoch [10/100], Step [2070/3236], Loss: 1.8883, Perplexity: 6.6082
Epoch [10/100], Step [2080/3236], Loss: 1.8894, Perplexity: 6.6155
Epoch [10/100], Step [2090/3236], Loss: 1.8202, Perplexity: 6.1733
Epoch [10/100], Step [2100/3236], Loss: 1.9335, Perplexity: 6.9139
Epoch [10/100], Step [2110/3236], Loss: 1.8902, Perplexity: 6.6209
Epoch [10/100], Step [2120/3236], Loss: 1.8285, Perplexity: 6.2246
Epoch [10/100], Step [2130/3236], Loss: 1.8043, Perplexity: 6.0755
Epoch [10/100], Step [2140/3236], Loss: 1.9439, Perplexity: 6.9860
Epoch [10/100], Step [2150/3236], Loss: 1.8588, Perplexity: 6.4159
Epoch [10/100], Step [2160/3236], Loss: 1.9880, Perplexity: 7.3011
Epoch [10/100], Step [2170/3236], Loss: 1.9826, Perplexity: 7.2614
Epoch [10/100], Step [2180/3236], Loss: 1.9934, Perplexity: 7.3401
Epoch [10/100], Step [2190/3236], Loss: 1.9256, Perplexity: 6.8592
Epoch [10/100], Step [2200/3236], Loss: 1.9333, Perplexity: 6.9126
Epoch [10/100], Step [2210/3236], Loss: 1.9888, Perplexity: 7.3069
Epoch [10/100], Step [2220/3236], Loss: 2.0370, Perplexity: 7.6675
Epoch [10/100], Step [2230/3236], Loss: 1.8454, Perplexity: 6.3304
Epoch [10/100], Step [2240/3236], Loss: 1.8151, Perplexity: 6.1417
Epoch [10/100], Step [2250/3236], Loss: 2.0122, Perplexity: 7.4799
Epoch [10/100], Step [2260/3236], Loss: 1.9134, Perplexity: 6.7761
Epoch [10/100], Step [2270/3236], Loss: 1.8921, Perplexity: 6.6330
Epoch [10/100], Step [2280/3236], Loss: 1.7822, Perplexity: 5.9426
Epoch [10/100], Step [2290/3236], Loss: 2.0251, Perplexity: 7.5771
Epoch [10/100], Step [2300/3236], Loss: 1.9308, Perplexity: 6.8953
Epoch [10/100], Step [2310/3236], Loss: 1.8166, Perplexity: 6.1506
Epoch [10/100], Step [2320/3236], Loss: 1.8874, Perplexity: 6.6024
Epoch [10/100], Step [2330/3236], Loss: 1.8231, Perplexity: 6.1912
Epoch [10/100], Step [2340/3236], Loss: 1.9235, Perplexity: 6.8448
Epoch [10/100], Step [2350/3236], Loss: 1.9417, Perplexity: 6.9706
Epoch [10/100], Step [2360/3236], Loss: 1.9238, Perplexity: 6.8473
Epoch [10/100], Step [2370/3236], Loss: 2.0378, Perplexity: 7.6737
Epoch [10/100], Step [2380/3236], Loss: 1.9335, Perplexity: 6.9140
Epoch [10/100], Step [2390/3236], Loss: 1.9169, Perplexity: 6.8000
Epoch [10/100], Step [2400/3236], Loss: 1.9399, Perplexity: 6.9579
Epoch [10/100], Step [2410/3236], Loss: 1.9724, Perplexity: 7.1881
Epoch [10/100], Step [2420/3236], Loss: 1.8886, Perplexity: 6.6099
Epoch [10/100], Step [2430/3236], Loss: 1.8722, Perplexity: 6.5028
Epoch [10/100], Step [2440/3236], Loss: 1.9281, Perplexity: 6.8761
Epoch [10/100], Step [2450/3236], Loss: 1.8415, Perplexity: 6.3057
Epoch [10/100], Step [2460/3236], Loss: 1.7343, Perplexity: 5.6651
Epoch [10/100], Step [2470/3236], Loss: 1.9197, Perplexity: 6.8192
Epoch [10/100], Step [2480/3236], Loss: 1.9238, Perplexity: 6.8471
Epoch [10/100], Step [2490/3236], Loss: 1.9704, Perplexity: 7.1737
Epoch [10/100], Step [2500/3236], Loss: 1.9331, Perplexity: 6.9111
Epoch [10/100], Step [2510/3236], Loss: 2.0415, Perplexity: 7.7019
Epoch [10/100], Step [2520/3236], Loss: 1.9220, Perplexity: 6.8349
Epoch [10/100], Step [2530/3236], Loss: 1.9313, Perplexity: 6.8988
Epoch [10/100], Step [2540/3236], Loss: 1.9735, Perplexity: 7.1957
Epoch [10/100], Step [2550/3236], Loss: 1.8591, Perplexity: 6.4178
Epoch [10/100], Step [2560/3236], Loss: 1.9197, Perplexity: 6.8191
Epoch [10/100], Step [2570/3236], Loss: 1.9460, Perplexity: 7.0006
Epoch [10/100], Step [2580/3236], Loss: 2.0080, Perplexity: 7.4480
Epoch [10/100], Step [2590/3236], Loss: 2.0090, Perplexity: 7.4559
Epoch [10/100], Step [2600/3236], Loss: 1.9661, Perplexity: 7.1428
Epoch [10/100], Step [2610/3236], Loss: 1.9694, Perplexity: 7.1666
Epoch [10/100], Step [2620/3236], Loss: 1.9577, Perplexity: 7.0834
Epoch [10/100], Step [2630/3236], Loss: 1.9408, Perplexity: 6.9647
Epoch [10/100], Step [2640/3236], Loss: 2.0027, Perplexity: 7.4093
Epoch [10/100], Step [2650/3236], Loss: 1.8611, Perplexity: 6.4306
Epoch [10/100], Step [2660/3236], Loss: 2.0000, Perplexity: 7.3890
Epoch [10/100], Step [2670/3236], Loss: 1.9614, Perplexity: 7.1092
Epoch [10/100], Step [2680/3236], Loss: 1.8623, Perplexity: 6.4384
Epoch [10/100], Step [2690/3236], Loss: 1.9105, Perplexity: 6.7567
Epoch [10/100], Step [2700/3236], Loss: 1.9871, Perplexity: 7.2941
Epoch [10/100], Step [2710/3236], Loss: 1.8720, Perplexity: 6.5010
Epoch [10/100], Step [2720/3236], Loss: 2.0120, Perplexity: 7.4786
Epoch [10/100], Step [2730/3236], Loss: 1.9274, Perplexity: 6.8713
Epoch [10/100], Step [2740/3236], Loss: 1.9624, Perplexity: 7.1163
Epoch [10/100], Step [2750/3236], Loss: 2.0216, Perplexity: 7.5507
Epoch [10/100], Step [2760/3236], Loss: 1.8487, Perplexity: 6.3516
Epoch [10/100], Step [2770/3236], Loss: 2.0273, Perplexity: 7.5937
Epoch [10/100], Step [2780/3236], Loss: 1.8889, Perplexity: 6.6124
Epoch [10/100], Step [2790/3236], Loss: 1.9038, Perplexity: 6.7115
Epoch [10/100], Step [2800/3236], Loss: 2.0067, Perplexity: 7.4389
Epoch [10/100], Step [2810/3236], Loss: 2.0812, Perplexity: 8.0139
Epoch [10/100], Step [2820/3236], Loss: 1.9899, Perplexity: 7.3151
Epoch [10/100], Step [2830/3236], Loss: 1.9564, Perplexity: 7.0740
Epoch [10/100], Step [2840/3236], Loss: 1.8288, Perplexity: 6.2265
Epoch [10/100], Step [2850/3236], Loss: 1.8584, Perplexity: 6.4137
Epoch [10/100], Step [2860/3236], Loss: 1.9184, Perplexity: 6.8098
Epoch [10/100], Step [2870/3236], Loss: 1.9575, Perplexity: 7.0818
Epoch [10/100], Step [2880/3236], Loss: 1.9605, Perplexity: 7.1027
Epoch [10/100], Step [2890/3236], Loss: 1.9675, Perplexity: 7.1525
Epoch [10/100], Step [2900/3236], Loss: 1.9157, Perplexity: 6.7917
Epoch [10/100], Step [2910/3236], Loss: 1.8644, Perplexity: 6.4523
Epoch [10/100], Step [2920/3236], Loss: 1.8838, Perplexity: 6.5781
Epoch [10/100], Step [2930/3236], Loss: 1.9492, Perplexity: 7.0234
Epoch [10/100], Step [2940/3236], Loss: 1.9636, Perplexity: 7.1250
Epoch [10/100], Step [2950/3236], Loss: 1.8107, Perplexity: 6.1148
Epoch [10/100], Step [2960/3236], Loss: 2.0193, Perplexity: 7.5331
Epoch [10/100], Step [2970/3236], Loss: 2.1099, Perplexity: 8.2474
Epoch [10/100], Step [2980/3236], Loss: 1.7926, Perplexity: 6.0048
Epoch [10/100], Step [2990/3236], Loss: 1.9475, Perplexity: 7.0110
Epoch [10/100], Step [3000/3236], Loss: 1.9575, Perplexity: 7.0816
Epoch [10/100], Step [3010/3236], Loss: 1.9766, Perplexity: 7.2178
Epoch [10/100], Step [3020/3236], Loss: 1.8753, Perplexity: 6.5228
Epoch [10/100], Step [3030/3236], Loss: 1.9263, Perplexity: 6.8638
Epoch [10/100], Step [3040/3236], Loss: 1.8846, Perplexity: 6.5834
Epoch [10/100], Step [3050/3236], Loss: 1.9873, Perplexity: 7.2955
Epoch [10/100], Step [3060/3236], Loss: 2.0432, Perplexity: 7.7152
Epoch [10/100], Step [3070/3236], Loss: 2.0346, Perplexity: 7.6490
Epoch [10/100], Step [3080/3236], Loss: 1.8726, Perplexity: 6.5050
Epoch [10/100], Step [3090/3236], Loss: 1.9796, Perplexity: 7.2395
Epoch [10/100], Step [3100/3236], Loss: 2.0162, Perplexity: 7.5099
Epoch [10/100], Step [3110/3236], Loss: 1.9334, Perplexity: 6.9129
Epoch [10/100], Step [3120/3236], Loss: 1.9553, Perplexity: 7.0658
Epoch [10/100], Step [3130/3236], Loss: 1.9659, Perplexity: 7.1411
Epoch [10/100], Step [3140/3236], Loss: 1.9499, Perplexity: 7.0277
Epoch [10/100], Step [3150/3236], Loss: 1.9437, Perplexity: 6.9847
Epoch [10/100], Step [3160/3236], Loss: 1.9038, Perplexity: 6.7114
Epoch [10/100], Step [3170/3236], Loss: 1.9532, Perplexity: 7.0511
Epoch [10/100], Step [3180/3236], Loss: 1.9356, Perplexity: 6.9282
Epoch [10/100], Step [3190/3236], Loss: 1.8805, Perplexity: 6.5566
Epoch [10/100], Step [3200/3236], Loss: 1.8813, Perplexity: 6.5618
Epoch [10/100], Step [3210/3236], Loss: 1.8605, Perplexity: 6.4267
Epoch [10/100], Step [3220/3236], Loss: 2.0288, Perplexity: 7.6050
Epoch [10/100], Step [3230/3236], Loss: 1.9600, Perplexity: 7.0993
start evaluate ...
4764 : a motorcycle is parked in a garage with other items
158222 : a kitchen with a sink a refrigerator and a window
22168 : a herd of sheep grazing on a lush green field
301282 : a young boy sitting at a table eating a pizza
56433 : a baby sitting on a chair with a laptop on her lap
21400 : a group of people standing in front of a building
147740 : a man is sitting on a bench with bananas
416220 : a city street with a lot of parked cars
463534 : a man laying on a bed with a cat
528786 : a statue of a man riding a horse
loading annotations into memory...
Done (t=0.81s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1181994.47 tokens per second.
PTBTokenizer tokenized 54174 tokens at 629084.46 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48516, 'guess': [49175, 44175, 39175, 34175], 'testlen': 49175, 'correct': [33346, 16158, 6901, 2996]}
('ratio:', 1.0135831478275)
Bleu_1: 0.678
Bleu_2: 0.498
Bleu_3: 0.352
Bleu_4: 0.249
computing METEOR score...
METEOR: 0.230
computing Rouge score...
ROUGE_L: 0.498
computing CIDEr score...
CIDEr: 0.812
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [27.522 seconds]
SPICE evaluation took: 37.48 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [11/100], Step [10/3236], Loss: 1.8296, Perplexity: 6.2316
Epoch [11/100], Step [20/3236], Loss: 1.8996, Perplexity: 6.6832
Epoch [11/100], Step [30/3236], Loss: 1.9356, Perplexity: 6.9284
Epoch [11/100], Step [40/3236], Loss: 1.9637, Perplexity: 7.1254
Epoch [11/100], Step [50/3236], Loss: 1.8462, Perplexity: 6.3360
Epoch [11/100], Step [60/3236], Loss: 1.8759, Perplexity: 6.5265
Epoch [11/100], Step [70/3236], Loss: 1.8745, Perplexity: 6.5178
Epoch [11/100], Step [80/3236], Loss: 1.7373, Perplexity: 5.6819
Epoch [11/100], Step [90/3236], Loss: 1.9344, Perplexity: 6.9195
Epoch [11/100], Step [100/3236], Loss: 1.7460, Perplexity: 5.7317
Epoch [11/100], Step [110/3236], Loss: 1.7750, Perplexity: 5.9002
Epoch [11/100], Step [120/3236], Loss: 1.8590, Perplexity: 6.4170
Epoch [11/100], Step [130/3236], Loss: 1.7849, Perplexity: 5.9590
Epoch [11/100], Step [140/3236], Loss: 1.9138, Perplexity: 6.7786
Epoch [11/100], Step [150/3236], Loss: 1.8368, Perplexity: 6.2763
Epoch [11/100], Step [160/3236], Loss: 1.7518, Perplexity: 5.7648
Epoch [11/100], Step [170/3236], Loss: 1.9388, Perplexity: 6.9502
Epoch [11/100], Step [180/3236], Loss: 1.7815, Perplexity: 5.9389
Epoch [11/100], Step [190/3236], Loss: 1.9007, Perplexity: 6.6904
Epoch [11/100], Step [200/3236], Loss: 1.7963, Perplexity: 6.0272
Epoch [11/100], Step [210/3236], Loss: 1.7930, Perplexity: 6.0076
Epoch [11/100], Step [220/3236], Loss: 1.8387, Perplexity: 6.2884
Epoch [11/100], Step [230/3236], Loss: 1.8762, Perplexity: 6.5288
Epoch [11/100], Step [240/3236], Loss: 1.7641, Perplexity: 5.8365
Epoch [11/100], Step [250/3236], Loss: 1.8607, Perplexity: 6.4283
Epoch [11/100], Step [260/3236], Loss: 1.8140, Perplexity: 6.1346
Epoch [11/100], Step [270/3236], Loss: 1.9918, Perplexity: 7.3284
Epoch [11/100], Step [280/3236], Loss: 1.9628, Perplexity: 7.1191
Epoch [11/100], Step [290/3236], Loss: 1.7828, Perplexity: 5.9466
Epoch [11/100], Step [300/3236], Loss: 1.8011, Perplexity: 6.0563
Epoch [11/100], Step [310/3236], Loss: 1.8534, Perplexity: 6.3815
Epoch [11/100], Step [320/3236], Loss: 1.9256, Perplexity: 6.8591
Epoch [11/100], Step [330/3236], Loss: 1.8926, Perplexity: 6.6368
Epoch [11/100], Step [340/3236], Loss: 1.8588, Perplexity: 6.4163
Epoch [11/100], Step [350/3236], Loss: 1.8435, Perplexity: 6.3188
Epoch [11/100], Step [360/3236], Loss: 1.7934, Perplexity: 6.0097
Epoch [11/100], Step [370/3236], Loss: 1.9272, Perplexity: 6.8705
Epoch [11/100], Step [380/3236], Loss: 1.7438, Perplexity: 5.7189
Epoch [11/100], Step [390/3236], Loss: 1.9204, Perplexity: 6.8238
Epoch [11/100], Step [400/3236], Loss: 1.8352, Perplexity: 6.2665
Epoch [11/100], Step [410/3236], Loss: 1.8396, Perplexity: 6.2939
Epoch [11/100], Step [420/3236], Loss: 1.7507, Perplexity: 5.7587
Epoch [11/100], Step [430/3236], Loss: 1.7575, Perplexity: 5.7978
Epoch [11/100], Step [440/3236], Loss: 1.8498, Perplexity: 6.3583
Epoch [11/100], Step [450/3236], Loss: 1.9490, Perplexity: 7.0219
Epoch [11/100], Step [460/3236], Loss: 1.8773, Perplexity: 6.5359
Epoch [11/100], Step [470/3236], Loss: 1.7734, Perplexity: 5.8910
Epoch [11/100], Step [480/3236], Loss: 1.8527, Perplexity: 6.3769
Epoch [11/100], Step [490/3236], Loss: 1.8096, Perplexity: 6.1077
Epoch [11/100], Step [500/3236], Loss: 1.9427, Perplexity: 6.9777
Epoch [11/100], Step [510/3236], Loss: 1.9145, Perplexity: 6.7836
Epoch [11/100], Step [520/3236], Loss: 1.7517, Perplexity: 5.7642
Epoch [11/100], Step [530/3236], Loss: 1.8731, Perplexity: 6.5082
Epoch [11/100], Step [540/3236], Loss: 1.8126, Perplexity: 6.1261
Epoch [11/100], Step [550/3236], Loss: 1.9480, Perplexity: 7.0146
Epoch [11/100], Step [560/3236], Loss: 1.8027, Perplexity: 6.0661
Epoch [11/100], Step [570/3236], Loss: 1.8496, Perplexity: 6.3575
Epoch [11/100], Step [580/3236], Loss: 1.7814, Perplexity: 5.9382
Epoch [11/100], Step [590/3236], Loss: 1.7501, Perplexity: 5.7551
Epoch [11/100], Step [600/3236], Loss: 1.7569, Perplexity: 5.7947
Epoch [11/100], Step [610/3236], Loss: 1.8346, Perplexity: 6.2625
Epoch [11/100], Step [620/3236], Loss: 1.8931, Perplexity: 6.6402
Epoch [11/100], Step [630/3236], Loss: 1.8762, Perplexity: 6.5287
Epoch [11/100], Step [640/3236], Loss: 1.8506, Perplexity: 6.3635
Epoch [11/100], Step [650/3236], Loss: 1.7893, Perplexity: 5.9851
Epoch [11/100], Step [660/3236], Loss: 1.8916, Perplexity: 6.6303
Epoch [11/100], Step [670/3236], Loss: 1.8760, Perplexity: 6.5270
Epoch [11/100], Step [680/3236], Loss: 1.7939, Perplexity: 6.0129
Epoch [11/100], Step [690/3236], Loss: 1.9812, Perplexity: 7.2517
Epoch [11/100], Step [700/3236], Loss: 1.8599, Perplexity: 6.4232
Epoch [11/100], Step [710/3236], Loss: 1.8959, Perplexity: 6.6588
Epoch [11/100], Step [720/3236], Loss: 1.9816, Perplexity: 7.2541
Epoch [11/100], Step [730/3236], Loss: 1.8429, Perplexity: 6.3146
Epoch [11/100], Step [740/3236], Loss: 1.9095, Perplexity: 6.7495
Epoch [11/100], Step [750/3236], Loss: 1.8599, Perplexity: 6.4228
Epoch [11/100], Step [760/3236], Loss: 1.8693, Perplexity: 6.4835
Epoch [11/100], Step [770/3236], Loss: 1.8755, Perplexity: 6.5242
Epoch [11/100], Step [780/3236], Loss: 1.9607, Perplexity: 7.1041
Epoch [11/100], Step [790/3236], Loss: 1.8968, Perplexity: 6.6645
Epoch [11/100], Step [800/3236], Loss: 1.8790, Perplexity: 6.5467
Epoch [11/100], Step [810/3236], Loss: 1.8880, Perplexity: 6.6061
Epoch [11/100], Step [820/3236], Loss: 1.8775, Perplexity: 6.5370
Epoch [11/100], Step [830/3236], Loss: 1.8553, Perplexity: 6.3937
Epoch [11/100], Step [840/3236], Loss: 1.8491, Perplexity: 6.3544
Epoch [11/100], Step [850/3236], Loss: 1.8923, Perplexity: 6.6345
Epoch [11/100], Step [860/3236], Loss: 1.8980, Perplexity: 6.6728
Epoch [11/100], Step [870/3236], Loss: 1.9760, Perplexity: 7.2137
Epoch [11/100], Step [880/3236], Loss: 1.8729, Perplexity: 6.5073
Epoch [11/100], Step [890/3236], Loss: 1.9204, Perplexity: 6.8237
Epoch [11/100], Step [900/3236], Loss: 1.9502, Perplexity: 7.0301
Epoch [11/100], Step [910/3236], Loss: 1.8757, Perplexity: 6.5256
Epoch [11/100], Step [920/3236], Loss: 1.8212, Perplexity: 6.1793
Epoch [11/100], Step [930/3236], Loss: 1.8956, Perplexity: 6.6565
Epoch [11/100], Step [940/3236], Loss: 1.7439, Perplexity: 5.7193
Epoch [11/100], Step [950/3236], Loss: 1.9157, Perplexity: 6.7920
Epoch [11/100], Step [960/3236], Loss: 1.7421, Perplexity: 5.7091
Epoch [11/100], Step [970/3236], Loss: 1.9587, Perplexity: 7.0904
Epoch [11/100], Step [980/3236], Loss: 1.9109, Perplexity: 6.7589
Epoch [11/100], Step [990/3236], Loss: 1.8632, Perplexity: 6.4443
Epoch [11/100], Step [1000/3236], Loss: 1.8088, Perplexity: 6.1032
Epoch [11/100], Step [1010/3236], Loss: 1.9458, Perplexity: 6.9990
Epoch [11/100], Step [1020/3236], Loss: 1.8328, Perplexity: 6.2513
Epoch [11/100], Step [1030/3236], Loss: 1.8174, Perplexity: 6.1558
Epoch [11/100], Step [1040/3236], Loss: 1.7950, Perplexity: 6.0192
Epoch [11/100], Step [1050/3236], Loss: 1.9584, Perplexity: 7.0883
Epoch [11/100], Step [1060/3236], Loss: 1.8564, Perplexity: 6.4005
Epoch [11/100], Step [1070/3236], Loss: 1.8574, Perplexity: 6.4072
Epoch [11/100], Step [1080/3236], Loss: 1.7409, Perplexity: 5.7027
Epoch [11/100], Step [1090/3236], Loss: 1.8137, Perplexity: 6.1329
Epoch [11/100], Step [1100/3236], Loss: 1.9368, Perplexity: 6.9364
Epoch [11/100], Step [1110/3236], Loss: 1.8856, Perplexity: 6.5901
Epoch [11/100], Step [1120/3236], Loss: 1.8755, Perplexity: 6.5241
Epoch [11/100], Step [1130/3236], Loss: 1.9570, Perplexity: 7.0779
Epoch [11/100], Step [1140/3236], Loss: 1.8571, Perplexity: 6.4052
Epoch [11/100], Step [1150/3236], Loss: 1.8221, Perplexity: 6.1848
Epoch [11/100], Step [1160/3236], Loss: 1.9008, Perplexity: 6.6914
Epoch [11/100], Step [1170/3236], Loss: 1.8788, Perplexity: 6.5458
Epoch [11/100], Step [1180/3236], Loss: 1.9484, Perplexity: 7.0178
Epoch [11/100], Step [1190/3236], Loss: 1.9405, Perplexity: 6.9619
Epoch [11/100], Step [1200/3236], Loss: 1.8521, Perplexity: 6.3734
Epoch [11/100], Step [1210/3236], Loss: 1.8541, Perplexity: 6.3860
Epoch [11/100], Step [1220/3236], Loss: 1.8179, Perplexity: 6.1590
Epoch [11/100], Step [1230/3236], Loss: 1.8932, Perplexity: 6.6403
Epoch [11/100], Step [1240/3236], Loss: 1.9513, Perplexity: 7.0376
Epoch [11/100], Step [1250/3236], Loss: 1.9073, Perplexity: 6.7347
Epoch [11/100], Step [1260/3236], Loss: 1.8718, Perplexity: 6.5002
Epoch [11/100], Step [1270/3236], Loss: 1.8455, Perplexity: 6.3310
Epoch [11/100], Step [1280/3236], Loss: 1.8771, Perplexity: 6.5345
Epoch [11/100], Step [1290/3236], Loss: 1.8580, Perplexity: 6.4106
Epoch [11/100], Step [1300/3236], Loss: 1.8906, Perplexity: 6.6232
Epoch [11/100], Step [1310/3236], Loss: 1.9578, Perplexity: 7.0840
Epoch [11/100], Step [1320/3236], Loss: 1.9415, Perplexity: 6.9689
Epoch [11/100], Step [1330/3236], Loss: 1.9671, Perplexity: 7.1500
Epoch [11/100], Step [1340/3236], Loss: 1.9331, Perplexity: 6.9107
Epoch [11/100], Step [1350/3236], Loss: 1.8787, Perplexity: 6.5449
Epoch [11/100], Step [1360/3236], Loss: 1.8936, Perplexity: 6.6430
Epoch [11/100], Step [1370/3236], Loss: 1.9695, Perplexity: 7.1674
Epoch [11/100], Step [1380/3236], Loss: 1.9031, Perplexity: 6.7067
Epoch [11/100], Step [1390/3236], Loss: 1.8198, Perplexity: 6.1704
Epoch [11/100], Step [1400/3236], Loss: 1.9298, Perplexity: 6.8883
Epoch [11/100], Step [1410/3236], Loss: 1.9229, Perplexity: 6.8409
Epoch [11/100], Step [1420/3236], Loss: 1.8572, Perplexity: 6.4059
Epoch [11/100], Step [1430/3236], Loss: 1.8474, Perplexity: 6.3433
Epoch [11/100], Step [1440/3236], Loss: 1.9084, Perplexity: 6.7425
Epoch [11/100], Step [1450/3236], Loss: 1.9671, Perplexity: 7.1502
Epoch [11/100], Step [1460/3236], Loss: 1.9385, Perplexity: 6.9484
Epoch [11/100], Step [1470/3236], Loss: 1.9185, Perplexity: 6.8106
Epoch [11/100], Step [1480/3236], Loss: 1.8417, Perplexity: 6.3074
Epoch [11/100], Step [1490/3236], Loss: 1.9277, Perplexity: 6.8736
Epoch [11/100], Step [1500/3236], Loss: 1.9410, Perplexity: 6.9658
Epoch [11/100], Step [1510/3236], Loss: 1.8869, Perplexity: 6.5989
Epoch [11/100], Step [1520/3236], Loss: 1.8908, Perplexity: 6.6245
Epoch [11/100], Step [1530/3236], Loss: 1.8621, Perplexity: 6.4376
Epoch [11/100], Step [1540/3236], Loss: 1.8188, Perplexity: 6.1642
Epoch [11/100], Step [1550/3236], Loss: 1.9841, Perplexity: 7.2726
Epoch [11/100], Step [1560/3236], Loss: 1.8237, Perplexity: 6.1945
Epoch [11/100], Step [1570/3236], Loss: 1.9482, Perplexity: 7.0158
Epoch [11/100], Step [1580/3236], Loss: 1.8844, Perplexity: 6.5826
Epoch [11/100], Step [1590/3236], Loss: 1.8305, Perplexity: 6.2369
Epoch [11/100], Step [1600/3236], Loss: 1.9732, Perplexity: 7.1937
Epoch [11/100], Step [1610/3236], Loss: 1.9105, Perplexity: 6.7562
Epoch [11/100], Step [1620/3236], Loss: 2.0299, Perplexity: 7.6131
Epoch [11/100], Step [1630/3236], Loss: 1.8719, Perplexity: 6.5008
Epoch [11/100], Step [1640/3236], Loss: 1.8472, Perplexity: 6.3421
Epoch [11/100], Step [1650/3236], Loss: 1.8011, Perplexity: 6.0565
Epoch [11/100], Step [1660/3236], Loss: 1.8665, Perplexity: 6.4656
Epoch [11/100], Step [1670/3236], Loss: 1.9640, Perplexity: 7.1275
Epoch [11/100], Step [1680/3236], Loss: 1.8226, Perplexity: 6.1881
Epoch [11/100], Step [1690/3236], Loss: 1.8142, Perplexity: 6.1359
Epoch [11/100], Step [1700/3236], Loss: 1.8855, Perplexity: 6.5898
Epoch [11/100], Step [1710/3236], Loss: 1.8552, Perplexity: 6.3928
Epoch [11/100], Step [1720/3236], Loss: 1.7867, Perplexity: 5.9695
Epoch [11/100], Step [1730/3236], Loss: 1.9416, Perplexity: 6.9698
Epoch [11/100], Step [1740/3236], Loss: 1.8182, Perplexity: 6.1605
Epoch [11/100], Step [1750/3236], Loss: 1.8969, Perplexity: 6.6653
Epoch [11/100], Step [1760/3236], Loss: 1.8504, Perplexity: 6.3623
Epoch [11/100], Step [1770/3236], Loss: 1.9409, Perplexity: 6.9647
Epoch [11/100], Step [1780/3236], Loss: 1.9208, Perplexity: 6.8264
Epoch [11/100], Step [1790/3236], Loss: 1.8729, Perplexity: 6.5069
Epoch [11/100], Step [1800/3236], Loss: 2.0296, Perplexity: 7.6113
Epoch [11/100], Step [1810/3236], Loss: 1.7970, Perplexity: 6.0315
Epoch [11/100], Step [1820/3236], Loss: 1.9642, Perplexity: 7.1293
Epoch [11/100], Step [1830/3236], Loss: 1.9074, Perplexity: 6.7358
Epoch [11/100], Step [1840/3236], Loss: 1.9546, Perplexity: 7.0611
Epoch [11/100], Step [1850/3236], Loss: 1.9815, Perplexity: 7.2534
Epoch [11/100], Step [1860/3236], Loss: 1.9431, Perplexity: 6.9805
Epoch [11/100], Step [1870/3236], Loss: 1.8300, Perplexity: 6.2338
Epoch [11/100], Step [1880/3236], Loss: 1.9987, Perplexity: 7.3792
Epoch [11/100], Step [1890/3236], Loss: 1.8953, Perplexity: 6.6548
Epoch [11/100], Step [1900/3236], Loss: 1.8690, Perplexity: 6.4821
Epoch [11/100], Step [1910/3236], Loss: 1.8064, Perplexity: 6.0886
Epoch [11/100], Step [1920/3236], Loss: 1.8112, Perplexity: 6.1178
Epoch [11/100], Step [1930/3236], Loss: 1.9211, Perplexity: 6.8283
Epoch [11/100], Step [1940/3236], Loss: 1.8131, Perplexity: 6.1293
Epoch [11/100], Step [1950/3236], Loss: 1.8724, Perplexity: 6.5040
Epoch [11/100], Step [1960/3236], Loss: 1.8486, Perplexity: 6.3511
Epoch [11/100], Step [1970/3236], Loss: 1.7876, Perplexity: 5.9749
Epoch [11/100], Step [1980/3236], Loss: 1.8921, Perplexity: 6.6332
Epoch [11/100], Step [1990/3236], Loss: 1.8346, Perplexity: 6.2626
Epoch [11/100], Step [2000/3236], Loss: 1.9911, Perplexity: 7.3234
Epoch [11/100], Step [2010/3236], Loss: 1.8560, Perplexity: 6.3983
Epoch [11/100], Step [2020/3236], Loss: 1.8494, Perplexity: 6.3562
Epoch [11/100], Step [2030/3236], Loss: 1.9668, Perplexity: 7.1476
Epoch [11/100], Step [2040/3236], Loss: 1.9471, Perplexity: 7.0087
Epoch [11/100], Step [2050/3236], Loss: 1.8944, Perplexity: 6.6483
Epoch [11/100], Step [2060/3236], Loss: 1.9537, Perplexity: 7.0546
Epoch [11/100], Step [2070/3236], Loss: 1.9312, Perplexity: 6.8976
Epoch [11/100], Step [2080/3236], Loss: 1.9511, Perplexity: 7.0368
Epoch [11/100], Step [2090/3236], Loss: 1.9006, Perplexity: 6.6901
Epoch [11/100], Step [2100/3236], Loss: 1.7706, Perplexity: 5.8742
Epoch [11/100], Step [2110/3236], Loss: 1.9464, Perplexity: 7.0035
Epoch [11/100], Step [2120/3236], Loss: 1.9459, Perplexity: 6.9998
Epoch [11/100], Step [2130/3236], Loss: 1.8734, Perplexity: 6.5105
Epoch [11/100], Step [2140/3236], Loss: 1.8658, Perplexity: 6.4608
Epoch [11/100], Step [2150/3236], Loss: 1.7955, Perplexity: 6.0222
Epoch [11/100], Step [2160/3236], Loss: 1.9186, Perplexity: 6.8115
Epoch [11/100], Step [2170/3236], Loss: 1.9176, Perplexity: 6.8044
Epoch [11/100], Step [2180/3236], Loss: 2.0007, Perplexity: 7.3939
Epoch [11/100], Step [2190/3236], Loss: 1.9239, Perplexity: 6.8473
Epoch [11/100], Step [2200/3236], Loss: 1.8547, Perplexity: 6.3901
Epoch [11/100], Step [2210/3236], Loss: 1.7721, Perplexity: 5.8834
Epoch [11/100], Step [2220/3236], Loss: 1.9077, Perplexity: 6.7374
Epoch [11/100], Step [2230/3236], Loss: 1.9310, Perplexity: 6.8966
Epoch [11/100], Step [2240/3236], Loss: 1.9207, Perplexity: 6.8256
Epoch [11/100], Step [2250/3236], Loss: 1.8136, Perplexity: 6.1325
Epoch [11/100], Step [2260/3236], Loss: 1.9845, Perplexity: 7.2757
Epoch [11/100], Step [2270/3236], Loss: 1.8234, Perplexity: 6.1927
Epoch [11/100], Step [2280/3236], Loss: 1.8129, Perplexity: 6.1282
Epoch [11/100], Step [2290/3236], Loss: 1.9614, Perplexity: 7.1092
Epoch [11/100], Step [2300/3236], Loss: 1.9893, Perplexity: 7.3101
Epoch [11/100], Step [2310/3236], Loss: 1.8910, Perplexity: 6.6260
Epoch [11/100], Step [2320/3236], Loss: 1.8208, Perplexity: 6.1766
Epoch [11/100], Step [2330/3236], Loss: 1.9647, Perplexity: 7.1326
Epoch [11/100], Step [2340/3236], Loss: 1.9089, Perplexity: 6.7458
Epoch [11/100], Step [2350/3236], Loss: 1.8819, Perplexity: 6.5662
Epoch [11/100], Step [2360/3236], Loss: 2.0538, Perplexity: 7.7973
Epoch [11/100], Step [2370/3236], Loss: 1.8258, Perplexity: 6.2077
Epoch [11/100], Step [2380/3236], Loss: 1.9298, Perplexity: 6.8881
Epoch [11/100], Step [2390/3236], Loss: 1.9114, Perplexity: 6.7627
Epoch [11/100], Step [2400/3236], Loss: 1.9146, Perplexity: 6.7843
Epoch [11/100], Step [2410/3236], Loss: 1.8250, Perplexity: 6.2030
Epoch [11/100], Step [2420/3236], Loss: 1.9517, Perplexity: 7.0405
Epoch [11/100], Step [2430/3236], Loss: 2.0044, Perplexity: 7.4216
Epoch [11/100], Step [2440/3236], Loss: 1.8921, Perplexity: 6.6335
Epoch [11/100], Step [2450/3236], Loss: 1.8414, Perplexity: 6.3054
Epoch [11/100], Step [2460/3236], Loss: 1.9416, Perplexity: 6.9701
Epoch [11/100], Step [2470/3236], Loss: 1.9782, Perplexity: 7.2300
Epoch [11/100], Step [2480/3236], Loss: 1.9067, Perplexity: 6.7307
Epoch [11/100], Step [2490/3236], Loss: 1.9084, Perplexity: 6.7422
Epoch [11/100], Step [2500/3236], Loss: 1.8050, Perplexity: 6.0797
Epoch [11/100], Step [2510/3236], Loss: 1.8126, Perplexity: 6.1261
Epoch [11/100], Step [2520/3236], Loss: 1.9342, Perplexity: 6.9188
Epoch [11/100], Step [2530/3236], Loss: 1.9190, Perplexity: 6.8143
Epoch [11/100], Step [2540/3236], Loss: 1.9070, Perplexity: 6.7330
Epoch [11/100], Step [2550/3236], Loss: 1.8010, Perplexity: 6.0559
Epoch [11/100], Step [2560/3236], Loss: 1.7635, Perplexity: 5.8328
Epoch [11/100], Step [2570/3236], Loss: 1.9417, Perplexity: 6.9709
Epoch [11/100], Step [2580/3236], Loss: 1.8415, Perplexity: 6.3061
Epoch [11/100], Step [2590/3236], Loss: 1.8178, Perplexity: 6.1586
Epoch [11/100], Step [2600/3236], Loss: 1.9232, Perplexity: 6.8431
Epoch [11/100], Step [2610/3236], Loss: 1.8010, Perplexity: 6.0555
Epoch [11/100], Step [2620/3236], Loss: 1.8336, Perplexity: 6.2564
Epoch [11/100], Step [2630/3236], Loss: 1.9141, Perplexity: 6.7805
Epoch [11/100], Step [2640/3236], Loss: 1.8559, Perplexity: 6.3973
Epoch [11/100], Step [2650/3236], Loss: 1.8451, Perplexity: 6.3287
Epoch [11/100], Step [2660/3236], Loss: 1.9092, Perplexity: 6.7475
Epoch [11/100], Step [2670/3236], Loss: 1.9803, Perplexity: 7.2450
Epoch [11/100], Step [2680/3236], Loss: 1.8455, Perplexity: 6.3314
Epoch [11/100], Step [2690/3236], Loss: 1.8720, Perplexity: 6.5015
Epoch [11/100], Step [2700/3236], Loss: 1.7439, Perplexity: 5.7198
Epoch [11/100], Step [2710/3236], Loss: 1.8857, Perplexity: 6.5908
Epoch [11/100], Step [2720/3236], Loss: 1.8952, Perplexity: 6.6539
Epoch [11/100], Step [2730/3236], Loss: 1.9663, Perplexity: 7.1442
Epoch [11/100], Step [2740/3236], Loss: 1.7638, Perplexity: 5.8344
Epoch [11/100], Step [2750/3236], Loss: 1.8718, Perplexity: 6.4999
Epoch [11/100], Step [2760/3236], Loss: 1.9569, Perplexity: 7.0772
Epoch [11/100], Step [2770/3236], Loss: 1.7796, Perplexity: 5.9272
Epoch [11/100], Step [2780/3236], Loss: 1.7967, Perplexity: 6.0297
Epoch [11/100], Step [2790/3236], Loss: 1.8978, Perplexity: 6.6709
Epoch [11/100], Step [2800/3236], Loss: 1.9334, Perplexity: 6.9131
Epoch [11/100], Step [2810/3236], Loss: 1.8840, Perplexity: 6.5799
Epoch [11/100], Step [2820/3236], Loss: 2.0714, Perplexity: 7.9358
Epoch [11/100], Step [2830/3236], Loss: 1.9696, Perplexity: 7.1680
Epoch [11/100], Step [2840/3236], Loss: 1.9805, Perplexity: 7.2461
Epoch [11/100], Step [2850/3236], Loss: 1.9894, Perplexity: 7.3113
Epoch [11/100], Step [2860/3236], Loss: 1.8636, Perplexity: 6.4466
Epoch [11/100], Step [2870/3236], Loss: 1.9223, Perplexity: 6.8365
Epoch [11/100], Step [2880/3236], Loss: 1.8311, Perplexity: 6.2405
Epoch [11/100], Step [2890/3236], Loss: 1.8994, Perplexity: 6.6820
Epoch [11/100], Step [2900/3236], Loss: 1.9785, Perplexity: 7.2318
Epoch [11/100], Step [2910/3236], Loss: 1.9400, Perplexity: 6.9588
Epoch [11/100], Step [2920/3236], Loss: 1.9562, Perplexity: 7.0721
Epoch [11/100], Step [2930/3236], Loss: 1.8630, Perplexity: 6.4433
Epoch [11/100], Step [2940/3236], Loss: 1.9130, Perplexity: 6.7734
Epoch [11/100], Step [2950/3236], Loss: 1.9555, Perplexity: 7.0674
Epoch [11/100], Step [2960/3236], Loss: 1.9457, Perplexity: 6.9983
Epoch [11/100], Step [2970/3236], Loss: 1.8403, Perplexity: 6.2987
Epoch [11/100], Step [2980/3236], Loss: 1.8825, Perplexity: 6.5701
Epoch [11/100], Step [2990/3236], Loss: 1.8320, Perplexity: 6.2466
Epoch [11/100], Step [3000/3236], Loss: 1.8683, Perplexity: 6.4776
Epoch [11/100], Step [3010/3236], Loss: 1.9009, Perplexity: 6.6919
Epoch [11/100], Step [3020/3236], Loss: 2.0080, Perplexity: 7.4481
Epoch [11/100], Step [3030/3236], Loss: 1.9757, Perplexity: 7.2120
Epoch [11/100], Step [3040/3236], Loss: 1.9157, Perplexity: 6.7915
Epoch [11/100], Step [3050/3236], Loss: 1.8201, Perplexity: 6.1724
Epoch [11/100], Step [3060/3236], Loss: 1.9568, Perplexity: 7.0767
Epoch [11/100], Step [3070/3236], Loss: 1.9425, Perplexity: 6.9760
Epoch [11/100], Step [3080/3236], Loss: 1.9225, Perplexity: 6.8381
Epoch [11/100], Step [3090/3236], Loss: 1.9012, Perplexity: 6.6937
Epoch [11/100], Step [3100/3236], Loss: 1.8634, Perplexity: 6.4458
Epoch [11/100], Step [3110/3236], Loss: 1.8668, Perplexity: 6.4675
Epoch [11/100], Step [3120/3236], Loss: 1.9446, Perplexity: 6.9909
Epoch [11/100], Step [3130/3236], Loss: 1.7745, Perplexity: 5.8972
Epoch [11/100], Step [3140/3236], Loss: 2.0374, Perplexity: 7.6708
Epoch [11/100], Step [3150/3236], Loss: 1.8253, Perplexity: 6.2046
Epoch [11/100], Step [3160/3236], Loss: 1.8771, Perplexity: 6.5348
Epoch [11/100], Step [3170/3236], Loss: 1.8423, Perplexity: 6.3113
Epoch [11/100], Step [3180/3236], Loss: 1.9455, Perplexity: 6.9973
Epoch [11/100], Step [3190/3236], Loss: 1.9868, Perplexity: 7.2923
Epoch [11/100], Step [3200/3236], Loss: 1.8582, Perplexity: 6.4124
Epoch [11/100], Step [3210/3236], Loss: 1.8771, Perplexity: 6.5342
Epoch [11/100], Step [3220/3236], Loss: 2.0113, Perplexity: 7.4727
Epoch [11/100], Step [3230/3236], Loss: 1.8120, Perplexity: 6.1228
start evaluate ...
522235 : a man sitting in a chair with a laptop and a cat
187822 : a group of people standing around a parking lot
581157 : a cat is laying down in a sink
291619 : a man and a woman playing a game of frisbee
480076 : a suitcase is sitting on the floor in front of a couch
328818 : a man is sitting on a bench with a dog
60596 : a man laying in bed with his head on a pillow
573105 : a red car with a red seat on top of it
305545 : a man in a hat and sunglasses holding a surfboard
362138 : a white and orange cat is eating a piece of broccoli
loading annotations into memory...
Done (t=0.74s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1563890.00 tokens per second.
PTBTokenizer tokenized 54505 tokens at 606892.10 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48763, 'guess': [49506, 44506, 39506, 34506], 'testlen': 49506, 'correct': [33504, 16258, 6986, 3037]}
('ratio:', 1.015236962451018)
Bleu_1: 0.677
Bleu_2: 0.497
Bleu_3: 0.352
Bleu_4: 0.249
computing METEOR score...
METEOR: 0.231
computing Rouge score...
ROUGE_L: 0.497
computing CIDEr score...
CIDEr: 0.811
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [25.440 seconds]
SPICE evaluation took: 36.80 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
Epoch [12/100], Step [10/3236], Loss: 1.8755, Perplexity: 6.5238
Epoch [12/100], Step [20/3236], Loss: 1.8562, Perplexity: 6.3997
Epoch [12/100], Step [30/3236], Loss: 1.7911, Perplexity: 5.9961
Epoch [12/100], Step [40/3236], Loss: 1.7875, Perplexity: 5.9746
Epoch [12/100], Step [50/3236], Loss: 1.9110, Perplexity: 6.7600
Epoch [12/100], Step [60/3236], Loss: 1.7846, Perplexity: 5.9571
Epoch [12/100], Step [70/3236], Loss: 1.8270, Perplexity: 6.2150
Epoch [12/100], Step [80/3236], Loss: 1.7922, Perplexity: 6.0024
Epoch [12/100], Step [90/3236], Loss: 1.7804, Perplexity: 5.9320
Epoch [12/100], Step [100/3236], Loss: 1.8308, Perplexity: 6.2388
Epoch [12/100], Step [110/3236], Loss: 1.8875, Perplexity: 6.6031
Epoch [12/100], Step [120/3236], Loss: 1.7433, Perplexity: 5.7163
Epoch [12/100], Step [130/3236], Loss: 1.8995, Perplexity: 6.6827
Epoch [12/100], Step [140/3236], Loss: 1.7826, Perplexity: 5.9455
Epoch [12/100], Step [150/3236], Loss: 1.8390, Perplexity: 6.2902
Epoch [12/100], Step [160/3236], Loss: 1.8963, Perplexity: 6.6611
Epoch [12/100], Step [170/3236], Loss: 1.7977, Perplexity: 6.0358
Epoch [12/100], Step [180/3236], Loss: 1.8508, Perplexity: 6.3652
Epoch [12/100], Step [190/3236], Loss: 1.8840, Perplexity: 6.5797
Epoch [12/100], Step [200/3236], Loss: 1.8146, Perplexity: 6.1384
Epoch [12/100], Step [210/3236], Loss: 1.7494, Perplexity: 5.7509
Epoch [12/100], Step [220/3236], Loss: 1.8394, Perplexity: 6.2931
Epoch [12/100], Step [230/3236], Loss: 1.8752, Perplexity: 6.5222
Epoch [12/100], Step [240/3236], Loss: 1.7046, Perplexity: 5.4991
Epoch [12/100], Step [250/3236], Loss: 1.8112, Perplexity: 6.1178
Epoch [12/100], Step [260/3236], Loss: 1.8935, Perplexity: 6.6429
Epoch [12/100], Step [270/3236], Loss: 1.7684, Perplexity: 5.8617
Epoch [12/100], Step [280/3236], Loss: 1.7705, Perplexity: 5.8738
Epoch [12/100], Step [290/3236], Loss: 1.8757, Perplexity: 6.5253
Epoch [12/100], Step [300/3236], Loss: 1.7941, Perplexity: 6.0140
Epoch [12/100], Step [310/3236], Loss: 1.8914, Perplexity: 6.6284
Epoch [12/100], Step [320/3236], Loss: 1.9456, Perplexity: 6.9980
Epoch [12/100], Step [330/3236], Loss: 1.8876, Perplexity: 6.6038
Epoch [12/100], Step [340/3236], Loss: 1.7378, Perplexity: 5.6851
Epoch [12/100], Step [350/3236], Loss: 1.8806, Perplexity: 6.5577
Epoch [12/100], Step [360/3236], Loss: 1.7837, Perplexity: 5.9518
Epoch [12/100], Step [370/3236], Loss: 1.7918, Perplexity: 6.0002
Epoch [12/100], Step [380/3236], Loss: 1.9200, Perplexity: 6.8207
Epoch [12/100], Step [390/3236], Loss: 1.7499, Perplexity: 5.7541
Epoch [12/100], Step [400/3236], Loss: 1.7763, Perplexity: 5.9082
Epoch [12/100], Step [410/3236], Loss: 1.8042, Perplexity: 6.0754
Epoch [12/100], Step [420/3236], Loss: 1.8359, Perplexity: 6.2708
Epoch [12/100], Step [430/3236], Loss: 1.7434, Perplexity: 5.7165
Epoch [12/100], Step [440/3236], Loss: 1.8688, Perplexity: 6.4808
Epoch [12/100], Step [450/3236], Loss: 1.8289, Perplexity: 6.2273
Epoch [12/100], Step [460/3236], Loss: 1.8523, Perplexity: 6.3748
Epoch [12/100], Step [470/3236], Loss: 1.8274, Perplexity: 6.2175
Epoch [12/100], Step [480/3236], Loss: 1.8248, Perplexity: 6.2013
Epoch [12/100], Step [490/3236], Loss: 1.8125, Perplexity: 6.1255
Epoch [12/100], Step [500/3236], Loss: 1.8427, Perplexity: 6.3136
Epoch [12/100], Step [510/3236], Loss: 1.8400, Perplexity: 6.2963
Epoch [12/100], Step [520/3236], Loss: 1.8895, Perplexity: 6.6160
Epoch [12/100], Step [530/3236], Loss: 1.8744, Perplexity: 6.5169
Epoch [12/100], Step [540/3236], Loss: 1.7689, Perplexity: 5.8644
Epoch [12/100], Step [550/3236], Loss: 1.9157, Perplexity: 6.7918
Epoch [12/100], Step [560/3236], Loss: 1.8408, Perplexity: 6.3018
Epoch [12/100], Step [570/3236], Loss: 1.8389, Perplexity: 6.2893
Epoch [12/100], Step [580/3236], Loss: 1.8373, Perplexity: 6.2798
Epoch [12/100], Step [590/3236], Loss: 1.7756, Perplexity: 5.9036
Epoch [12/100], Step [600/3236], Loss: 1.8104, Perplexity: 6.1132
Epoch [12/100], Step [610/3236], Loss: 1.8404, Perplexity: 6.2991
Epoch [12/100], Step [620/3236], Loss: 1.8583, Perplexity: 6.4126
Epoch [12/100], Step [630/3236], Loss: 1.8322, Perplexity: 6.2475
Epoch [12/100], Step [640/3236], Loss: 1.8554, Perplexity: 6.3943
Epoch [12/100], Step [650/3236], Loss: 1.9100, Perplexity: 6.7533
Epoch [12/100], Step [660/3236], Loss: 1.8501, Perplexity: 6.3605
Epoch [12/100], Step [670/3236], Loss: 1.9370, Perplexity: 6.9380
Epoch [12/100], Step [680/3236], Loss: 1.7461, Perplexity: 5.7325
Epoch [12/100], Step [690/3236], Loss: 1.8605, Perplexity: 6.4270
Epoch [12/100], Step [700/3236], Loss: 1.7499, Perplexity: 5.7541
Epoch [12/100], Step [710/3236], Loss: 1.9619, Perplexity: 7.1128
Epoch [12/100], Step [720/3236], Loss: 1.8561, Perplexity: 6.3988
Epoch [12/100], Step [730/3236], Loss: 1.8316, Perplexity: 6.2437
Epoch [12/100], Step [740/3236], Loss: 1.8305, Perplexity: 6.2368
Epoch [12/100], Step [750/3236], Loss: 1.9170, Perplexity: 6.8008
Epoch [12/100], Step [760/3236], Loss: 1.8386, Perplexity: 6.2877
Epoch [12/100], Step [770/3236], Loss: 1.8488, Perplexity: 6.3519
Epoch [12/100], Step [780/3236], Loss: 1.8479, Perplexity: 6.3465
Epoch [12/100], Step [790/3236], Loss: 1.9957, Perplexity: 7.3573
Epoch [12/100], Step [800/3236], Loss: 1.8245, Perplexity: 6.1994
Epoch [12/100], Step [810/3236], Loss: 1.7965, Perplexity: 6.0284
Epoch [12/100], Step [820/3236], Loss: 1.9367, Perplexity: 6.9360
Epoch [12/100], Step [830/3236], Loss: 1.9088, Perplexity: 6.7448
Epoch [12/100], Step [840/3236], Loss: 1.8868, Perplexity: 6.5984
Epoch [12/100], Step [850/3236], Loss: 1.8683, Perplexity: 6.4774
Epoch [12/100], Step [860/3236], Loss: 1.8007, Perplexity: 6.0539
Epoch [12/100], Step [870/3236], Loss: 1.9538, Perplexity: 7.0552
Epoch [12/100], Step [880/3236], Loss: 1.8304, Perplexity: 6.2366
Epoch [12/100], Step [890/3236], Loss: 1.8541, Perplexity: 6.3859
Epoch [12/100], Step [900/3236], Loss: 1.9251, Perplexity: 6.8559
Epoch [12/100], Step [910/3236], Loss: 1.7691, Perplexity: 5.8656
Epoch [12/100], Step [920/3236], Loss: 1.8275, Perplexity: 6.2181
Epoch [12/100], Step [930/3236], Loss: 1.8515, Perplexity: 6.3694
Epoch [12/100], Step [940/3236], Loss: 1.7609, Perplexity: 5.8176
Epoch [12/100], Step [950/3236], Loss: 1.8046, Perplexity: 6.0777
Epoch [12/100], Step [960/3236], Loss: 1.9569, Perplexity: 7.0774
Epoch [12/100], Step [970/3236], Loss: 1.8930, Perplexity: 6.6393
Epoch [12/100], Step [980/3236], Loss: 1.8778, Perplexity: 6.5391
Epoch [12/100], Step [990/3236], Loss: 1.8168, Perplexity: 6.1522
Epoch [12/100], Step [1000/3236], Loss: 1.8141, Perplexity: 6.1358
Epoch [12/100], Step [1010/3236], Loss: 1.7902, Perplexity: 5.9906
Epoch [12/100], Step [1020/3236], Loss: 1.8690, Perplexity: 6.4818
Epoch [12/100], Step [1030/3236], Loss: 1.8666, Perplexity: 6.4664
Epoch [12/100], Step [1040/3236], Loss: 1.8033, Perplexity: 6.0695
Epoch [12/100], Step [1050/3236], Loss: 1.8648, Perplexity: 6.4550
Epoch [12/100], Step [1060/3236], Loss: 1.8000, Perplexity: 6.0496
Epoch [12/100], Step [1070/3236], Loss: 1.7765, Perplexity: 5.9093
Epoch [12/100], Step [1080/3236], Loss: 1.8265, Perplexity: 6.2119
Epoch [12/100], Step [1090/3236], Loss: 1.8205, Perplexity: 6.1747
Epoch [12/100], Step [1100/3236], Loss: 1.8575, Perplexity: 6.4076
Epoch [12/100], Step [1110/3236], Loss: 1.8954, Perplexity: 6.6554
Epoch [12/100], Step [1120/3236], Loss: 1.7160, Perplexity: 5.5623
Epoch [12/100], Step [1130/3236], Loss: 1.7878, Perplexity: 5.9765
Epoch [12/100], Step [1140/3236], Loss: 1.7689, Perplexity: 5.8641
Epoch [12/100], Step [1150/3236], Loss: 1.9053, Perplexity: 6.7215
Epoch [12/100], Step [1160/3236], Loss: 1.9079, Perplexity: 6.7392
Epoch [12/100], Step [1170/3236], Loss: 1.8670, Perplexity: 6.4692
Epoch [12/100], Step [1180/3236], Loss: 1.8407, Perplexity: 6.3007
Epoch [12/100], Step [1190/3236], Loss: 1.9490, Perplexity: 7.0219
Epoch [12/100], Step [1200/3236], Loss: 1.8775, Perplexity: 6.5372
Epoch [12/100], Step [1210/3236], Loss: 1.8210, Perplexity: 6.1783
Epoch [12/100], Step [1220/3236], Loss: 1.9583, Perplexity: 7.0876
Epoch [12/100], Step [1230/3236], Loss: 1.8883, Perplexity: 6.6084
Epoch [12/100], Step [1240/3236], Loss: 1.8872, Perplexity: 6.6009
Epoch [12/100], Step [1250/3236], Loss: 1.9099, Perplexity: 6.7525
Epoch [12/100], Step [1260/3236], Loss: 1.8461, Perplexity: 6.3353
Epoch [12/100], Step [1270/3236], Loss: 1.9140, Perplexity: 6.7804
Epoch [12/100], Step [1280/3236], Loss: 1.8974, Perplexity: 6.6683
Epoch [12/100], Step [1290/3236], Loss: 1.8001, Perplexity: 6.0505
Epoch [12/100], Step [1300/3236], Loss: 1.8339, Perplexity: 6.2580
Epoch [12/100], Step [1310/3236], Loss: 1.7668, Perplexity: 5.8519
Epoch [12/100], Step [1320/3236], Loss: 1.9006, Perplexity: 6.6902
Epoch [12/100], Step [1330/3236], Loss: 1.9127, Perplexity: 6.7712
Epoch [12/100], Step [1340/3236], Loss: 1.8171, Perplexity: 6.1538
Epoch [12/100], Step [1350/3236], Loss: 1.8108, Perplexity: 6.1152
Epoch [12/100], Step [1360/3236], Loss: 1.8465, Perplexity: 6.3376
Epoch [12/100], Step [1370/3236], Loss: 1.7739, Perplexity: 5.8939
Epoch [12/100], Step [1380/3236], Loss: 1.8731, Perplexity: 6.5082
Epoch [12/100], Step [1390/3236], Loss: 1.7165, Perplexity: 5.5649
Epoch [12/100], Step [1400/3236], Loss: 1.9139, Perplexity: 6.7793
Epoch [12/100], Step [1410/3236], Loss: 1.8071, Perplexity: 6.0926
Epoch [12/100], Step [1420/3236], Loss: 1.7969, Perplexity: 6.0308
Epoch [12/100], Step [1430/3236], Loss: 1.8560, Perplexity: 6.3983
Epoch [12/100], Step [1440/3236], Loss: 1.8345, Perplexity: 6.2619
Epoch [12/100], Step [1450/3236], Loss: 1.9232, Perplexity: 6.8429
Epoch [12/100], Step [1460/3236], Loss: 1.8658, Perplexity: 6.4614
Epoch [12/100], Step [1470/3236], Loss: 1.8486, Perplexity: 6.3507
Epoch [12/100], Step [1480/3236], Loss: 1.8184, Perplexity: 6.1617
Epoch [12/100], Step [1490/3236], Loss: 1.8358, Perplexity: 6.2704
Epoch [12/100], Step [1500/3236], Loss: 1.8419, Perplexity: 6.3083
Epoch [12/100], Step [1510/3236], Loss: 1.9278, Perplexity: 6.8745
Epoch [12/100], Step [1520/3236], Loss: 1.9152, Perplexity: 6.7885
Epoch [12/100], Step [1530/3236], Loss: 1.8033, Perplexity: 6.0696
Epoch [12/100], Step [1540/3236], Loss: 1.8759, Perplexity: 6.5266
Epoch [12/100], Step [1550/3236], Loss: 1.9250, Perplexity: 6.8552
Epoch [12/100], Step [1560/3236], Loss: 1.8071, Perplexity: 6.0929
Epoch [12/100], Step [1570/3236], Loss: 1.9099, Perplexity: 6.7526
Epoch [12/100], Step [1580/3236], Loss: 1.8743, Perplexity: 6.5164
Epoch [12/100], Step [1590/3236], Loss: 1.9101, Perplexity: 6.7541
Epoch [12/100], Step [1600/3236], Loss: 1.8795, Perplexity: 6.5504
Epoch [12/100], Step [1610/3236], Loss: 1.7386, Perplexity: 5.6896
Epoch [12/100], Step [1620/3236], Loss: 1.8186, Perplexity: 6.1633
Epoch [12/100], Step [1630/3236], Loss: 1.8391, Perplexity: 6.2910
Epoch [12/100], Step [1640/3236], Loss: 1.8468, Perplexity: 6.3394
Epoch [12/100], Step [1650/3236], Loss: 1.7686, Perplexity: 5.8624
Epoch [12/100], Step [1660/3236], Loss: 1.8180, Perplexity: 6.1596
Epoch [12/100], Step [1670/3236], Loss: 1.9417, Perplexity: 6.9707
Epoch [12/100], Step [1680/3236], Loss: 1.9720, Perplexity: 7.1847
Epoch [12/100], Step [1690/3236], Loss: 1.8641, Perplexity: 6.4501
Epoch [12/100], Step [1700/3236], Loss: 1.8386, Perplexity: 6.2876
Epoch [12/100], Step [1710/3236], Loss: 1.8736, Perplexity: 6.5119
Epoch [12/100], Step [1720/3236], Loss: 1.8715, Perplexity: 6.4983
Epoch [12/100], Step [1730/3236], Loss: 1.8446, Perplexity: 6.3257
Epoch [12/100], Step [1740/3236], Loss: 1.9213, Perplexity: 6.8300
Epoch [12/100], Step [1750/3236], Loss: 1.8396, Perplexity: 6.2942
Epoch [12/100], Step [1760/3236], Loss: 1.8372, Perplexity: 6.2787
Epoch [12/100], Step [1770/3236], Loss: 1.8956, Perplexity: 6.6567
Epoch [12/100], Step [1780/3236], Loss: 1.9039, Perplexity: 6.7118
Epoch [12/100], Step [1790/3236], Loss: 1.8964, Perplexity: 6.6618
Epoch [12/100], Step [1800/3236], Loss: 1.8122, Perplexity: 6.1238
Epoch [12/100], Step [1810/3236], Loss: 1.8694, Perplexity: 6.4846
Epoch [12/100], Step [1820/3236], Loss: 1.9667, Perplexity: 7.1472
Epoch [12/100], Step [1830/3236], Loss: 1.8833, Perplexity: 6.5750
Epoch [12/100], Step [1840/3236], Loss: 1.7592, Perplexity: 5.8079
Epoch [12/100], Step [1850/3236], Loss: 1.8506, Perplexity: 6.3636
Epoch [12/100], Step [1860/3236], Loss: 1.8283, Perplexity: 6.2232
Epoch [12/100], Step [1870/3236], Loss: 1.8895, Perplexity: 6.6158
Epoch [12/100], Step [1880/3236], Loss: 1.8916, Perplexity: 6.6301
Epoch [12/100], Step [1890/3236], Loss: 1.8500, Perplexity: 6.3598
Epoch [12/100], Step [1900/3236], Loss: 2.0590, Perplexity: 7.8382
Epoch [12/100], Step [1910/3236], Loss: 1.8908, Perplexity: 6.6250
Epoch [12/100], Step [1920/3236], Loss: 1.9208, Perplexity: 6.8266
Epoch [12/100], Step [1930/3236], Loss: 1.8843, Perplexity: 6.5820
Epoch [12/100], Step [1940/3236], Loss: 1.9167, Perplexity: 6.7982
Epoch [12/100], Step [1950/3236], Loss: 1.8207, Perplexity: 6.1764
Epoch [12/100], Step [1960/3236], Loss: 1.9143, Perplexity: 6.7823
Epoch [12/100], Step [1970/3236], Loss: 1.8872, Perplexity: 6.6006
Epoch [12/100], Step [1980/3236], Loss: 1.8289, Perplexity: 6.2272
Epoch [12/100], Step [1990/3236], Loss: 1.8559, Perplexity: 6.3972
Epoch [12/100], Step [2000/3236], Loss: 1.9295, Perplexity: 6.8859
Epoch [12/100], Step [2010/3236], Loss: 1.8000, Perplexity: 6.0497
Epoch [12/100], Step [2020/3236], Loss: 1.9015, Perplexity: 6.6959
Epoch [12/100], Step [2030/3236], Loss: 1.8445, Perplexity: 6.3249
Epoch [12/100], Step [2040/3236], Loss: 1.8979, Perplexity: 6.6720
Epoch [12/100], Step [2050/3236], Loss: 1.8149, Perplexity: 6.1407
Epoch [12/100], Step [2060/3236], Loss: 1.8623, Perplexity: 6.4387
Epoch [12/100], Step [2070/3236], Loss: 1.7245, Perplexity: 5.6096
Epoch [12/100], Step [2080/3236], Loss: 1.8181, Perplexity: 6.1601
Epoch [12/100], Step [2090/3236], Loss: 1.8822, Perplexity: 6.5680
Epoch [12/100], Step [2100/3236], Loss: 1.8773, Perplexity: 6.5356
Epoch [12/100], Step [2110/3236], Loss: 1.8932, Perplexity: 6.6403
Epoch [12/100], Step [2120/3236], Loss: 1.7651, Perplexity: 5.8422
Epoch [12/100], Step [2130/3236], Loss: 1.8706, Perplexity: 6.4920
Epoch [12/100], Step [2140/3236], Loss: 1.8479, Perplexity: 6.3464
Epoch [12/100], Step [2150/3236], Loss: 1.8361, Perplexity: 6.2720
Epoch [12/100], Step [2160/3236], Loss: 1.8041, Perplexity: 6.0747
Epoch [12/100], Step [2170/3236], Loss: 1.7927, Perplexity: 6.0056
Epoch [12/100], Step [2180/3236], Loss: 1.8158, Perplexity: 6.1458
Epoch [12/100], Step [2190/3236], Loss: 1.7748, Perplexity: 5.8993
Epoch [12/100], Step [2200/3236], Loss: 1.9916, Perplexity: 7.3271
Epoch [12/100], Step [2210/3236], Loss: 1.8491, Perplexity: 6.3539
Epoch [12/100], Step [2220/3236], Loss: 1.9100, Perplexity: 6.7528
Epoch [12/100], Step [2230/3236], Loss: 1.8123, Perplexity: 6.1242
Epoch [12/100], Step [2240/3236], Loss: 1.8714, Perplexity: 6.4972
Epoch [12/100], Step [2250/3236], Loss: 1.8151, Perplexity: 6.1414
Epoch [12/100], Step [2260/3236], Loss: 1.8346, Perplexity: 6.2624
Epoch [12/100], Step [2270/3236], Loss: 1.7861, Perplexity: 5.9661
Epoch [12/100], Step [2280/3236], Loss: 1.8997, Perplexity: 6.6842
Epoch [12/100], Step [2290/3236], Loss: 1.9421, Perplexity: 6.9737
Epoch [12/100], Step [2300/3236], Loss: 1.8414, Perplexity: 6.3054
Epoch [12/100], Step [2310/3236], Loss: 1.8934, Perplexity: 6.6417
Epoch [12/100], Step [2320/3236], Loss: 1.8144, Perplexity: 6.1375
Epoch [12/100], Step [2330/3236], Loss: 1.9074, Perplexity: 6.7357
Epoch [12/100], Step [2340/3236], Loss: 1.7578, Perplexity: 5.7996
Epoch [12/100], Step [2350/3236], Loss: 1.9133, Perplexity: 6.7754
Epoch [12/100], Step [2360/3236], Loss: 1.7793, Perplexity: 5.9255
Epoch [12/100], Step [2370/3236], Loss: 1.9654, Perplexity: 7.1379
Epoch [12/100], Step [2380/3236], Loss: 1.7681, Perplexity: 5.8598
Epoch [12/100], Step [2390/3236], Loss: 1.9083, Perplexity: 6.7418
Epoch [12/100], Step [2400/3236], Loss: 1.8272, Perplexity: 6.2163
Epoch [12/100], Step [2410/3236], Loss: 1.8763, Perplexity: 6.5290
Epoch [12/100], Step [2420/3236], Loss: 1.8325, Perplexity: 6.2496
Epoch [12/100], Step [2430/3236], Loss: 1.8194, Perplexity: 6.1682
Epoch [12/100], Step [2440/3236], Loss: 1.9950, Perplexity: 7.3525
Epoch [12/100], Step [2450/3236], Loss: 1.9109, Perplexity: 6.7592
Epoch [12/100], Step [2460/3236], Loss: 1.8571, Perplexity: 6.4051
Epoch [12/100], Step [2470/3236], Loss: 1.9084, Perplexity: 6.7421
Epoch [12/100], Step [2480/3236], Loss: 1.9764, Perplexity: 7.2168
Epoch [12/100], Step [2490/3236], Loss: 1.8563, Perplexity: 6.3999
Epoch [12/100], Step [2500/3236], Loss: 1.8017, Perplexity: 6.0602
Epoch [12/100], Step [2510/3236], Loss: 1.8683, Perplexity: 6.4775
Epoch [12/100], Step [2520/3236], Loss: 1.7896, Perplexity: 5.9869
Epoch [12/100], Step [2530/3236], Loss: 1.8533, Perplexity: 6.3807
Epoch [12/100], Step [2540/3236], Loss: 1.8300, Perplexity: 6.2336
Epoch [12/100], Step [2550/3236], Loss: 1.8155, Perplexity: 6.1439
Epoch [12/100], Step [2560/3236], Loss: 1.8503, Perplexity: 6.3619
Epoch [12/100], Step [2570/3236], Loss: 1.9726, Perplexity: 7.1892
Epoch [12/100], Step [2580/3236], Loss: 1.7498, Perplexity: 5.7537
Epoch [12/100], Step [2590/3236], Loss: 1.9225, Perplexity: 6.8379
Epoch [12/100], Step [2600/3236], Loss: 1.8557, Perplexity: 6.3959
Epoch [12/100], Step [2610/3236], Loss: 1.8982, Perplexity: 6.6742
Epoch [12/100], Step [2620/3236], Loss: 1.9497, Perplexity: 7.0262
Epoch [12/100], Step [2630/3236], Loss: 1.7935, Perplexity: 6.0107
Epoch [12/100], Step [2640/3236], Loss: 1.7944, Perplexity: 6.0156
Epoch [12/100], Step [2650/3236], Loss: 1.9089, Perplexity: 6.7454
Epoch [12/100], Step [2660/3236], Loss: 1.8727, Perplexity: 6.5059
Epoch [12/100], Step [2670/3236], Loss: 1.9447, Perplexity: 6.9912
Epoch [12/100], Step [2680/3236], Loss: 1.9247, Perplexity: 6.8533
Epoch [12/100], Step [2690/3236], Loss: 1.7755, Perplexity: 5.9032
Epoch [12/100], Step [2700/3236], Loss: 1.9100, Perplexity: 6.7529
Epoch [12/100], Step [2710/3236], Loss: 1.9156, Perplexity: 6.7910
Epoch [12/100], Step [2720/3236], Loss: 1.7516, Perplexity: 5.7640
Epoch [12/100], Step [2730/3236], Loss: 1.8675, Perplexity: 6.4720
Epoch [12/100], Step [2740/3236], Loss: 1.8889, Perplexity: 6.6122
Epoch [12/100], Step [2750/3236], Loss: 1.9333, Perplexity: 6.9124
Epoch [12/100], Step [2760/3236], Loss: 1.8902, Perplexity: 6.6205
Epoch [12/100], Step [2770/3236], Loss: 1.9250, Perplexity: 6.8549
Epoch [12/100], Step [2780/3236], Loss: 1.8849, Perplexity: 6.5858
Epoch [12/100], Step [2790/3236], Loss: 1.8279, Perplexity: 6.2210
Epoch [12/100], Step [2800/3236], Loss: 1.8859, Perplexity: 6.5923
Epoch [12/100], Step [2810/3236], Loss: 1.7853, Perplexity: 5.9615
Epoch [12/100], Step [2820/3236], Loss: 1.8117, Perplexity: 6.1210
Epoch [12/100], Step [2830/3236], Loss: 1.8336, Perplexity: 6.2561
Epoch [12/100], Step [2840/3236], Loss: 1.8227, Perplexity: 6.1883
Epoch [12/100], Step [2850/3236], Loss: 1.9565, Perplexity: 7.0744
Epoch [12/100], Step [2860/3236], Loss: 1.8147, Perplexity: 6.1395
Epoch [12/100], Step [2870/3236], Loss: 1.9022, Perplexity: 6.7004
Epoch [12/100], Step [2880/3236], Loss: 1.8324, Perplexity: 6.2486
Epoch [12/100], Step [2890/3236], Loss: 1.9380, Perplexity: 6.9446
Epoch [12/100], Step [2900/3236], Loss: 1.8394, Perplexity: 6.2926
Epoch [12/100], Step [2910/3236], Loss: 1.8896, Perplexity: 6.6168
Epoch [12/100], Step [2920/3236], Loss: 1.8834, Perplexity: 6.5758
Epoch [12/100], Step [2930/3236], Loss: 1.8626, Perplexity: 6.4402
Epoch [12/100], Step [2940/3236], Loss: 1.8414, Perplexity: 6.3057
Epoch [12/100], Step [2950/3236], Loss: 1.8528, Perplexity: 6.3776
Epoch [12/100], Step [2960/3236], Loss: 1.8472, Perplexity: 6.3418
Epoch [12/100], Step [2970/3236], Loss: 1.8120, Perplexity: 6.1229
Epoch [12/100], Step [2980/3236], Loss: 1.9241, Perplexity: 6.8489
Epoch [12/100], Step [2990/3236], Loss: 1.8939, Perplexity: 6.6454
Epoch [12/100], Step [3000/3236], Loss: 1.8869, Perplexity: 6.5990
Epoch [12/100], Step [3010/3236], Loss: 1.9497, Perplexity: 7.0264
Epoch [12/100], Step [3020/3236], Loss: 1.9324, Perplexity: 6.9059
Epoch [12/100], Step [3030/3236], Loss: 1.7879, Perplexity: 5.9771
Epoch [12/100], Step [3040/3236], Loss: 1.8325, Perplexity: 6.2497
Epoch [12/100], Step [3050/3236], Loss: 2.0132, Perplexity: 7.4870
Epoch [12/100], Step [3060/3236], Loss: 1.8883, Perplexity: 6.6082
Epoch [12/100], Step [3070/3236], Loss: 1.9160, Perplexity: 6.7939
Epoch [12/100], Step [3080/3236], Loss: 1.8702, Perplexity: 6.4898
Epoch [12/100], Step [3090/3236], Loss: 1.8741, Perplexity: 6.5150
Epoch [12/100], Step [3100/3236], Loss: 1.8336, Perplexity: 6.2563
Epoch [12/100], Step [3110/3236], Loss: 1.8686, Perplexity: 6.4795
Epoch [12/100], Step [3120/3236], Loss: 1.8250, Perplexity: 6.2028
Epoch [12/100], Step [3130/3236], Loss: 1.8233, Perplexity: 6.1921
Epoch [12/100], Step [3140/3236], Loss: 1.8756, Perplexity: 6.5250
Epoch [12/100], Step [3150/3236], Loss: 1.8261, Perplexity: 6.2097
Epoch [12/100], Step [3160/3236], Loss: 1.8989, Perplexity: 6.6788
Epoch [12/100], Step [3170/3236], Loss: 1.8659, Perplexity: 6.4618
Epoch [12/100], Step [3180/3236], Loss: 1.7798, Perplexity: 5.9287
Epoch [12/100], Step [3190/3236], Loss: 1.9570, Perplexity: 7.0781
Epoch [12/100], Step [3200/3236], Loss: 1.9028, Perplexity: 6.7048
Epoch [12/100], Step [3210/3236], Loss: 1.8484, Perplexity: 6.3499
Epoch [12/100], Step [3220/3236], Loss: 1.8333, Perplexity: 6.2544
Epoch [12/100], Step [3230/3236], Loss: 1.9576, Perplexity: 7.0824
start evaluate ...
533140 : a group of sheep that are standing in the grass
391539 : a white refrigerator freezer sitting next to a counter
64779 : a plate of vegetables and a knife on a table
525439 : a skateboarder is in the air doing a trick
406949 : a street with cars and a traffic light
114389 : a woman standing next to a river with a bridge in the background
398534 : a young boy holding a tennis racquet on a tennis court
12959 : a large clock tower with a massive clock on its face
247576 : a red double decker bus driving down a street
161047 : a kitchen with a stove and a microwave
loading annotations into memory...
Done (t=0.85s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1166516.57 tokens per second.
PTBTokenizer tokenized 54064 tokens at 626133.13 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48422, 'guess': [49065, 44065, 39065, 34065], 'testlen': 49065, 'correct': [33304, 16295, 7102, 3058]}
('ratio:', 1.0132790880178222)
Bleu_1: 0.679
Bleu_2: 0.501
Bleu_3: 0.357
Bleu_4: 0.253
computing METEOR score...
METEOR: 0.230
computing Rouge score...
ROUGE_L: 0.499
computing CIDEr score...
CIDEr: 0.819
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [23.532 seconds]
SPICE evaluation took: 34.38 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
model saved to experiment/gt/withGAN
Epoch [13/100], Step [10/3236], Loss: 1.7746, Perplexity: 5.8982
Epoch [13/100], Step [20/3236], Loss: 1.9228, Perplexity: 6.8401
Epoch [13/100], Step [30/3236], Loss: 1.8468, Perplexity: 6.3392
Epoch [13/100], Step [40/3236], Loss: 1.8959, Perplexity: 6.6588
Epoch [13/100], Step [50/3236], Loss: 1.7441, Perplexity: 5.7208
Epoch [13/100], Step [60/3236], Loss: 1.8820, Perplexity: 6.5666
Epoch [13/100], Step [70/3236], Loss: 1.8343, Perplexity: 6.2605
Epoch [13/100], Step [80/3236], Loss: 1.7257, Perplexity: 5.6166
Epoch [13/100], Step [90/3236], Loss: 1.7890, Perplexity: 5.9835
Epoch [13/100], Step [100/3236], Loss: 1.9544, Perplexity: 7.0596
Epoch [13/100], Step [110/3236], Loss: 1.8014, Perplexity: 6.0580
Epoch [13/100], Step [120/3236], Loss: 1.8479, Perplexity: 6.3463
Epoch [13/100], Step [130/3236], Loss: 1.7607, Perplexity: 5.8164
Epoch [13/100], Step [140/3236], Loss: 1.7873, Perplexity: 5.9736
Epoch [13/100], Step [150/3236], Loss: 1.7056, Perplexity: 5.5049
Epoch [13/100], Step [160/3236], Loss: 1.8645, Perplexity: 6.4525
Epoch [13/100], Step [170/3236], Loss: 1.8475, Perplexity: 6.3442
Epoch [13/100], Step [180/3236], Loss: 1.8584, Perplexity: 6.4137
Epoch [13/100], Step [190/3236], Loss: 1.7342, Perplexity: 5.6643
Epoch [13/100], Step [200/3236], Loss: 1.6520, Perplexity: 5.2173
Epoch [13/100], Step [210/3236], Loss: 1.7404, Perplexity: 5.6997
Epoch [13/100], Step [220/3236], Loss: 1.9055, Perplexity: 6.7229
Epoch [13/100], Step [230/3236], Loss: 1.8502, Perplexity: 6.3613
Epoch [13/100], Step [240/3236], Loss: 1.8607, Perplexity: 6.4280
Epoch [13/100], Step [250/3236], Loss: 1.8337, Perplexity: 6.2568
Epoch [13/100], Step [260/3236], Loss: 1.9161, Perplexity: 6.7941
Epoch [13/100], Step [270/3236], Loss: 1.7752, Perplexity: 5.9016
Epoch [13/100], Step [280/3236], Loss: 1.8533, Perplexity: 6.3811
Epoch [13/100], Step [290/3236], Loss: 1.8632, Perplexity: 6.4444
Epoch [13/100], Step [300/3236], Loss: 1.8503, Perplexity: 6.3618
Epoch [13/100], Step [310/3236], Loss: 1.9153, Perplexity: 6.7888
Epoch [13/100], Step [320/3236], Loss: 1.7852, Perplexity: 5.9607
Epoch [13/100], Step [330/3236], Loss: 1.7486, Perplexity: 5.7465
Epoch [13/100], Step [340/3236], Loss: 1.7836, Perplexity: 5.9511
Epoch [13/100], Step [350/3236], Loss: 1.8147, Perplexity: 6.1393
Epoch [13/100], Step [360/3236], Loss: 1.8183, Perplexity: 6.1615
Epoch [13/100], Step [370/3236], Loss: 1.8414, Perplexity: 6.3053
Epoch [13/100], Step [380/3236], Loss: 1.8555, Perplexity: 6.3950
Epoch [13/100], Step [390/3236], Loss: 1.8066, Perplexity: 6.0899
Epoch [13/100], Step [400/3236], Loss: 1.7969, Perplexity: 6.0308
Epoch [13/100], Step [410/3236], Loss: 1.8140, Perplexity: 6.1348
Epoch [13/100], Step [420/3236], Loss: 1.8156, Perplexity: 6.1445
Epoch [13/100], Step [430/3236], Loss: 1.8883, Perplexity: 6.6084
Epoch [13/100], Step [440/3236], Loss: 1.8845, Perplexity: 6.5829
Epoch [13/100], Step [450/3236], Loss: 1.7821, Perplexity: 5.9422
Epoch [13/100], Step [460/3236], Loss: 1.7102, Perplexity: 5.5300
Epoch [13/100], Step [470/3236], Loss: 1.7855, Perplexity: 5.9625
Epoch [13/100], Step [480/3236], Loss: 1.6929, Perplexity: 5.4354
Epoch [13/100], Step [490/3236], Loss: 1.8672, Perplexity: 6.4704
Epoch [13/100], Step [500/3236], Loss: 1.7182, Perplexity: 5.5742
Epoch [13/100], Step [510/3236], Loss: 1.6853, Perplexity: 5.3942
Epoch [13/100], Step [520/3236], Loss: 1.7887, Perplexity: 5.9818
Epoch [13/100], Step [530/3236], Loss: 1.8785, Perplexity: 6.5434
Epoch [13/100], Step [540/3236], Loss: 1.8123, Perplexity: 6.1244
Epoch [13/100], Step [550/3236], Loss: 1.8694, Perplexity: 6.4844
Epoch [13/100], Step [560/3236], Loss: 1.8758, Perplexity: 6.5261
Epoch [13/100], Step [570/3236], Loss: 1.8285, Perplexity: 6.2243
Epoch [13/100], Step [580/3236], Loss: 1.7949, Perplexity: 6.0190
Epoch [13/100], Step [590/3236], Loss: 1.8766, Perplexity: 6.5311
Epoch [13/100], Step [600/3236], Loss: 1.8159, Perplexity: 6.1464
Epoch [13/100], Step [610/3236], Loss: 1.8395, Perplexity: 6.2934
Epoch [13/100], Step [620/3236], Loss: 1.7896, Perplexity: 5.9873
Epoch [13/100], Step [630/3236], Loss: 1.8509, Perplexity: 6.3655
Epoch [13/100], Step [640/3236], Loss: 1.7998, Perplexity: 6.0486
Epoch [13/100], Step [650/3236], Loss: 1.7752, Perplexity: 5.9015
Epoch [13/100], Step [660/3236], Loss: 1.8471, Perplexity: 6.3414
Epoch [13/100], Step [670/3236], Loss: 1.8393, Perplexity: 6.2923
Epoch [13/100], Step [680/3236], Loss: 1.8531, Perplexity: 6.3795
Epoch [13/100], Step [690/3236], Loss: 1.9083, Perplexity: 6.7418
Epoch [13/100], Step [700/3236], Loss: 1.8559, Perplexity: 6.3976
Epoch [13/100], Step [710/3236], Loss: 1.7705, Perplexity: 5.8741
Epoch [13/100], Step [720/3236], Loss: 1.8575, Perplexity: 6.4076
Epoch [13/100], Step [730/3236], Loss: 1.7731, Perplexity: 5.8891
Epoch [13/100], Step [740/3236], Loss: 1.8683, Perplexity: 6.4774
Epoch [13/100], Step [750/3236], Loss: 1.8240, Perplexity: 6.1965
Epoch [13/100], Step [760/3236], Loss: 1.8976, Perplexity: 6.6696
Epoch [13/100], Step [770/3236], Loss: 1.7480, Perplexity: 5.7429
Epoch [13/100], Step [780/3236], Loss: 1.8096, Perplexity: 6.1078
Epoch [13/100], Step [790/3236], Loss: 1.8118, Perplexity: 6.1213
Epoch [13/100], Step [800/3236], Loss: 1.9192, Perplexity: 6.8156
Epoch [13/100], Step [810/3236], Loss: 1.7864, Perplexity: 5.9678
Epoch [13/100], Step [820/3236], Loss: 1.9262, Perplexity: 6.8636
Epoch [13/100], Step [830/3236], Loss: 1.7296, Perplexity: 5.6383
Epoch [13/100], Step [840/3236], Loss: 1.7394, Perplexity: 5.6940
Epoch [13/100], Step [850/3236], Loss: 1.7458, Perplexity: 5.7306
Epoch [13/100], Step [860/3236], Loss: 1.8588, Perplexity: 6.4161
Epoch [13/100], Step [870/3236], Loss: 1.7461, Perplexity: 5.7325
Epoch [13/100], Step [880/3236], Loss: 1.8288, Perplexity: 6.2265
Epoch [13/100], Step [890/3236], Loss: 1.8766, Perplexity: 6.5311
Epoch [13/100], Step [900/3236], Loss: 1.8016, Perplexity: 6.0592
Epoch [13/100], Step [910/3236], Loss: 1.7353, Perplexity: 5.6709
Epoch [13/100], Step [920/3236], Loss: 1.7507, Perplexity: 5.7584
Epoch [13/100], Step [930/3236], Loss: 1.8264, Perplexity: 6.2113
Epoch [13/100], Step [940/3236], Loss: 1.7543, Perplexity: 5.7792
Epoch [13/100], Step [950/3236], Loss: 1.9149, Perplexity: 6.7861
Epoch [13/100], Step [960/3236], Loss: 1.9734, Perplexity: 7.1952
Epoch [13/100], Step [970/3236], Loss: 1.8107, Perplexity: 6.1149
Epoch [13/100], Step [980/3236], Loss: 1.7853, Perplexity: 5.9616
Epoch [13/100], Step [990/3236], Loss: 1.8385, Perplexity: 6.2870
Epoch [13/100], Step [1000/3236], Loss: 1.8960, Perplexity: 6.6594
Epoch [13/100], Step [1010/3236], Loss: 1.8883, Perplexity: 6.6083
Epoch [13/100], Step [1020/3236], Loss: 1.7425, Perplexity: 5.7115
Epoch [13/100], Step [1030/3236], Loss: 1.9405, Perplexity: 6.9623
Epoch [13/100], Step [1040/3236], Loss: 1.8236, Perplexity: 6.1943
Epoch [13/100], Step [1050/3236], Loss: 1.8324, Perplexity: 6.2490
Epoch [13/100], Step [1060/3236], Loss: 1.7586, Perplexity: 5.8043
Epoch [13/100], Step [1070/3236], Loss: 1.9324, Perplexity: 6.9061
Epoch [13/100], Step [1080/3236], Loss: 1.8081, Perplexity: 6.0987
Epoch [13/100], Step [1090/3236], Loss: 1.8008, Perplexity: 6.0548
Epoch [13/100], Step [1100/3236], Loss: 1.8488, Perplexity: 6.3524
Epoch [13/100], Step [1110/3236], Loss: 1.9061, Perplexity: 6.7269
Epoch [13/100], Step [1120/3236], Loss: 1.8964, Perplexity: 6.6617
Epoch [13/100], Step [1130/3236], Loss: 1.7715, Perplexity: 5.8795
Epoch [13/100], Step [1140/3236], Loss: 1.8841, Perplexity: 6.5806
Epoch [13/100], Step [1150/3236], Loss: 1.7944, Perplexity: 6.0161
Epoch [13/100], Step [1160/3236], Loss: 1.8599, Perplexity: 6.4231
Epoch [13/100], Step [1170/3236], Loss: 1.8044, Perplexity: 6.0763
Epoch [13/100], Step [1180/3236], Loss: 1.8515, Perplexity: 6.3693
Epoch [13/100], Step [1190/3236], Loss: 1.7517, Perplexity: 5.7643
Epoch [13/100], Step [1200/3236], Loss: 1.9501, Perplexity: 7.0295
Epoch [13/100], Step [1210/3236], Loss: 1.7086, Perplexity: 5.5214
Epoch [13/100], Step [1220/3236], Loss: 1.8749, Perplexity: 6.5201
Epoch [13/100], Step [1230/3236], Loss: 1.6903, Perplexity: 5.4208
Epoch [13/100], Step [1240/3236], Loss: 1.7951, Perplexity: 6.0200
Epoch [13/100], Step [1250/3236], Loss: 1.8722, Perplexity: 6.5023
Epoch [13/100], Step [1260/3236], Loss: 1.7808, Perplexity: 5.9343
Epoch [13/100], Step [1270/3236], Loss: 1.8837, Perplexity: 6.5776
Epoch [13/100], Step [1280/3236], Loss: 1.7600, Perplexity: 5.8125
Epoch [13/100], Step [1290/3236], Loss: 1.7855, Perplexity: 5.9624
Epoch [13/100], Step [1300/3236], Loss: 1.8158, Perplexity: 6.1459
Epoch [13/100], Step [1310/3236], Loss: 1.8331, Perplexity: 6.2534
Epoch [13/100], Step [1320/3236], Loss: 1.7912, Perplexity: 5.9969
Epoch [13/100], Step [1330/3236], Loss: 1.8725, Perplexity: 6.5045
Epoch [13/100], Step [1340/3236], Loss: 1.8449, Perplexity: 6.3273
Epoch [13/100], Step [1350/3236], Loss: 1.7267, Perplexity: 5.6220
Epoch [13/100], Step [1360/3236], Loss: 1.8917, Perplexity: 6.6305
Epoch [13/100], Step [1370/3236], Loss: 1.8110, Perplexity: 6.1165
Epoch [13/100], Step [1380/3236], Loss: 1.8557, Perplexity: 6.3960
Epoch [13/100], Step [1390/3236], Loss: 1.7727, Perplexity: 5.8867
Epoch [13/100], Step [1400/3236], Loss: 1.8089, Perplexity: 6.1036
Epoch [13/100], Step [1410/3236], Loss: 1.6677, Perplexity: 5.3002
Epoch [13/100], Step [1420/3236], Loss: 1.7409, Perplexity: 5.7026
Epoch [13/100], Step [1430/3236], Loss: 1.7703, Perplexity: 5.8727
Epoch [13/100], Step [1440/3236], Loss: 1.7433, Perplexity: 5.7164
Epoch [13/100], Step [1450/3236], Loss: 1.7366, Perplexity: 5.6779
Epoch [13/100], Step [1460/3236], Loss: 1.8053, Perplexity: 6.0816
Epoch [13/100], Step [1470/3236], Loss: 1.7691, Perplexity: 5.8658
Epoch [13/100], Step [1480/3236], Loss: 1.8254, Perplexity: 6.2051
Epoch [13/100], Step [1490/3236], Loss: 1.9229, Perplexity: 6.8410
Epoch [13/100], Step [1500/3236], Loss: 1.8175, Perplexity: 6.1564
Epoch [13/100], Step [1510/3236], Loss: 1.7757, Perplexity: 5.9043
Epoch [13/100], Step [1520/3236], Loss: 1.9033, Perplexity: 6.7082
Epoch [13/100], Step [1530/3236], Loss: 1.8356, Perplexity: 6.2688
Epoch [13/100], Step [1540/3236], Loss: 1.8867, Perplexity: 6.5978
Epoch [13/100], Step [1550/3236], Loss: 1.8814, Perplexity: 6.5624
Epoch [13/100], Step [1560/3236], Loss: 1.7818, Perplexity: 5.9407
Epoch [13/100], Step [1570/3236], Loss: 1.8063, Perplexity: 6.0882
Epoch [13/100], Step [1580/3236], Loss: 1.7848, Perplexity: 5.9583
Epoch [13/100], Step [1590/3236], Loss: 1.8589, Perplexity: 6.4170
Epoch [13/100], Step [1600/3236], Loss: 1.8320, Perplexity: 6.2466
Epoch [13/100], Step [1610/3236], Loss: 1.8185, Perplexity: 6.1628
Epoch [13/100], Step [1620/3236], Loss: 1.9512, Perplexity: 7.0370
Epoch [13/100], Step [1630/3236], Loss: 1.7228, Perplexity: 5.6000
Epoch [13/100], Step [1640/3236], Loss: 1.9720, Perplexity: 7.1849
Epoch [13/100], Step [1650/3236], Loss: 1.7949, Perplexity: 6.0191
Epoch [13/100], Step [1660/3236], Loss: 1.7654, Perplexity: 5.8441
Epoch [13/100], Step [1670/3236], Loss: 1.8600, Perplexity: 6.4235
Epoch [13/100], Step [1680/3236], Loss: 1.9391, Perplexity: 6.9522
Epoch [13/100], Step [1690/3236], Loss: 1.7757, Perplexity: 5.9044
Epoch [13/100], Step [1700/3236], Loss: 1.8637, Perplexity: 6.4474
Epoch [13/100], Step [1710/3236], Loss: 1.8229, Perplexity: 6.1899
Epoch [13/100], Step [1720/3236], Loss: 1.8118, Perplexity: 6.1217
Epoch [13/100], Step [1730/3236], Loss: 1.7482, Perplexity: 5.7444
Epoch [13/100], Step [1740/3236], Loss: 1.8573, Perplexity: 6.4063
Epoch [13/100], Step [1750/3236], Loss: 1.8721, Perplexity: 6.5020
Epoch [13/100], Step [1760/3236], Loss: 1.8022, Perplexity: 6.0632
Epoch [13/100], Step [1770/3236], Loss: 1.6885, Perplexity: 5.4115
Epoch [13/100], Step [1780/3236], Loss: 1.8400, Perplexity: 6.2965
Epoch [13/100], Step [1790/3236], Loss: 1.8624, Perplexity: 6.4393
Epoch [13/100], Step [1800/3236], Loss: 1.9321, Perplexity: 6.9042
Epoch [13/100], Step [1810/3236], Loss: 1.8691, Perplexity: 6.4826
Epoch [13/100], Step [1820/3236], Loss: 1.8284, Perplexity: 6.2242
Epoch [13/100], Step [1830/3236], Loss: 1.9869, Perplexity: 7.2926
Epoch [13/100], Step [1840/3236], Loss: 1.8043, Perplexity: 6.0758
Epoch [13/100], Step [1850/3236], Loss: 1.7391, Perplexity: 5.6920
Epoch [13/100], Step [1860/3236], Loss: 1.8956, Perplexity: 6.6567
Epoch [13/100], Step [1870/3236], Loss: 1.7881, Perplexity: 5.9779
Epoch [13/100], Step [1880/3236], Loss: 1.7516, Perplexity: 5.7639
Epoch [13/100], Step [1890/3236], Loss: 1.8126, Perplexity: 6.1263
Epoch [13/100], Step [1900/3236], Loss: 1.7187, Perplexity: 5.5772
Epoch [13/100], Step [1910/3236], Loss: 1.8542, Perplexity: 6.3868
Epoch [13/100], Step [1920/3236], Loss: 1.8877, Perplexity: 6.6042
Epoch [13/100], Step [1930/3236], Loss: 1.8010, Perplexity: 6.0558
Epoch [13/100], Step [1940/3236], Loss: 1.7629, Perplexity: 5.8293
Epoch [13/100], Step [1950/3236], Loss: 1.8147, Perplexity: 6.1393
Epoch [13/100], Step [1960/3236], Loss: 1.8817, Perplexity: 6.5645
Epoch [13/100], Step [1970/3236], Loss: 1.8037, Perplexity: 6.0723
Epoch [13/100], Step [1980/3236], Loss: 1.9292, Perplexity: 6.8837
Epoch [13/100], Step [1990/3236], Loss: 1.8063, Perplexity: 6.0878
Epoch [13/100], Step [2000/3236], Loss: 1.8506, Perplexity: 6.3637
Epoch [13/100], Step [2010/3236], Loss: 1.8241, Perplexity: 6.1970
Epoch [13/100], Step [2020/3236], Loss: 1.8723, Perplexity: 6.5032
Epoch [13/100], Step [2030/3236], Loss: 1.8501, Perplexity: 6.3607
Epoch [13/100], Step [2040/3236], Loss: 1.8141, Perplexity: 6.1355
Epoch [13/100], Step [2050/3236], Loss: 1.8507, Perplexity: 6.3640
Epoch [13/100], Step [2060/3236], Loss: 1.7633, Perplexity: 5.8319
Epoch [13/100], Step [2070/3236], Loss: 1.8227, Perplexity: 6.1885
Epoch [13/100], Step [2080/3236], Loss: 1.7282, Perplexity: 5.6305
Epoch [13/100], Step [2090/3236], Loss: 1.8340, Perplexity: 6.2588
Epoch [13/100], Step [2100/3236], Loss: 1.8272, Perplexity: 6.2162
Epoch [13/100], Step [2110/3236], Loss: 1.8623, Perplexity: 6.4384
Epoch [13/100], Step [2120/3236], Loss: 1.8864, Perplexity: 6.5958
Epoch [13/100], Step [2130/3236], Loss: 1.9160, Perplexity: 6.7937
Epoch [13/100], Step [2140/3236], Loss: 1.8824, Perplexity: 6.5695
Epoch [13/100], Step [2150/3236], Loss: 1.9135, Perplexity: 6.7771
Epoch [13/100], Step [2160/3236], Loss: 1.8553, Perplexity: 6.3933
Epoch [13/100], Step [2170/3236], Loss: 1.8951, Perplexity: 6.6531
Epoch [13/100], Step [2180/3236], Loss: 1.8172, Perplexity: 6.1545
Epoch [13/100], Step [2190/3236], Loss: 1.8628, Perplexity: 6.4415
Epoch [13/100], Step [2200/3236], Loss: 1.6764, Perplexity: 5.3460
Epoch [13/100], Step [2210/3236], Loss: 1.9271, Perplexity: 6.8697
Epoch [13/100], Step [2220/3236], Loss: 1.7923, Perplexity: 6.0030
Epoch [13/100], Step [2230/3236], Loss: 1.8151, Perplexity: 6.1417
Epoch [13/100], Step [2240/3236], Loss: 1.8651, Perplexity: 6.4569
Epoch [13/100], Step [2250/3236], Loss: 1.7477, Perplexity: 5.7416
Epoch [13/100], Step [2260/3236], Loss: 1.7926, Perplexity: 6.0051
Epoch [13/100], Step [2270/3236], Loss: 1.7370, Perplexity: 5.6803
Epoch [13/100], Step [2280/3236], Loss: 1.8971, Perplexity: 6.6664
Epoch [13/100], Step [2290/3236], Loss: 1.8795, Perplexity: 6.5500
Epoch [13/100], Step [2300/3236], Loss: 1.8579, Perplexity: 6.4100
Epoch [13/100], Step [2310/3236], Loss: 1.7767, Perplexity: 5.9102
Epoch [13/100], Step [2320/3236], Loss: 1.8780, Perplexity: 6.5401
Epoch [13/100], Step [2330/3236], Loss: 1.7336, Perplexity: 5.6613
Epoch [13/100], Step [2340/3236], Loss: 1.9558, Perplexity: 7.0699
Epoch [13/100], Step [2350/3236], Loss: 1.8587, Perplexity: 6.4151
Epoch [13/100], Step [2360/3236], Loss: 1.8466, Perplexity: 6.3383
Epoch [13/100], Step [2370/3236], Loss: 1.7942, Perplexity: 6.0147
Epoch [13/100], Step [2380/3236], Loss: 1.8990, Perplexity: 6.6795
Epoch [13/100], Step [2390/3236], Loss: 1.8392, Perplexity: 6.2915
Epoch [13/100], Step [2400/3236], Loss: 1.7818, Perplexity: 5.9407
Epoch [13/100], Step [2410/3236], Loss: 1.7156, Perplexity: 5.5599
Epoch [13/100], Step [2420/3236], Loss: 1.8035, Perplexity: 6.0709
Epoch [13/100], Step [2430/3236], Loss: 1.8157, Perplexity: 6.1452
Epoch [13/100], Step [2440/3236], Loss: 1.8662, Perplexity: 6.4636
Epoch [13/100], Step [2450/3236], Loss: 1.7483, Perplexity: 5.7447
Epoch [13/100], Step [2460/3236], Loss: 1.8597, Perplexity: 6.4220
Epoch [13/100], Step [2470/3236], Loss: 1.8491, Perplexity: 6.3543
Epoch [13/100], Step [2480/3236], Loss: 1.8055, Perplexity: 6.0831
Epoch [13/100], Step [2490/3236], Loss: 1.8982, Perplexity: 6.6736
Epoch [13/100], Step [2500/3236], Loss: 1.8134, Perplexity: 6.1310
Epoch [13/100], Step [2510/3236], Loss: 1.7083, Perplexity: 5.5196
Epoch [13/100], Step [2520/3236], Loss: 1.8760, Perplexity: 6.5274
Epoch [13/100], Step [2530/3236], Loss: 1.8579, Perplexity: 6.4102
Epoch [13/100], Step [2540/3236], Loss: 1.7835, Perplexity: 5.9504
Epoch [13/100], Step [2550/3236], Loss: 1.9177, Perplexity: 6.8051
Epoch [13/100], Step [2560/3236], Loss: 1.8010, Perplexity: 6.0559
Epoch [13/100], Step [2570/3236], Loss: 1.8552, Perplexity: 6.3930
Epoch [13/100], Step [2580/3236], Loss: 1.8241, Perplexity: 6.1972
Epoch [13/100], Step [2590/3236], Loss: 1.8461, Perplexity: 6.3350
Epoch [13/100], Step [2600/3236], Loss: 1.8593, Perplexity: 6.4194
Epoch [13/100], Step [2610/3236], Loss: 1.8836, Perplexity: 6.5772
Epoch [13/100], Step [2620/3236], Loss: 1.8605, Perplexity: 6.4270
Epoch [13/100], Step [2630/3236], Loss: 1.8998, Perplexity: 6.6848
Epoch [13/100], Step [2640/3236], Loss: 1.7828, Perplexity: 5.9464
Epoch [13/100], Step [2650/3236], Loss: 1.9236, Perplexity: 6.8458
Epoch [13/100], Step [2660/3236], Loss: 1.8642, Perplexity: 6.4509
Epoch [13/100], Step [2670/3236], Loss: 1.8050, Perplexity: 6.0801
Epoch [13/100], Step [2680/3236], Loss: 1.9100, Perplexity: 6.7530
Epoch [13/100], Step [2690/3236], Loss: 1.9072, Perplexity: 6.7339
Epoch [13/100], Step [2700/3236], Loss: 1.8344, Perplexity: 6.2614
Epoch [13/100], Step [2710/3236], Loss: 1.8330, Perplexity: 6.2523
Epoch [13/100], Step [2720/3236], Loss: 1.8491, Perplexity: 6.3543
Epoch [13/100], Step [2730/3236], Loss: 1.7844, Perplexity: 5.9559
Epoch [13/100], Step [2740/3236], Loss: 1.8098, Perplexity: 6.1095
Epoch [13/100], Step [2750/3236], Loss: 1.8069, Perplexity: 6.0913
Epoch [13/100], Step [2760/3236], Loss: 1.8607, Perplexity: 6.4280
Epoch [13/100], Step [2770/3236], Loss: 1.7998, Perplexity: 6.0483
Epoch [13/100], Step [2780/3236], Loss: 1.9144, Perplexity: 6.7827
Epoch [13/100], Step [2790/3236], Loss: 1.8244, Perplexity: 6.1993
Epoch [13/100], Step [2800/3236], Loss: 1.8122, Perplexity: 6.1236
Epoch [13/100], Step [2810/3236], Loss: 1.8749, Perplexity: 6.5202
Epoch [13/100], Step [2820/3236], Loss: 1.8358, Perplexity: 6.2704
Epoch [13/100], Step [2830/3236], Loss: 1.8168, Perplexity: 6.1521
Epoch [13/100], Step [2840/3236], Loss: 1.8269, Perplexity: 6.2146
Epoch [13/100], Step [2850/3236], Loss: 1.9177, Perplexity: 6.8050
Epoch [13/100], Step [2860/3236], Loss: 1.9585, Perplexity: 7.0890
Epoch [13/100], Step [2870/3236], Loss: 1.8104, Perplexity: 6.1131
Epoch [13/100], Step [2880/3236], Loss: 1.8181, Perplexity: 6.1604
Epoch [13/100], Step [2890/3236], Loss: 1.8875, Perplexity: 6.6027
Epoch [13/100], Step [2900/3236], Loss: 1.8898, Perplexity: 6.6181
Epoch [13/100], Step [2910/3236], Loss: 1.9389, Perplexity: 6.9509
Epoch [13/100], Step [2920/3236], Loss: 1.8863, Perplexity: 6.5950
Epoch [13/100], Step [2930/3236], Loss: 1.8622, Perplexity: 6.4381
Epoch [13/100], Step [2940/3236], Loss: 1.8329, Perplexity: 6.2520
Epoch [13/100], Step [2950/3236], Loss: 1.8358, Perplexity: 6.2699
Epoch [13/100], Step [2960/3236], Loss: 1.7970, Perplexity: 6.0316
Epoch [13/100], Step [2970/3236], Loss: 1.8476, Perplexity: 6.3446
Epoch [13/100], Step [2980/3236], Loss: 1.7740, Perplexity: 5.8942
Epoch [13/100], Step [2990/3236], Loss: 1.8570, Perplexity: 6.4044
Epoch [13/100], Step [3000/3236], Loss: 1.8582, Perplexity: 6.4120
Epoch [13/100], Step [3010/3236], Loss: 1.9720, Perplexity: 7.1850
Epoch [13/100], Step [3020/3236], Loss: 1.8435, Perplexity: 6.3185
Epoch [13/100], Step [3030/3236], Loss: 1.9226, Perplexity: 6.8386
Epoch [13/100], Step [3040/3236], Loss: 1.8251, Perplexity: 6.2035
Epoch [13/100], Step [3050/3236], Loss: 1.8992, Perplexity: 6.6803
Epoch [13/100], Step [3060/3236], Loss: 1.9056, Perplexity: 6.7233
Epoch [13/100], Step [3070/3236], Loss: 1.8589, Perplexity: 6.4164
Epoch [13/100], Step [3080/3236], Loss: 1.8298, Perplexity: 6.2326
Epoch [13/100], Step [3090/3236], Loss: 1.9357, Perplexity: 6.9287
Epoch [13/100], Step [3100/3236], Loss: 1.8869, Perplexity: 6.5988
Epoch [13/100], Step [3110/3236], Loss: 1.8659, Perplexity: 6.4620
Epoch [13/100], Step [3120/3236], Loss: 1.8173, Perplexity: 6.1553
Epoch [13/100], Step [3130/3236], Loss: 1.8478, Perplexity: 6.3458
Epoch [13/100], Step [3140/3236], Loss: 1.8761, Perplexity: 6.5278
Epoch [13/100], Step [3150/3236], Loss: 1.8764, Perplexity: 6.5297
Epoch [13/100], Step [3160/3236], Loss: 1.8658, Perplexity: 6.4611
Epoch [13/100], Step [3170/3236], Loss: 1.7118, Perplexity: 5.5389
Epoch [13/100], Step [3180/3236], Loss: 1.8599, Perplexity: 6.4230
Epoch [13/100], Step [3190/3236], Loss: 1.8021, Perplexity: 6.0626
Epoch [13/100], Step [3200/3236], Loss: 1.7294, Perplexity: 5.6373
Epoch [13/100], Step [3210/3236], Loss: 1.7980, Perplexity: 6.0373
Epoch [13/100], Step [3220/3236], Loss: 1.9242, Perplexity: 6.8495
Epoch [13/100], Step [3230/3236], Loss: 1.8616, Perplexity: 6.4339
start evaluate ...
57879 : a street with cars parked on the side of the road
167656 : a man standing on a tennis court holding a racquet
509577 : a plate of food with a salad and a sandwich
308730 : a kitchen with a stove oven dishwasher and a sink
174898 : a motorcycle parked on the side of the road
94379 : a wine glass sitting on top of a table
558608 : a group of people standing on a beach with a kite
355919 : a pepperoni pizza on a plate next to a bottle of beer
79565 : two giraffes standing in a field with trees in the background
443101 : a herd of sheep grazing on a lush green hillside
loading annotations into memory...
Done (t=0.83s)
creating index...
index created!
using 5000/5000 predictions
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
tokenization...
PTBTokenizer tokenized 307821 tokens at 1275329.65 tokens per second.
PTBTokenizer tokenized 54297 tokens at 629424.06 tokens per second.
setting up scorers...
computing Bleu score...
{'reflen': 48586, 'guess': [49298, 44298, 39298, 34298], 'testlen': 49298, 'correct': [33273, 16055, 6980, 3037]}
('ratio:', 1.0146544272012306)
Bleu_1: 0.675
Bleu_2: 0.495
Bleu_3: 0.352
Bleu_4: 0.249
computing METEOR score...
METEOR: 0.231
computing Rouge score...
ROUGE_L: 0.497
computing CIDEr score...
CIDEr: 0.811
computing SPICE score...
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
Threads( StanfordCoreNLP ) [25.857 seconds]
SPICE evaluation took: 39.61 s
SPICE: 0.159
model saved to experiment/gt/withGAN/model_mle_G.pth
Epoch [14/100], Step [10/3236], Loss: 1.6823, Perplexity: 5.3777
^Z
[2]+  Ï†ïÏßÄÎê®               python Main.py
]0;gt@gt: ~/PycharmProjects/show-and-tell[01;32mgt@gt[00m:[01;34m~/PycharmProjects/show-and-tell[00m$ exit
Ï†ïÏßÄÎêú ÏûëÏóÖÏù¥ ÏûàÏäµÎãàÎã§.
]0;gt@gt: ~/PycharmProjects/show-and-tell[01;32mgt@gt[00m:[01;34m~/PycharmProjects/show-and-tell[00m$ exit

Script done on 2017ÎÖÑ 05Ïõî 23Ïùº (Ìôî) Ïò§ÌõÑ 01Ïãú 03Î∂Ñ 51Ï¥à
